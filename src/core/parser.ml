(***** Beluga external syntax parser

**** Intro to parser combinators

This is a hand-made parser combinator system.
The basic idea in parser combinators is to use higher-order functions
to manipulate _parsing functions_ to build up more complex parsers.

The most basic type we can give for a parsing function would be
something like:

> type 'a parser = char list -> char list * 'a option

`char list` represents the input stream. We must return a new stream,
perhaps with some characters removed since we parsed them. The result
of the parse is parametric. Since parsing may fail, we use a type
constructor to represent this, namely `option`.

However this design has many shortcomings.
1. Representing the input as a `char list` requires the entire input
   to be buffered in memory. This is wasteful. Instead, we should
   progressively read input as we need it. Therefore in our
   implementation we use a lazy list `LinkStream.t`.
2. Using `option` to represent failure doesn't give us a means to
   specify what the error is. Instead we use `Either.t` in order to
   also return some information in case of failure.
3. Finally, in order to control backtracking and other parsing
   features, we will need to not only pass around and transform the
   _input_, but a more general _parser state_.

So our parsing function type now looks like:

> type 'a parser = state -> state * (error, 'a) Either.t

where `state` contains a `(Location.t * Token.t) LinkStream.t` for the
input as well as extra stuff for handling backtracking.

***** Backtracking

The naive implementation of the `alt' alternation combinator is to say
that `alt p1 p2' first runs `p1', and if it fails, runs `p2'.
This implementation has the major drawback of allowing _unlimited_
backtracking. This is undesirable because it results in terrible error
messages. What we would like is a way to control the backtracking
behaviour of parsers on a more fine-grained level.

Instead, the library below is non-backtracking, so it introduces the
`trying' combinator to selectively enable backtracking.
`trying p' runs `p', and if `p' fails having even consumed input, then
`trying p' can still be backtracked out of.
The `alt' combinator is implemented like this:
- Run `p1'. If it succeeds, return its result without trying p2.
- If `p1' failed without consuming any input, then run `p2'.
- If `p1' failed under a `trying', then run `p2'.
- Otherwise, the error generated by `p1' was fatal, so return it.

The rationale for this is that it allows the parser writer to commit
to a parse tree once certain conditions have been met. For example,
in Beluga, after a `case` keyword, we know for sure that we're parsing
a case expression. Therefore, if we fail afterwards to parse the
scrutinee of the case (a synthesizable expression), we should not
backtrack out of the parser for case expressions.
 *)

open Support

module Comp = Syntax.Prs.Comp
module LF = Syntax.Prs.LF
module Harpoon = Syntax.Prs.Harpoon
module Sgn = Syntax.Prs.Sgn

(***** Parser state definition *****)

(** Type of located values, i.e. values paired with their location. *)
type 'a locd = Location.t * 'a

(** The input to the parser is a backtrackable stream of tokens paired
    with their locations.
 *)
type input = Token.t locd LinkStream.t

(** The parser state contains the input stream as well as control
    information to handle backtracking.
 *)
type state =
  { input : input
  ; backtrack : bool
  ; last_loc : Location.t (* Location of the last token seen by the parser. *)
  }

  (*
(** Peeks at the next token in the input stream in the given state. *)
let peek_at (s : state) : Token.t locd option =
  Option.(LinkStream.observe s.input $> Pair.fst)
   *)

  (*
(** Like `peek_at` but forgets the location. *)
let next_token s =
  Option.(peek_at s $> Pair.snd |> get_default Token.EOI)
   *)

(***** ERROR HANDLING *****)

type error_entry =
  { label : string
  ; location : Location.t option
  }

type path' =
  | Entry of error_entry
  | Shift of error_entry * path
and path = path' list

let entry ?location label =
  Entry { location; label }

let rec path_head (p : path) : error_entry option =
  match p with
  | [] -> Option.none
  | x :: _ -> Option.some (path'_head x)

and path'_head (p' : path') : error_entry =
  match p' with
  | Entry e -> e
  | Shift (e, p) ->
     match path_head p with
     | Option.Some e' ->
        { e with label = e.label ^ " " ^ e'.label }
     | Option.None -> e

type content =
  [ `token of Token.t option
  | `identifier of string option
  | `qualified_identifier of (string list * string) option
  | `keyword of string option
  | `hash_identifier of string option
  | `dollar_identifier of string option
  | `hash_blank
  | `dollar_blank
  | `hole of string option
  | `integer of int option
  | `dot_integer
  | `string_literal
  | `html_comment
  | `eoi
  ]

let print_content ppf : content -> unit =
  let open Format in
  let format_option_with g ppf t =
    Option.print (fun ppf t -> fprintf ppf " `%a'" g t) ppf t
  in
  let string_option = format_option_with pp_print_string in
  let int_option = format_option_with pp_print_int in
  let format_with ppf s f x = fprintf ppf "%s%a" s f x in
  function
  | `token t ->
     fprintf ppf "token%a"
       (format_option_with Token.pp) t
  | `dot_integer -> fprintf ppf "dot integer"
  | `string_literal -> fprintf ppf "string literal"
  | `identifier i ->
     format_with ppf "identifier" string_option i
  | `qualified_identifier i ->
     fprintf ppf "qualified identifier%a"
       (format_option_with
          (fun ppf (ss, s) ->
            fprintf ppf "%a%s"
              (pp_print_list ~pp_sep: (fun ppf () -> fprintf ppf ".")
                 pp_print_string) ss
              s))
       i
  | `hash_identifier i ->
     format_with ppf "hash identifier" string_option i
  | `dollar_identifier i ->
     format_with ppf "dollar identifier" string_option i
  | `hash_blank ->
     fprintf ppf "hash blank"
  | `dollar_blank ->
     fprintf ppf "dollar blank"
  | `hole i ->
     format_with ppf "hole" string_option i
  | `keyword i ->
     format_with ppf "keyword" string_option i
  | `integer i ->
     format_with ppf "integer literal" int_option i
  | `eoi ->
     fprintf ppf "end of input"
  | `html_comment -> fprintf ppf "HTML comment"

type error' =
  (* External errors: the user's fault. *)
  | Unexpected of { expected : content; actual : content }
  | IllFormedDataDecl
  (* ^ incorrect constructor type: the type of a constructor must be a
     base type or a function type.
   *)
  (* | Custom of string (* Generic external error. *) *)
  | WrongConstructorType of
    { constructor_name : Name.t
    ; expected_type_name : Name.t
    ; actual_type_name : Name.t
    }

  | NoMoreChoices of error list (* all alternatives failed *)

  (* Internal errors: our fault; these should never go to the user. *)
  (** Raised by `satisfy` when it fails.
      This is an internal error because it is totally uninformative
      and low-level. When a high-level parser is constructed using
      `satisfy`, it should check for this error and rewrite it into a
      nicer one for the user.
   *)
  | NotFollowedBy

  (** Generic internal error. *)
  | Violation of string

and error =
  { error : error'
  (* ^ The actual error. *)
  ; path : path
  (* ^ Sequence of parser labels that led to the parse error.
     This is used to generate errors of the form.
     ```
     Parse error: unexpected `bar', expected `foo'.
     In a parser for `production1'
     In a parser for `production2'
     and so on
     ```
   *)
  ; loc : Location.t (* the location the error occurred at *)
  }

  (*
(** Adds a label to the error path *)
let push_label (l : string) : error -> error =
  fun e -> { e with path = Entry l :: e.path }
   *)

         (*
(** Adds a label to an error path, if any. *)
let push_label_option (l : string option) (e : error) : error =
  let open Option in
  l $> (fun l -> push_label l e)
  |> get_default e
          *)

exception Error of state * error

(** Pretty-print an error patHarpoon. *)
let print_path ppf (path : path) : unit =
  let open Format in
  let print_entry ppf { label; location } : unit =
    fprintf ppf "in `%s'%a" label
      (Option.print
         (fun ppf x -> fprintf ppf " at %a" Location.print x))
      location
  in
  let rec go' ppf (path' : path') =
    match path' with
    | Entry e -> fprintf ppf "%a" print_entry e
    | Shift (e, p) ->
       fprintf ppf "@[%a@]@,%a" print_entry e go_box p
  and go ppf (path : path) =
    pp_print_list go' ppf path
  and go_box ppf (path : path) =
    fprintf ppf "  @[<v>%a@]" go path
  in
  fprintf ppf "%a" go_box path

let print_error ppf ({path; loc; _} as e : error) =
  let open Format in
  fprintf ppf "@[<v>Parse error.@,";
  let (* rec *) g ppf {error = e; _} =
    match e with
    | NoMoreChoices ss ->
       fprintf ppf "Expected:@,  @[<v>";
       pp_print_list ~pp_sep: (fun _ () -> ())
         (fun ppf x ->
           Option.print
             (fun ppf x -> fprintf ppf "%s@," x.label)
             ppf
             (path_head x.path))
         ppf
         ss;
       fprintf ppf "@]"
    (* fprintf ppf "Next token: %a@." Token.(print `TOKEN) (next_token s) *)
    | Unexpected { expected = t_exp; actual = t_act; _ } ->
       fprintf ppf "Unexpected token in stream@,  @[<v>Expected %a@,Got %a@]@,"
         print_content t_exp
         print_content t_act
    | IllFormedDataDecl ->
       fprintf ppf
         ( "Ill-formed constructor declaration.@," ^^
             "The type of a constructor must be a base type or function type."
         )
    | WrongConstructorType
      { constructor_name = c
      ; expected_type_name = exp
      ; actual_type_name = act
      } ->
       fprintf ppf
         ( "Wrong datatype for constructor %s.@,  @[<v>"
           ^^ "Expected type %s@,"
           ^^ "Actual type %s"
           ^^ "@]"
         )
         (Name.string_of_name c)
         (Name.string_of_name exp)
         (Name.string_of_name act)
    (* | Custom s -> fprintf ppf "%s" s *)
    | Violation s -> fprintf ppf "%s" s
  in
  fprintf ppf "%a" g e;
  if Debug.flag 11 then fprintf ppf "@,%a" print_path path;
  fprintf ppf "@]"

let () =
  Error.register_printer'
    begin
      function
      | Error (s, e) ->
         Option.some
           (Error.print_with_location e.loc
              (fun ppf -> print_error ppf e))
      | _ -> Option.none
    end

(***** Syntax mangling helpers *****)

type typ_or_ctx =
  [ `Typ of LF.typ
  | `Ctx of LF.dctx
  ]

(***** Parser type definition *****)

(** Gets the location of the next item in the input stream *)
let next_loc_at (s : state) : Location.t =
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed"
  (* the lexer should infinitely repeat "EOI" when it's done. *)
  | Option.Some ((loc, _), _) -> loc

let prev_loc_at (s : state) : Location.t = s.last_loc

let initial_state input =
  { input
  ; backtrack = false
  ; last_loc = Location.ghost
  }

(** A parsing result is either an error or a successfully computed value. *)
type 'a result = (error, 'a) Either .t

(** A parsing function transforms a state and produces a parsing result. *)
type 'a parser = state -> state * 'a result

(** Run a parser.
    In other words, extracts the parsing function from a parser. *)
let[@inline] run p s = p s

(** Eliminator for parse results. *)
let handle catch f = Either.eliminate catch f

(** Converts a parse result to Either. *)
let to_either (r : 'a result) : (error, 'a) Either.t = r

(** Extracts the value from a parse result.
    If the parse was unsuccessful, then this raises a parse error exception. *)
let extract =
  function
  | (s, Either.Left e) -> raise @@ Error (s, e)
  | (_, Either.Right x) -> x

type 'a t = 'a parser

(***** Basic parser helpers *****)

(** Runs `p' and invokes the given handler to modify the outcome.
    Despite being called "catch", this parser is actually a kind of `map',
    and is used to implement "low-level" parser transformations.
 *)
let catch (p : 'a parser) (handler : state * 'a result -> state * 'b result) : 'b parser =
  fun s -> run p s |> handler

  (*
(** Runs p. If it fails, its error path is transformed by the given
    function.
    Use a constant function to replace an error path with a new one.
 *)
let repathing (l : path -> path) (p : 'a parser) : 'a parser =
  catch p
    (function
     | Either.Left {error; path} -> Either.left {error; path = l path}
     | x -> x)
   *)

(** Constructs a failure result for a given state. *)
let fail_at' s loc path error =
  ( s
  , Either.left {error ; path; loc}
  )

(** Fail with no error patHarpoon. *)
let fail_at s error = fail_at' s (next_loc_at s) [] error

(** A parser that fails with the given error and patHarpoon. *)
let fail' path e : 'a parser =
  fun s -> fail_at' s (next_loc_at s) path e

(** A parser that fails with the given error and an empty patHarpoon. *)
let fail e : 'a parser = fail' [] e

let return_at s x =
  (s, Either.right x)

(** Gets the current parser state. *)
let get_state : state parser =
  fun s -> return_at s s

(** Sets the current parser state. *)
let put_state (s : state) : unit parser =
  fun _ -> return_at s ()

  (*
(** Keeps the state unchanged, but reads the current location. *)
let get_loc =
  anon_parser
    (fun s -> return_at s (s.loc))
   *)

(***** Parser combinators *****)

(** Runs the parser `p` with unlimited backtracking enabled. *)
let trying p =
  fun s ->
    match run p s with
    | (s, Either.Left e) -> ({ s with backtrack = true}, Either.left e)
    | x -> x

module M = Monad.Make (struct
  type nonrec 'a t = 'a t

  let return x = fun s -> return_at s x

  let bind k p =
    fun s ->
    match run p s with
    | (s, Either.Right x) -> run (k x) s
    | (s, Either.Left e) -> (s, Either.left e)
end)

include (M : Monad.MONAD with type 'a t := 'a t)

include (Functor.Make (M) : Functor.FUNCTOR with type 'a t := 'a t)

include (Apply.Make (M) : Apply.APPLY with type 'a t := 'a t)

             (*
(** Forgets the result of a parser. *)
let void (p : 'a parser) : unit parser = p &> return ()
              *)

(***** Combinators for handling error labels. *****)

(** Gets the location of the next token in the input stream.
    If the stream is ended, gets the location of the last token.
 *)
let next_loc : Location.t parser =
  get_state
  $> fun s -> next_loc_at s

let prev_loc : Location.t parser =
  get_state
  $> fun s -> prev_loc_at s

(** Runs `p` tracking the span of source material processed by it. *)
let span p =
  seq3 next_loc p prev_loc $> fun (l1, x, l2) -> (Location.join l1 l2, x)

(** Runs the parser, and if it fails, runs the given function to
    transform the label stack.
    Also provides the location of the very next token `p` would see.
 *)
let relabelling (type a) (p : a parser) (f : Location.t -> path -> path) : a parser =
  next_loc
  >>= fun loc ->
    catch p
      (function
       | s, Either.Left e -> s, Either.left {e with path = f loc e.path }
       | x -> x)

    (*
(** Flipped version of `relabelling` *)
let relabelled f p = relabelling p f
     *)

let shift p s =
  relabelling p
    begin fun loc path ->
    [ Shift
        ( { location = Option.some loc
          ; label = s
          }
        , path
        )
    ]
    end

let shifted s p = shift p s

(** Adds the given label to the stack if `p` fails. *)
let label p s =
  relabelling p (fun location path -> entry ~location s :: path)

(** Flipped version of `label'. *)
let labelled s p = label p s

(** Replaces the _name_ of the last entry on the patHarpoon. *)
let renamed label p =
  relabelling p
    begin fun loc ->
    function
    | [] -> []
    | Shift (e, p) :: xs -> Shift ({ e with label }, p) :: xs
    | Entry e :: xs -> Entry { e with label } :: xs
    end

(***** Special combinators *****)

(** `not_followed_by p` succeeds if the parser `p` fails.
    This parser does not consume any input.
 *)
let not_followed_by (p : 'a parser) : unit parser =
  span get_state
  >>= fun (loc, s) ->
    catch p
      (function
       | s', Either.Left _ ->
          (* if `p` fails, we restore the original state *)
          run (put_state s) s'
       | _, Either.Right _ ->
          (* if `p` succeeds, then we need to fail *)
          s, Either.left { error = NotFollowedBy; path = []; loc = loc }
      )

(***** Parsing lists. *****)

    (*
(** Transforms each element of a list into a parser, and sequences the
    parsers.
 *)
let rec traverse (f : 'a -> 'b parser) (xs : 'a list) : 'b list parser =
  match xs with
  | [] -> return []
  | x :: xs ->
     seq2 (f x) (traverse f xs)
     $> fun (x, xs) -> x :: xs
     *)

(** Like {!traverse} but for parsers without interesting outputs. *)
let rec traverse_ (f : 'a -> unit parser) (xs : 'a list) : unit parser =
  match xs with
  | [] -> return ()
  | x :: xs ->
     f x &> traverse_ f xs

                     (*
(** Runs a sequence of parsers in order and collects their results. *)
let sequence (ps : 'a parser list) : 'a list parser =
  traverse Fun.id ps
                      *)

                                (*
(** Gets the next item in the input stream without advancing the parser. *)
let peek : (Location.t * Token.t) option parser = anon_parser (fun s -> return_at s (peek_at s))
                                 *)

(***** Prioritized choice *****)

(** Alternation between parsers.

    Runs `p1`. If it fails, p2 is run if one of the following is true.
    - p1 failed without consuming any input.
    - p2 failed with backtracking enabled.

    Backtracking is enabled by the `trying` combinator.
 *)
let alt (p1 : 'a parser) (p2 : 'a parser) : 'a parser =
  fun s ->
  match run p1 s with
  | (s', Either.Left e) ->
      let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
      if Bool.not consumed_input || s'.backtrack
      then run p2 s
      else (s', Either.left e)
  | x -> x

let choice (ps : 'a parser list) : 'a parser =
  fun s ->
  let rec go es =
    function
    | [] -> fail (NoMoreChoices es)
    | p :: ps' ->
        catch p
          (function
          | (s', Either.Left e) ->
              let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
              if Bool.not consumed_input || s'.backtrack
              then run (go (e :: es) ps') s
              else (s', Either.left e)
          | x -> x)
  in
  run (go [] ps) s

(** Succeeds only if the stream has reached the end of the input. *)
let eoi : unit parser =
  (fun s ->
  match LinkStream.observe s.input with
  | Option.None | Option.Some ((_, Token.EOI), _) -> return_at s ()
  | Option.Some ((_, t), _) ->
    fail_at s (Unexpected { expected = `eoi; actual = `token (Option.some t) }))
  |> labelled "end of input"

(** Constructs a parser that accepts the current token if it satisfies
    the given predicate.
    The predicate is _successful_ if it returns `Right`.
    The `Left` output indicates failure and can be used to remember
    the next token in the stream to construct better eroros in a
    downstream parser. If you don't care, use unit.
    The input stream advances only if the predicate succeeds.
 *)
let satisfy (f : Token.t -> ('e, 'b) Either.t) : ('e, 'b) Either.t parser =
  fun s ->
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed: end-of-input is a token"
  | Option.Some ((loc, t), xs) ->
      let r = f t in
      let s' =
        (* construct the new state with the input depending on
          whether the predicate succeeded.
        *)
        match r with
        | Either.Left _ -> s
        | Either.Right _ -> { s with input = xs; last_loc = loc }
      in
      return_at s' r

(** Tries a parser, and if it fails returns [Option.none] *)
let maybe (p : 'a parser) : 'a option parser =
  shifted "optionally"
    (alt (p $> Option.some) (return Option.none))

(** Tries a parser, and if it fails uses a default value. *)
let maybe_default p ~default =
  maybe p $> Option.value ~default

(** Internal implementation of `many` that doesn't label. *)
let rec many' (p : 'a parser) : 'a list parser =
  alt (some' p) (return [])

(** Internal implementation of `some` that doesn't label. *)
and some' (p : 'a parser) : 'a list parser =
  p >>= fun x -> many' p >>= fun xs -> return (x :: xs)

(** `many p` repeats the parser `p` zero or more times and collects
    the results in a list.
 *)
let many (p : 'a parser) : 'a list parser =
  shifted "many" (many' p)

(** `some p` repeats the parser `p` one or more times and collects the
    results in a list.
 *)
let some (p : 'a parser) : 'a list parser =
  shifted "some" (some' p)

(** `sep_by0 p sep` parses zero or more occurrences of `p` separated
    by `sep` and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use `void`.
 *)
let sep_by0 (p : 'a parser) (sep : unit parser) : 'a list parser =
  maybe p
  >>= (function
      | Option.None -> return []
      | Option.Some x ->
        many' (sep &> p)
        >>= fun xs -> return (x :: xs))
  |> shifted "many separated"

(** `sep_by1 p sep` parses one or more occurrences of `p` separated by
    `sep` and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use `void`.
 *)
let sep_by1 (p : 'a parser) (sep : unit parser) : 'a List1.t parser =
  seq2 p (many' (sep &> p))
  $> (fun (x, xs) -> List1.from x xs)
  |> shifted "some separated"

(***** Unmixing & other checks *****)

(** Checks that datatype declarations are well formed.
    We can't do this later because after parsing there is no
    structural grouping between constructors of a same datatype.
 *)
let check_datatype_decl loc a cs : unit parser =
  let rec retname =
    function
    | Comp.TypBase { head; _ } -> return head
    | Comp.TypArr { range; _ } -> retname range
    | Comp.TypPiBox { range; _ } -> retname range
    | _ -> fail IllFormedDataDecl
  in
  traverse_
    (function
     | Sgn.CompConst { identifier; typ; _ } ->
        retname typ
        >>= fun a' ->
          if Name.(a <> a')
          then fail
            (WrongConstructorType
              { constructor_name = identifier
              ; expected_type_name = a
              ; actual_type_name = a'
              })
          else return ()
     | _ -> fail (Violation "check_datatype_decl invalid input"))
    cs

let check_codatatype_decl loc a cs : unit parser =
  let retname =
    function
    | Comp.TypBase { head; _ } -> return head
    | _ -> fail IllFormedDataDecl
  in
  traverse_
    (function
     | Sgn.CompDest { identifier; observation_typ = tau0; _} ->
        retname tau0
        >>= fun a' ->
          if Name.(a <> a')
          then fail
            (WrongConstructorType
              { constructor_name = identifier
              ; expected_type_name = a
              ; actual_type_name = a'
              })
          else return ()
     | _ -> fail (Violation "check_codatatype_decl invalid input"))
    cs

(****** Simple parsers *****)

let satisfy' (expected : content) (f : Token.t -> 'a option) : 'a parser =
  satisfy (fun t -> f t |> Option.eliminate (Fun.const (Either.left t)) Either.right)
  |> span
  >>= fun (location, x) ->
    match x with
    | Either.Left t ->
       fail'
         [ entry ~location (Format.stringify print_content expected) ]
         (Unexpected { expected; actual = `token (Option.some t) })
    | Either.Right x -> return x

(** Parses an exact token. *)
let token (t : Token.t) : unit parser =
  satisfy' (`token (Option.some t))
    (fun x -> Option.of_bool (Token.(x = t)))

(** Parses an exact sequence of tokens. *)
let tokens (ts : Token.t list) : unit parser =
  traverse_ token ts

(** Parses an identifier and verifies that it is exactly the given
    string. This is used for parsing "weak keywords", which we would
    still like to allow as general identifiers, but which appear in
    restricted contexts as keywords.
 *)
let keyword (kw : string) : unit parser =
  satisfy' (`keyword (Option.some kw))
    Fun.(Token.equal (Token.IDENT kw) >> Option.of_bool)

let identifier : string parser =
  satisfy' (`identifier Option.none)
    (function
     | Token.IDENT s -> Option.some s
     | _ -> Option.none)

let hash_identifier : string parser =
  satisfy' (`hash_identifier Option.none)
    (function
     | Token.HASH_IDENT s -> Option.some s
     | _ -> Option.none)

let dollar_identifier : string parser =
  satisfy' (`dollar_identifier Option.none)
    (function
     | Token.DOLLAR_IDENT s -> Option.some s
     | _ -> Option.none)

let hash_blank : unit parser =
  satisfy' `hash_blank
    (function
     | Token.HASH_BLANK -> Option.some ()
     | _ -> Option.none)

let dollar_blank : unit parser =
  satisfy' `dollar_blank
    (function
     | Token.DOLLAR_BLANK -> Option.some ()
     | _ -> Option.none)

let namify (p : string t) : Name.t t =
  p |> span
  $> fun (location, x) -> Name.mk_name ~location (Name.SomeString x)

let name : Name.t parser =
  namify identifier

type name_or_blank = [ `name of Name.t | `blank of Location.t ]

let blankify (p : unit t) : name_or_blank t =
  p |> span $> fun (loc, ()) -> `blank loc

let name_or_blank : name_or_blank parser =
  alt
    (name $> fun x -> `name x)
    (token Token.UNDERSCORE |> blankify)

(** Converts a name or blank into a plicity and a name. *)
let plicity_name_of_nb =
  function
  | `blank loc' -> (Plicity.implicit, Name.mk_blank (Option.some loc'))
  | `name x -> (Plicity.explicit, x)

let dot_name : Name.t t =
  token Token.DOT &> name

let hash_name : Name.t t =
  namify hash_identifier

let hash_name_or_blank : name_or_blank t =
  alt
    (hash_name $> fun x -> `name x)
    (hash_blank |> blankify)

let dollar_name : Name.t t =
  namify dollar_identifier

let dollar_name_or_blank : name_or_blank t =
  alt
    (dollar_name $> fun x -> `name x)
    (dollar_blank |> blankify)

type name_class =
  [ `ordinary
  | `dollar
  | `hash
  ]

type 'a name_parser = name_class -> 'a t

let name_or_blank' : name_or_blank name_parser =
  function
  | `ordinary -> name_or_blank
  | `dollar -> dollar_name_or_blank
  | `hash -> hash_name_or_blank

let name' : Name.t name_parser =
  function
  | `ordinary -> name
  | `dollar -> dollar_name
  | `hash -> hash_name

let integer : int parser =
  satisfy' (`integer Option.none)
    (function
     | Token.INTLIT k -> Option.some k
     | _ -> Option.none)

let dot_integer : int parser =
  satisfy' `dot_integer
    (function
     | Token.DOT_NUMBER k -> Option.some k
     | _ -> Option.none)

let fqidentifier = sep_by1 (trying identifier) (token Token.DOUBLE_COLON)

(** A qualified name, with possible module names before. *)
let fqname =
  fqidentifier
  |> span
  $> fun (location, is) ->
     let (modules, i) = List1.unsnoc is in
     Name.mk_name ~location ~modules Name.(SomeString i)

let pragma s = token (Token.PRAGMA s)

let string_literal =
  satisfy' `string_literal
    (function
     | Token.STRING s -> Option.some s
     | _ -> Option.none)

(** Runs the parser `p` between two parsers whose results are
    ignored. *)
let bracketed start stop p =
  start &> p <& stop

(** Runs the parser `p` between the two instances of the same parser
    `b` whose results are ignored. *)
let bracketed' b p = bracketed b b p

(** [parens p] parses [`(` p `)`]. *)
let parens p = bracketed (token Token.LPAREN) (token Token.RPAREN) p

(** [braces p] parses [`{` p `}`]. *)
let braces p = bracketed (token Token.LBRACE) (token Token.RBRACE) p

(** [bracks p] parses [`[` p `]`]. *)
let bracks p = bracketed (token Token.LBRACK) (token Token.RBRACK) p

(** [angles p] parses [`<` p `>`]. *)
let angles p = bracketed (token Token.LANGLE) (token Token.RANGLE) p

(** bracks_or_opt_parens' prefix p
    parses p surrounded optionally by square brackets or parentheses,
    with `prefix` before the square brackets or parentheses, but
    forbidden in the case that they are omitted.
 *)
let bracks_or_opt_parens' prefix p =
  alt
    (prefix
     &> alt (bracks p) (parens p))
    p

(** See bracks_or_opt_parens'. This is a prefixless instance. *)
let bracks_or_opt_parens p =
  bracks_or_opt_parens' (return ()) p

(** See bracks_or_opt_parens'.
    This instance uses an optional hash sign as the prefix and is used
    for parsing the contextual type of a parameter variable, which has
    a hash before, optionally.
 *)
let sigil_bracks_or_opt_parens tok p =
  bracks_or_opt_parens' (maybe (token tok)) p

(** Helper for parsing something *optionally* between parens. *)
let opt_parens p = alt (parens p) p

(** Parses p and requires that the input stream be finished. *)
let only p = p <& eoi

(***** Production rules *****)

let nostrenghten_pragma =
  span (pragma "nostrengthen")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.NoStrengthen }

let coverage_pragma =
  span (pragma "coverage")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.Coverage `Error }

let warncoverage_pragma =
  span (pragma "warncoverage")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.Coverage `Warn }

let sgn_global_prag : Sgn.decl parser =
  labelled "global pragma"
  @@ choice
       [ nostrenghten_pragma
       ; coverage_pragma
       ; warncoverage_pragma
       ]

let sgn_name_pragma : Sgn.decl parser =
  seq3
    (pragma "name" &> name)
    identifier
    (maybe identifier <& token Token.DOT)
  |> labelled "name pragma"
  |> span
  $> fun (location, (constant, meta_name, comp_name)) ->
       let pragma = Sgn.NamePrag { constant; meta_name; comp_name } in
       Sgn.Pragma { location; pragma }

module rec LF_parsers : sig
  val lf_kind : LF.kind t
  val lf_typ : LF.typ t
  val lf_kind_or_typ : [ `Kind of LF.kind | `Typ of LF.typ] t
  val lf_typ_decl : LF.typ_decl t
  val lf_term : LF.term t
end = struct
  let lf_term_sequence =
    span (some LF_parsers.lf_term) $> (fun (location, terms) -> LF.TList { location; terms })
    |> labelled "LF term sequence"

  let lf_term_lam =
    seq2 (token Token.LAMBDA &> name <& token Token.DOT) lf_term_sequence
      |> span
      $> (fun (location, (parameter_name, body)) -> LF.Lam { location; parameter_name; body })
    |> labelled "LF lambda term"

  let lf_head =
    span fqname
    |> labelled "LF application head"
    $> fun (loc, n) -> LF.Name (loc, n, Option.none)

  let lf_term_head =
    span lf_head $> (fun (location, head) -> LF.Root { location; head; spine = [] })
    |> labelled "LF head term"

  let lf_term_atomic =
    choice
      [ span (token Token.UNDERSCORE)
        $> (fun (location, ()) -> LF.Root { location; head = LF.Hole location; spine = [] })
      ; span (parens (seq2 LF_parsers.lf_typ (maybe (token Token.COLON &> LF_parsers.lf_typ))))
        >>= fun (location, (m, q)) ->
          match q, m with
          | Option.None, LF.AtomTerm { term; _ } -> return term
          | Option.None, _ -> return @@ LF.NTyp { location; typ = m }
          | Option.Some typ, LF.AtomTerm { term; _ } -> return @@ LF.Ann { location; term; typ }
          | _, _ -> fail (Violation "invalid atomic LF term")
                                  (* ^ XXX not sure if this is a violation or a user error -je *)
      ]
    |> labelled "LF atomic term"

  (** An LF type declaration, `x : a'. *)
  let lf_typ_decl =
    seq2
      (name <& token Token.COLON)
      LF_parsers.lf_typ
    |> labelled "LF type declaration"
    $> fun (x, a) -> LF.TypDecl (x, a)

  let lf_typ_pi : LF.typ parser =
    let lf_typ_declaration = seq2 (name <& token Token.COLON) LF_parsers.lf_typ in
    seq2
      (trying (braces lf_typ_declaration <& maybe (token Token.ARROW)))
      LF_parsers.lf_typ
    |> span
    $> (fun (location, ((parameter_name, parameter_type), range)) ->
          LF.PiTyp { location; parameter_name; parameter_type; range })
    |> labelled "LF pi type"

  let lf_typ_atomic =
    alt
      (span lf_term_sequence
        $> function
          | (loc, LF.NTyp { typ; _ }) -> typ
          | (loc, LF.TList { terms = [ LF.NTyp { typ; _ } ]; _ }) -> typ
          | (location, LF.TList { terms = [ term ]; _ }) -> LF.AtomTerm { location; term }
          | (location, term) -> LF.AtomTerm { location; term })
      (parens LF_parsers.lf_typ)
    |> labelled "LF atomic type"

  let lf_typ_arr : LF.typ parser =
    seq2
      (trying (lf_typ_atomic <& token Token.ARROW))
      LF_parsers.lf_typ
    |> span
    $> (fun (location, (domain, range)) -> LF.ArrTyp { location; domain; range })
    |> labelled "LF arrow type"

  let lf_typ : LF.typ parser =
    choice
      [ lf_typ_pi
      ; lf_typ_arr
      ; lf_typ_atomic
      ]
    |> labelled "LF type"

  (** Parses the `type' kind. *)
  let type_kind =
    labelled "`type' kind"
      (span (token Token.KW_TYPE) $> fun (location, ()) -> LF.Typ { location })

  let lf_kind =
    let lf_typ_declaration = seq2 (name <& token Token.COLON) LF_parsers.lf_typ in
    let pi_kind =
      seq2
        (braces lf_typ_declaration)
        LF_parsers.lf_kind
      |> span
      $> fun (location, ((parameter_name, parameter_type), range)) ->
        LF.PiKind { location; parameter_name; parameter_type; range }
    in
    let arr_kind =
      seq2
        (lf_typ_atomic <& token Token.ARROW)
        LF_parsers.lf_kind
      |> span
      $> fun (location, (domain, range)) ->
        LF.ArrKind { location; domain; range }
    in
    choice
      [ label pi_kind "LF Pi kind"
      ; label arr_kind "LF arrow kind"
      ; type_kind
      ]
    |> labelled "LF kind"

  let lf_term =
    choice
      [ lf_term_lam
      ; lf_term_head
      ; lf_term_atomic
      ]
    |> labelled "LF term"

  (** Parses an LF kind or type.
      This is an optimization. In situations where either a type or a
      kind could appear, use this and then match on the `typ_or_kind`
      returned. This is more efficient than backtracking the parser.
   *)
  let lf_kind_or_typ : [ `Kind of LF.kind | `Typ of LF.typ] t =
    let pi =
      seq2
        (braces (seq2 (name <& token Token.COLON) LF_parsers.lf_typ))
        LF_parsers.lf_kind_or_typ
      |> span
      |> labelled "LF Pi kind or type"
      $> fun (location, ((parameter_name, parameter_type), k_or_a)) ->
          match k_or_a with
          | `Kind range ->
            `Kind (LF.PiKind { location; parameter_name; parameter_type; range })
          | `Typ range ->
            `Typ (LF.PiTyp { location; parameter_name; parameter_type; range })
    in
    let arrow =
      seq2
        lf_typ_atomic
        (maybe (token Token.ARROW &> LF_parsers.lf_kind_or_typ))
      |> span
      |> labelled "LF arrow kind or type"
      $> fun (location, (a, k_or_a)) ->
          match k_or_a with
          | Option.None -> `Typ a
          | Option.Some (`Kind k) -> `Kind (LF.ArrKind { location; domain = a; range = k })
          | Option.Some (`Typ a') -> `Typ (LF.ArrTyp { location; domain = a; range = a' })
    in
    choice
      [ pi
      ; type_kind $> (fun a -> `Kind a)
      ; arrow
      ]
    |> labelled "LF kind or type"
end

let lf_kind = LF_parsers.lf_kind
let lf_typ = LF_parsers.lf_typ
let lf_kind_or_typ = LF_parsers.lf_kind_or_typ
let lf_typ_decl = LF_parsers.lf_typ_decl

let hole : string option parser =
  satisfy' (`hole Option.none)
    (function
     | Token.HOLE "" -> Option.some Option.none
     | Token.HOLE s -> Option.some (Option.some s)
     | _ -> Option.none)
  |> labelled "hole"

let rec_block (p : (Name.t * LF.typ) parser) =
  token Token.KW_BLOCK
  &> opt_parens (sep_by1 p (token Token.COMMA))
  |> span
  $> fun (loc, es) ->
     List1.fold_right
       (fun (x, a) -> LF.SigmaLast (Some x, a))
       (fun (x, a) s -> LF.SigmaElem (x, a, s))
       es

module rec Contextual_LF_parsers : sig
  val meta_obj : Comp.meta_obj t
  val contextual : 'a parser -> (LF.dctx * 'a) parser
  val clf_typ : LF.typ t
  val clf_typ_pure : LF.typ t
  val clf_normal : LF.term t
  val clf_dctx : LF.dctx t
  val ctx_variable : (Name.t * LF.ctyp * Plicity.t) t
  val clf_ctyp_decl_bare : 'a name_parser -> ('a -> Plicity.t * Name.t) -> (Name.t * LF.ctyp * Plicity.t) t
  val clf_ctyp_decl : (Name.t * LF.ctyp * Plicity.t) t
  val cltyp : (LF.dctx * typ_or_ctx) t
  val clf_sub_term : LF.sub_start t
end = struct
  let clf_projection : LF.proj parser =
    alt
      (dot_integer $> (fun k -> LF.ByPos k))
      (dot_name $> (fun x -> LF.ByName x))

  (** Parses a sequence of contextual LF normal terms and packages them
      into a TList for infix operator parsing later during indexing.
   *)
  let clf_term_app =
    let normal_list =
      some Contextual_LF_parsers.clf_normal
      |> span
      $> fun (location, terms) -> LF.TList { location; terms }
    in
    choice
      [ normal_list
      ; span Contextual_LF_parsers.clf_typ
        $> (fun (location, typ) -> LF.NTyp { location; typ })
      ]
    |> labelled "contextual LF application"

  let clf_typ_pure_atomic =
    choice
      [ parens Contextual_LF_parsers.clf_typ_pure
      ; seq2 name (many Contextual_LF_parsers.clf_normal)
        |> span
        $> fun (location, (x, ms)) ->
            LF.AtomTerm
              { location
              ; term = LF.TList
                  { location
                  ; terms = LF.Root { location; head = LF.Name (location, x, Option.none); spine = [] }
                    :: ms
                  }
              }
      ]
    |> labelled "atomic return contextual LF type"

  (** Parses an LF function type (uniform pi or arrow). *)
  let lf_function_type =
    let pi =
      seq2 (braces (seq2 (name <& token Token.COLON) Contextual_LF_parsers.clf_typ_pure)) Contextual_LF_parsers.clf_typ_pure
      |> span
      $> fun (location, ((parameter_name, parameter_type), range)) ->
        LF.PiTyp { location; parameter_name; parameter_type; range }
    in
    let arrow =
      seq2 (trying (clf_typ_pure_atomic <& token Token.ARROW)) Contextual_LF_parsers.clf_typ_pure
      |> span
      $> fun (location, (domain, range)) -> LF.ArrTyp { location; domain; range }
    in
    alt pi arrow

  let clf_typ_pure =
    alt
      lf_function_type
      clf_typ_pure_atomic
    |> labelled "return contextual LF type"

  let clf_typ_rec_elem =
    seq2 (name <& token Token.COLON) clf_typ_pure
    |> labelled "contextual LF block element"

  let clf_typ_rec_block =
    rec_block clf_typ_rec_elem
    |> labelled "contextual LF block"

  let clf_typ_atomic =
    let a =
      labelled
        "nonempty sequence of contextual LF normal terms"
        begin
          some Contextual_LF_parsers.clf_normal
          |> span
          $> fun (location, terms) ->
              match terms with
              | [LF.NTyp { typ; _ }] -> typ
              | _ -> LF.AtomTerm { location; term = LF.TList { location; terms } }
        end
    in
    let b =
      seq2
        name
        (many Contextual_LF_parsers.clf_normal)
      |> span
      $> fun (location, (x, ms)) ->
          LF.AtomTerm
            { location
            ; term = LF.TList { location; terms = (LF.Root { location; head = LF.Name (location, x, Option.none); spine = [] }) :: ms }
            }
    in
    choice
      [ a
      ; b
      ; parens Contextual_LF_parsers.clf_typ
      ; clf_typ_rec_block |> span $> (fun (location, block) -> LF.Sigma { location; block })
      ]
    |> labelled "atomic contextual LF type"

  let clf_typ =
    let pi_decl =
      seq2
        (name <& token Token.COLON)
        Contextual_LF_parsers.clf_typ
      |> braces
    in
    let pi =
      seq2
        (pi_decl <& maybe (token Token.ARROW))
        Contextual_LF_parsers.clf_typ
      |> span
      $> fun (location, ((parameter_name, parameter_type), range)) ->
          LF.PiTyp { location; parameter_name; parameter_type; range }
    in
    let arrow_or_atomic =
      seq2
        clf_typ_atomic
        (maybe (token Token.ARROW &> Contextual_LF_parsers.clf_typ))
      |> span
      $> fun (location, (a, b)) ->
          match b with
          | Option.None -> a
          | Option.Some b -> LF.ArrTyp { location; domain = a; range = b }
    in
    choice [ pi; arrow_or_atomic ]
    |> labelled "contextual LF type"

  let clf_sub_new =
    let start =
      alt
        (Contextual_LF_parsers.clf_sub_term
          $> fun t -> (t, []))
        (span clf_term_app
          $> fun (loc, tM) -> (LF.EmptySub loc, [tM]))
    in
    let nonemptysub =
      seq2 start (many (token Token.COMMA &> clf_term_app))
      (* we need to reverse xs because the *rightmost* element
          (textually) must be the head of the list.
          This is also why ts comes after xs, despite being *parsed*
          before!
        *)
      $> fun ((s, ts), xs) -> (s, List.rev xs @ ts)
    in
    let emptysub =
      span (return ()) $> fun (loc, ()) -> (LF.EmptySub loc, [])
    in
    alt nonemptysub emptysub
    |> labelled "contextual LF substitution"

  let clf_sub_term =
    choice
      [ token Token.HAT |> span $> (fun (loc, ()) -> LF.EmptySub loc)
      ; token Token.DOTS |> span $> (fun (loc, ()) -> LF.Id loc)
      ; seq2
          dollar_name
          (maybe (bracks clf_sub_new))
        |> span
        $> fun (loc, (x, s)) -> LF.SVar (loc, x, s)
      ]
    |> labelled "contextual LF substitution term"

  let clf_head =
    let var =
      seq3
        (alt
            (hash_name $> fun x -> fun loc sigma -> LF.PVar (loc, x, sigma))
            (fqname $> fun x -> fun loc sigma -> LF.Name (loc, x, sigma)))
        (maybe clf_projection)
        (maybe (bracks clf_sub_new))
      |> shifted "variable head"
      |> span
      $> fun (loc, (f, proj, sigma)) ->
          let m = f loc sigma in
          match proj with
          | Option.Some k -> LF.Proj (loc, m, k)
          | Option.None -> m
    in
    let hole =
      token Token.UNDERSCORE
      |> span
      $> fun (loc, ()) -> LF.Hole loc
    in
    choice [hole ; var]

  let clf_normal =
    let lam =
      seq2
        (token Token.LAMBDA &> name)
        (token Token.DOT &> clf_term_app)
      |> span
      |> labelled "LF lambda"
      $> fun (location, (parameter_name, body)) ->
          LF.Lam { location; parameter_name; body }
    in
    (*
    let modul =
      span fqname $> fun (loc, x) -> LF.Root (loc, LF.Name (loc, x), LF.Nil)
    in
      *)
    let head =
      span clf_head
      $> fun (location, head) -> LF.Root { location; head; spine = [] }
    in
    let app =
      seq2
        clf_term_app
        (maybe (token Token.COLON &> clf_typ))
      |> parens
      |> span
      |> labelled "LF application"
      $> fun (location, (term, typ_opt)) ->
          match typ_opt with
          | Option.None -> term
          | Option.Some typ -> LF.Ann { location; term; typ }
    in
    let lfhole =
      span hole
      |> labelled "LF hole"
      $> fun (location, label) -> LF.LFHole { location; label }
    in
    let tuple =
      sep_by1 clf_term_app (token Token.SEMICOLON)
      |> angles
      |> span
      |> labelled "LF tuple"
      $> fun (location, ms) ->
          LF.Tuple
            { location
            ; tuple = ms
            }
    in
    choice
      [ lam
      (* ; modul *) (* modules are wacky *)
      ; app
      ; head
      ; lfhole
      ; tuple
      ]
    |> labelled "contextual LF normal term"

  (** Parses an LF context, commonly referred to by cPsi.
      This parser allows declarations without a type; if you require
      that all declarations give a type, then separately validate the
      context after.
   *)
  let clf_dctx : LF.dctx parser =
    let clf_typ_decl =
      seq2
        name
        (maybe (token Token.COLON &> clf_typ))
      $> fun (x, tA) ->
          match tA with
          | Option.Some tA -> LF.TypDecl (x, tA)
          | Option.None -> LF.TypDeclOpt x
    in
    (* the different ways a context can begin:
        a hole, a variable, or a declaration
      *)
    let start =
      choice
        [ token Token.UNDERSCORE &> return LF.CtxHole
        ; span clf_typ_decl
          $> fun (loc, d) ->
              (* This is nasty. XXX
                We need this to handle context variables, which are
                syntactically indistinguishable from a concrete
                context beginning with a variable whose type is
                omitted (to be solved by unification later).
                A better way to do this would be to change, in the
                external syntax, the type `dctx` to be something like
                ```
                type dctx_start = Null | CtxHole
                type dctx = dctx_start * typ_decl list
                ```
                The empty context would be `(Null, [])`.
                A context like `g, x:tm` would be `(Null, [TypDeclOpt g; TypDecl (x, tm)])`
                A disambiguation would be performed during indexing in the case of a context that
                - begins with Null; and
                - whose first entry is a TypDeclOpt that refers to a context variable.
                This would be transformed into a proper context
                beginning with a context variable in the approximate
                syntax.
              *)
              match d with
              | LF.TypDeclOpt x -> LF.CtxVar (loc, x)
              | _ -> LF.DDec (LF.Null, d)

        ]
    in
    choice
      [ seq2
          start
          (many (token Token.COMMA &> clf_typ_decl))
        $> (fun (cPsi, ds) ->
          List.fold_left (fun acc d -> LF.DDec (acc, d)) cPsi ds)
      ; return LF.Null
      ]
    |> labelled "contextual LF context"

  (** Parses
      `[ dctx |- p ]`
      Since this is pretty common for various choices of `p`.
      Returns the parse of the dctx and p in a tuple.
   *)
  let contextual : type a. a parser -> (LF.dctx * a) parser =
    fun p ->
    seq2
      (clf_dctx <& token Token.TURNSTILE)
      p

  let meta_obj =
    let clobj =
      seq2
        clf_dctx
        (maybe (token Token.TURNSTILE &> clf_sub_new))
      |> span
      $> fun (loc, (cPsi, tR)) ->
          match tR with
          | Option.Some tR -> (loc, LF.ClObj (cPsi, tR))
          | Option.None -> (loc, LF.CObj cPsi)
    in
    clobj
    |> bracks
    |> labelled "meta object"


  (** Parses a variable declaration for a contextual type.
      `name : [ dctx |- p ]`
      Note that this doesn't include the braces around the declaration!
      The shape of the box is configurable via the `box` parameter.
   *)
  let contextual_variable_decl
        (name : 'name t) (box : (LF.dctx * 'a) t -> 'b t) (p : 'a t)
      : ('name * 'b) t =
    seq2
      (name <& token Token.COLON)
      (box (contextual p))

  let cltyp : (LF.dctx * typ_or_ctx) parser =
    labelled "boxed type"
      begin
        let typ =
          contextual clf_typ_atomic
          |> bracks
          $> fun (cPsi, a) ->
             (cPsi, `Typ a)
        in
        let ctx =
          contextual clf_dctx
          |> bracks
          $> fun (cPsi, cPhi) ->
             (cPsi, `Ctx cPhi)
        in
        alt
          (label typ "proper contextual type")
          (label ctx "contextual context type")
      end

  let clf_ctyp_decl_bare =
    fun nameclass plicity_of_name ->
      let hash_variable_decl p =
        contextual_variable_decl
          (nameclass `hash)
          (sigil_bracks_or_opt_parens Token.HASH)
          p
      in
      let dollar_variable_decl p =
        contextual_variable_decl
          (nameclass `dollar)
          (sigil_bracks_or_opt_parens Token.DOLLAR)
          p
      in
      let param_variable =
        hash_variable_decl (trying clf_typ_atomic)
        |> span
        $> (fun (loc, (nb, (cPsi, tA))) ->
              let plicity, x = plicity_of_name nb in
              (x, LF.ClTyp (loc, LF.PTyp tA, cPsi), plicity)
        )
        |> labelled "parameter variable declaration"
      in
      let subst_variable =
        let subst_class =
          maybe (token Token.HASH)
          $> Option.eliminate (Fun.const LF.Subst) (Fun.const LF.Ren)
        in
        dollar_variable_decl (seq2 subst_class clf_dctx)
        |> span
        $> (fun (loc, (nb, (cPsi, (sclass, cPhi)))) ->
              let plicity, x = plicity_of_name nb in
              (x, LF.ClTyp (loc, LF.STyp (sclass, cPhi), cPsi), plicity)
        )
        |> labelled "substitution/renaming variable"
      in
      choice
        [ param_variable
        ; subst_variable
        (* since a name followed by a colon happens in both
            the case for an mvar and the case for a context
            variable, we refactor the grammar to parse first the
            name followed by the colon, and *then* we perform an
            alternation to see whether we have another name (so
            a ctx var) or a box (so an mvar)
          *)
        ; nameclass `ordinary <& token Token.COLON |> span
          >>= fun (loc1, nb) ->
            let plicity, x = plicity_of_name nb in
            alt
              (span name
                $> fun (loc2, ctx) ->
                  let loc = Location.join loc1 loc2 in
                  (x, LF.CTyp (loc, ctx), plicity))
              (bracks_or_opt_parens (contextual clf_typ_atomic) |> span
                $> fun (loc2, (cPsi, tA)) ->
                  let loc = Location.join loc1 loc2 in
                  (x, LF.ClTyp (loc, LF.MTyp tA, cPsi), plicity))
        ]

  (* parses `name : name` *)
  let ctx_variable =
    labelled "context variable declaration"
      begin
        seq2
          (trying (name <& token Token.COLON))
          (name <& not_followed_by meta_obj)
        |> span
        $> fun (loc, (p, w)) -> (p, LF.CTyp (loc, w), Plicity.implicit)
      end

  (** Contextual LF contextual type declaration *)
  let clf_ctyp_decl =
    (* Parses `#name : [ dctx |- p ]` *)
    let hash_variable_decl p =
      contextual_variable_decl hash_name bracks_or_opt_parens p
    in
    let dollar_variable_decl p =
      contextual_variable_decl dollar_name bracks_or_opt_parens p
    in
    let param_variable =
      labelled "parameter variable declaration"
        begin
          hash_variable_decl (trying clf_typ_atomic)
          |> span
          $> fun (loc, (p, (cPsi, tA))) ->
               (p, LF.ClTyp (loc, LF.PTyp tA, cPsi), Plicity.explicit)
        end
    in
    let subst_variable =
      let subst_class =
        maybe (token Token.HASH)
        $> Option.eliminate (Fun.const LF.Subst) (Fun.const LF.Ren)
      in
      labelled "substitution/renaming variable"
        begin
          dollar_variable_decl (seq2 subst_class clf_dctx)
          |> span
          $> fun (loc, (p, (cPsi, (sclass, cPhi)))) ->
               (p, LF.ClTyp (loc,  LF.STyp (sclass, cPhi), cPsi), Plicity.explicit)
        end
    in
    let q =
      choice
        [ param_variable
        ; subst_variable
        (* since a name followed by a colon happens in both
            the case for an mvar and the case for a context
            variable, we refactor the grammar to parse first the
            name followed by the colon, and *then* we perform an
            alternation to see whether we have another name (so
            a ctx var) or a box (so an mvar)
          *)
        ; name <& token Token.COLON |> span
          >>= fun (loc1, x) ->
            alt
              (span name
                $> fun (loc2, ctx) ->
                     let loc = Location.join loc1 loc2 in
                     (x, LF.CTyp (loc, ctx), Plicity.explicit))
              (bracks_or_opt_parens (contextual clf_typ_atomic)
                |> span
                $> fun (loc2, (cPsi, tA)) ->
                     let loc = Location.join loc1 loc2 in
                     (x, LF.ClTyp (loc, LF.MTyp tA, cPsi), Plicity.explicit))
        ]
      |> braces
    in
    labelled "contextual type declaration"
      (alt (parens ctx_variable) q)
end

let meta_obj = Contextual_LF_parsers.meta_obj
let contextual = Contextual_LF_parsers.contextual
let clf_normal = Contextual_LF_parsers.clf_normal
let clf_dctx = Contextual_LF_parsers.clf_dctx
let ctx_variable = Contextual_LF_parsers.ctx_variable
let clf_ctyp_decl_bare = Contextual_LF_parsers.clf_ctyp_decl_bare
let clf_ctyp_decl = Contextual_LF_parsers.clf_ctyp_decl
let cltyp = Contextual_LF_parsers.cltyp

let mctx ?(sep = token Token.COMMA) p =
  sep_by0 p sep
  $> Context.of_list_rev

module rec Comp_parsers : sig
  val cmp_kind : Comp.kind t
  val cmp_typ : Comp.typ t
  val cmp_typ_cross : Comp.typ t
  val cmp_pattern : Comp.pattern t
  val cmp_exp_chk : Comp.exp t
  val cmp_exp_syn : Comp.exp t
  val gctx : Comp.gctx t
end = struct
  let pibox p r f =
    seq2
      (p <& maybe (token Token.ARROW))
      r
    |> span
    $> fun (loc, (ctyp_decl, x)) ->
       f loc ctyp_decl x

  let arrow atomic r f =
    seq2
      (trying (atomic <& token Token.ARROW))
      r
    |> span
    $> fun (loc, (a1, a2)) -> f loc a1 a2

    let cmp_typ_atomic : Comp.typ parser =
      let base =
        labelled "base computation type"
          (seq2 name (many meta_obj)
            |> span
            $> fun (location, (head, spine)) ->
              Comp.TypBase { location; head; spine })
      in
      let pbox =
        token Token.HASH
        &> bracks (contextual (some clf_normal |> span))
        |> span
        $> fun (location, (cPsi, (location', terms))) ->
            let typ =
              LF.ClTyp
                ( location
                , LF.PTyp (LF.AtomTerm { location; term = LF.TList { location = location'; terms } })
                , cPsi
                )
            in
            Comp.TypBox { location; typ }
      in
      let sub =
        token Token.DOLLAR
        &> bracks (contextual clf_dctx)
        |> span
        $> fun (location, (cPsi, cPhi)) ->
            let typ =
              LF.ClTyp
                ( location
                , LF.STyp (LF.Subst, cPhi), cPsi
                )
            in
            Comp.TypBox { location; typ }
      in
      let ctx =
        span fqname
        $> fun (location, schema) ->
            Comp.TypBox { location; typ = LF.CTyp (location, schema) }
      in
      let ordinary =
        seq2
          (trying (clf_dctx <& token Token.TURNSTILE))
          (some clf_normal)
        |> span
        |> labelled "boxed type"
        $> fun (location, (cPsi, terms)) ->
            let typ =
              LF.ClTyp
                ( location
                , LF.MTyp
                  (LF.AtomTerm { location; term = LF.TList { location; terms } })
                , cPsi
                )
            in
            Comp.TypBox { location; typ }
      in
      choice
        [ base
        ; ctx
        ; pbox
        ; sub
        ; bracks (alt ordinary ctx)
        ; parens Comp_parsers.cmp_typ
        ]
      |> labelled "atomic computation type"

  let cmp_typ_cross =
    seq2
      cmp_typ_atomic
      (many (token Token.STAR &> Comp_parsers.cmp_typ_cross))
    |> span
    |> labelled "computation product type"
    $> fun (location, (tau1, taus)) ->
        match taus with
        | [] -> tau1
        | tau2 :: taus -> Comp.TypCross { location; typs = List2.from tau1 tau2 taus }

  let cmp_typ =
    let ctx_pibox =
      labelled "Context variable Pi-box type"
        (pibox (ctx_variable |> parens) Comp_parsers.cmp_typ
            (fun location (parameter_name, parameter_type, plicity) range ->
              Comp.TypPiBox { location; parameter_name; parameter_type; plicity; range }))
    in
    let pibox =
      labelled "Pi-box type"
        (pibox (clf_ctyp_decl_bare name' (fun x -> Plicity.explicit, x) |> braces) Comp_parsers.cmp_typ
            (fun location (parameter_name, parameter_type, plicity) range ->
              Comp.TypPiBox { location; parameter_name; parameter_type; plicity; range }))
    in
    let arr =
      labelled "Arrow computation type"
        (arrow cmp_typ_cross Comp_parsers.cmp_typ
            (fun location domain range -> Comp.TypArr { location; domain; range }))
    in
    choice
      [ pibox
      ; ctx_pibox
      ; arr
      ; cmp_typ_cross
      ]
    |> labelled "computation type"

  (** Parses the `ctype` kind, the kind of computation types. *)
  let ctype_kind =
    token Token.KW_CTYPE |> span
    $> fun (location, ()) -> Comp.Ctype { location }

  let cmp_kind =
    let pibox =
      labelled "Pi-box kind"
        begin
          seq2
            (trying (clf_ctyp_decl <& maybe (token Token.ARROW)))
            Comp_parsers.cmp_kind
          |> span
          $> fun (location, ((parameter_name, parameter_type, plicity), range)) ->
              (* XXX the ctyp_decl must be for an ordinary box-type. *)
              Comp.PiKind { location; parameter_name; parameter_type; plicity; range }
        end
    in
    let arrow =
      labelled "arrow kind"
        begin
          seq2
            (trying (cltyp <& token Token.ARROW) |> span)
            Comp_parsers.cmp_kind
          |> span
          $> fun (location, ((loc', (cPsi, a)), range)) ->
              let domain =
                LF.ClTyp
                  ( loc'
                  , begin match a with
                    | `Ctx cPhi -> LF.STyp (LF.Subst, cPhi)
                    | `Typ a -> LF.MTyp a
                    end
                  , cPsi
                  )
              in
              Comp.ArrKind { location; domain; range }
        end
    in
    choice
      [ ctype_kind
      ; pibox
      ; arrow
      ]
    |> labelled "computation kind"

  let cmp_pattern_atomic =
    let mobj_pat =
      span meta_obj
      |> labelled "meta object pattern"
      $> fun (location, obj) -> Comp.PatMetaObj { location; obj }
    in
    let nested (* `(' p (, p)* `)' *) =
      span (parens (seq2 Comp_parsers.cmp_pattern (many (token Token.COMMA &> Comp_parsers.cmp_pattern))))
      $> (fun (location, (p1, ps)) ->
        match ps with
        | [] -> p1
        | p2 :: ps -> Comp.PatTuple { location; patterns = List2.from p1 p2 ps })
      |> labelled "parenthesized or tuple pattern"
    in
    let var =
      name
      |> span
      |> labelled "variable pattern"
      $> fun (location, name) -> Comp.PatName { location; name }
    in
    choice
      [ mobj_pat
      ; nested
      ; var
      ]
    |> labelled "bare pattern"

  let cmp_pattern =
    let app =
      seq2
        (span name)
        (many cmp_pattern_atomic)
      |> span
      |> labelled "variable or inductive type pattern"
      $> fun (location, ((location', name), spine)) ->
           let pat_name = Comp.PatName { location = location'; name } in
         Comp.RawPatApplication { location; patterns = List1.from pat_name spine }
    in
    let pattern = alt app cmp_pattern_atomic in
    seq2
      pattern
      (maybe (token Token.COLON &> cmp_typ))
    |> labelled "possibly annotated pattern"
    |> span
    $> fun (location, (pattern, typ)) ->
        match typ with
        | Option.None -> pattern
        | Option.Some typ -> Comp.PatAnn { location; pattern; typ }

  let cmp_copat_spine =
    let go (* TODO: Incomplete, address when rewriting the parser *) =
      dot_name
      |> span
      |> labelled "observation pattern"
      $> (fun (location, name) -> Comp.PatObs { location; name })
    in
    seq2
      (go <& token Token.THICK_ARROW)
      Comp_parsers.cmp_exp_chk
    |> shifted "copattern spine"

  let cmp_branch =
    seq3
      (mctx ~sep: (return ()) (clf_ctyp_decl_bare name' (fun x -> Plicity.explicit, x) |> braces $> (fun (name, typ, plicity) -> LF.Decl (name, typ, plicity))))
      cmp_pattern
      (token Token.THICK_ARROW &> Comp_parsers.cmp_exp_chk)
    |> span
    |> labelled "case branch"
    $> fun (location, (mctx, pattern, body)) ->
        Comp.Branch { location; mctx; pattern; body }

  (** Parses a return checkable computation term,
      i.e. a checkable term *except* for applications.
   *)
  let cmp_exp_chk' =
    let abstraction param c =
      seq2
        (sep_by1 param (token Token.COMMA) $> List1.to_list)
        (token Token.THICK_ARROW &> Comp_parsers.cmp_exp_chk)
      |> span
      $> fun (loc, (params, i)) ->
          List.fold_left
            (fun acc f -> c loc f acc) i (List.rev params)
    in
    let fn =
      token Token.KW_FN
      &> abstraction name
            (fun location parameter_name body -> Comp.Fn { location; parameter_name; body })
      |> labelled "ordinary function abstraction"
    in
    let mlam =
      token Token.KW_MLAM
      &> abstraction (choice [hash_name; dollar_name; name])
            (fun location parameter_name body -> Comp.MLam { location; parameter_name; body })
      |> labelled "meta function abstraction"
    in
    let matching_fun =
      token Token.KW_FUN
      &> maybe (token Token.PIPE)
      &> sep_by1 (span cmp_copat_spine) (token Token.PIPE)
      |> span
      |> labelled "copattern abstraction"
      $> fun (location, branches) ->
          let branches' =
            List1.map
              (fun (location, (pattern, body)) ->
                Comp.Branch { location; mctx = LF.Empty; pattern; body })
              branches
          in
          Comp.Fun { location; branches = branches' }
    in
    let case =
      let check_exhaustiveness =
        maybe_default
          (pragma "not" &> return false)
          ~default:true
      in
      seq3
        (token Token.KW_CASE &> Comp_parsers.cmp_exp_syn)
        (token Token.KW_OF &> check_exhaustiveness)
        (maybe (token Token.PIPE) &> sep_by1 cmp_branch (token Token.PIPE))
      |> span
      |> labelled "case expression"
      $> fun (location, (scrutinee, check_exhaustiveness, branches)) ->
          Comp.Case { location; check_exhaustiveness; scrutinee; branches }
    in
    let impossible =
      token Token.KW_IMPOSSIBLE
      &> Comp_parsers.cmp_exp_syn
      |> span
      $> fun (location, expression) -> Comp.Impossible { location; expression }
    in
    let lets =
      let let_pattern =
        seq4
          (mctx ~sep: (return ()) (clf_ctyp_decl_bare name' (fun x -> Plicity.explicit, x) |> braces $> (fun (name, typ, plicity) -> LF.Decl (name, typ, plicity))))
          (cmp_pattern <& token Token.EQUALS)
          (Comp_parsers.cmp_exp_syn <& token Token.KW_IN)
          Comp_parsers.cmp_exp_chk
        |> span
        $> fun (location, (mctx, pattern, scrutinee, body)) ->
            let branch = Comp.Branch { location; mctx; pattern; body } in
            Comp.Case { location; check_exhaustiveness = true; scrutinee; branches = List1.singleton branch}
      in
      token Token.KW_LET
      (* XXX
          there is ambiguity between let_exp and let_pattern, in
          particular because exp is a proper subclass of pattern:
          i.e. a variable is a valid pattern.
          Furthermore, there is no syntactic way we can tell,
          since variables may be any case.
          During parsing, we will prioritize let_pattern, and during
          indexing, when we have scoping information, we will
          disambiguate.
          -je
        *)
      &> let_pattern
    in
    let nested (* `(' e (, e)* `)' *) =
      span (parens (seq2 Comp_parsers.cmp_exp_chk (many (token Token.COMMA &> Comp_parsers.cmp_exp_chk))))
      $> (fun (location, (p1, ps)) ->
        match ps with
        | [] -> p1
        | p2 :: ps -> Comp.Tuple { location; expressions = List2.from p1 p2 ps })
      |> labelled "parenthesized or tuple checkable expression"
    in
    let hole =
      hole |> span $> fun (location, label) -> Comp.Hole { location; label } in
    let box_hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> Comp.BoxHole { location })
    in
    let meta_obj =
      meta_obj
      |> span
      $> fun (location, obj) -> Comp.Box { location; obj }
    in
    choice
      [ fn (* fn introduction form *)
      ; mlam (* mlam introduction form *)
      ; matching_fun (* generalized fun form *)
      ; case (* case expression *)
      ; impossible (* empty case expression *)
      ; nested (* an expression nested in parens or a tuple *)
      ; hole
      ; box_hole
      ; meta_obj
      ; lets (* let expressions: true let and pattern let *)
      ]

  (** Parses a synthesizable expression except applications. *)
  let cmp_exp_syn' =
    let meta_obj =
      meta_obj
      |> span
      |> labelled "synthesizable box"
      $> fun (location, obj) -> Comp.Box { location; obj }
    in
    let nested (* `(' i (, i)* `)' *) =
      span (parens (seq2 Comp_parsers.cmp_exp_syn (many (token Token.COMMA &> Comp_parsers.cmp_exp_syn))))
      $> (fun (location, (p1, ps)) ->
        match ps with
        | [] -> p1
        | p2 :: ps -> Comp.Tuple { location; expressions = List2.from p1 p2 ps })
      |> labelled "parenthesized or tuple synthesizable expression"
    in
    let name =
      fqname
      |> span
      |> labelled "computation variable or constructor"
      $> fun (location, name) -> Comp.Name { location; name }
    in
    choice
      [ name
      ; meta_obj
      ; nested
      ]

  (** Parses a purely checkable expression or an atomic
      (non-application) synthesizable expression.
   *)
  let cmp_exp_chk'' =
    choice
      [ cmp_exp_chk'
      ; cmp_exp_syn'
      ]

  (** Parses a synthesizable expression *)
  let cmp_exp_syn =
    seq2
      cmp_exp_syn'
      (many (span cmp_exp_chk''))
    |> span
    $> fun (loc, (i, es)) ->
        let rec fold i es =
          match es with
          | [] -> i
          | (loc', e) :: es ->
            let location = Location.join loc loc' in
            let i = Comp.Apply { location; applicand = i; argument = e } in
            fold i es
        in
        fold i es

  (** Parses a checkable computation term *)
  let cmp_exp_chk =
    choice
      [ cmp_exp_chk'
      ; cmp_exp_syn
      ]

  (** Parses `x : tau`. *)
  let cmp_ctyp_decl =
    seq2 (name <& token Token.COLON) cmp_typ
    |> labelled "computational type declaration"
    $> fun (x, tau) -> Comp.CTypDecl (x, tau)

  let gctx =
    sep_by0 cmp_ctyp_decl (token Token.COMMA)
    $> Context.of_list_rev
end

let cmp_kind = Comp_parsers.cmp_kind
let cmp_typ = Comp_parsers.cmp_typ
let cmp_exp_chk = Comp_parsers.cmp_exp_chk
let cmp_exp_syn = Comp_parsers.cmp_exp_syn
let gctx = Comp_parsers.gctx

module rec Harpoon_parsers : sig
  val harpoon_proof : Comp.proof t
  val interactive_harpoon_command : Harpoon.command t
  val interactive_harpoon_command_sequence : Harpoon.command list t
  val next_theorem : [> `next of Name.t | `quit ] t
end = struct
  let boxity =
    choice
      [ keyword "boxed" &> return `boxed
      ; keyword "unboxed" &> return `unboxed
      ; keyword "strengthened" &> return `strengthened
      ]

  let harpoon_command : Comp.command t =
    let by =
      token Token.KW_BY &>
        seq3
          (cmp_exp_syn <& token Token.KW_AS)
          name
          (maybe_default boxity ~default:`boxed)
      |> span
      |> labelled "Harpoon command"
      $> fun (loc, (i, x, b)) ->
         match b with
         | `boxed -> Comp.By (loc, i, x)
         | `unboxed -> Comp.Unbox (loc, i, x, Option.none)
         | `strengthened -> Comp.Unbox (loc, i, x, Option.some `strengthened)
    in
    let unbox =
      keyword "unbox" &>
        seq2
          ((span cmp_exp_syn) <& token Token.KW_AS)
          name
      $> fun ((loc, i), x) -> Comp.Unbox (loc, i, x, Option.none)
    in
    let strengthen =
      keyword "strengthend" &>
        seq2
          (span cmp_exp_syn <& token Token.KW_AS)
          name
      $> fun ((loc, i), x) -> Comp.Unbox (loc, i, x, Option.some `strengthened)
    in
    choice [ by; unbox; strengthen ]

  let case_label : Comp.case_label parser =
    let extension_case_label =
      trying (keyword "extended" &> token Token.KW_BY) &> integer
      |> span
      |> labelled "context extension case label"
      $> fun (loc, n) -> Comp.(ContextCase (ExtendedBy (loc, n)))
    in
    let empty_case_label =
      trying (keyword "empty" &> keyword "context")
      |> span
      |> labelled "empty context case label"
      $> fun (loc, ()) -> Comp.(ContextCase (EmptyContext loc))
    in
    let named_case_label =
      name
      |> span
      |> labelled "constructor case label"
      $> fun (loc, name) -> Comp.NamedCase (loc, name)
    in
    let pvar_case_label =
      token Token.HASH &>
        seq2
          (maybe_default integer ~default:1)
          (maybe dot_integer)
      |> span
      |> labelled "parameter variable case label"
      $> fun (loc, (n, k)) -> Comp.PVarCase (loc, n, k)
    in
    let bvar_case_label =
      trying (keyword "head" &> keyword "variable")
      |> span
      $> fun (loc, ()) -> Comp.BVarCase loc
    in
    choice
      [ bvar_case_label
      ; extension_case_label
      ; empty_case_label
      ; named_case_label
      ; pvar_case_label
      ]

  let harpoon_hypothetical : Comp.hypothetical parser =
    let open Comp in
    let hypotheses =
      seq2
        (mctx (clf_ctyp_decl_bare name_or_blank' plicity_name_of_nb $> (fun (name, typ, plicity) -> LF.Decl (name, typ, plicity))) <& token Token.PIPE)
        gctx
      $> fun (cD, cG) -> { cD; cG }
    in
    seq2
      (hypotheses <& token Token.SEMICOLON)
      Harpoon_parsers.harpoon_proof
    |> braces
    |> span
    |> labelled "Harpoon hypothetical"
    $> fun (hypothetical_loc, (hypotheses, proof)) ->
        { hypotheses; proof; hypothetical_loc }

  let harpoon_split_branch : Comp.split_branch parser =
    token Token.KW_CASE &>
      seq2
        (case_label <& token Token.COLON)
        harpoon_hypothetical
    |> span
    |> labelled "Harpoon split branch"
    $> fun (split_branch_loc, (case_label, branch_body)) ->
        let open Comp in
        { case_label; branch_body; split_branch_loc }

  let harpoon_directive : Comp.directive parser =
    choice
      [ keyword "intros"
        &> harpoon_hypothetical
        |> span
        $> (fun (loc, h) -> Comp.Intros (loc, h))
      ; keyword "solve"
        &> cmp_exp_chk
        |> span
        $> (fun (loc, e) -> Comp.Solve (loc, e))
      ; keyword "split"
        &> seq2
              (cmp_exp_syn <& token Token.KW_AS)
              (many harpoon_split_branch)
        |> span
        $> (fun (loc, (i, bs)) -> Comp.Split (loc, i, bs))
      ; token Token.KW_IMPOSSIBLE
        &> cmp_exp_syn
        |> span
        $> (fun (loc, i) -> Comp.Split (loc, i, []))
      ; let suffices_arg =
          seq2 cmp_typ (Harpoon_parsers.harpoon_proof |> braces)
          |> span
          $> fun (loc, (tau, p)) -> (loc, tau, p)
        in
        tokens Token.[KW_SUFFICES; KW_BY] &>
          seq2
            (cmp_exp_syn <& token Token.KW_TOSHOW)
            (many suffices_arg)
        |> span
        $> (fun (loc, (i, args)) -> Comp.Suffices (loc, i, args))
      ]
    |> shifted "Harpoon directive"

  let harpoon_proof : Comp.proof parser =
    let incomplete_proof =
      hole
      |> span
      |> labelled "Harpoon incomplete proof `?'"
      $> fun (loc, h) -> Comp.Incomplete (loc, h)
    in
    let command_proof =
      seq2
        (harpoon_command <& token Token.SEMICOLON)
        Harpoon_parsers.harpoon_proof
      |> span
      $> fun (loc, (cmd, prf)) -> Comp.Command (loc, cmd, prf)
    in
    let directive_proof =
      harpoon_directive
      |> span
      $> fun (loc, d) -> Comp.Directive (loc, d)
    in
    choice
      [ incomplete_proof
      ; command_proof
      ; directive_proof
      ]
    |> labelled "Harpoon proof"

  let interactive_harpoon_command : Harpoon.command t =
    let intros =
      keyword "intros"
      &> maybe (some identifier)
      $> fun xs -> Harpoon.Intros xs
    in
    let split =
      keyword "split"
      &> cmp_exp_syn
      $> fun t -> Harpoon.Split (`split, t)
    in
    let msplit =
      keyword "msplit"
      &> span (choice [ dollar_name; hash_name; name ])
      $> fun (loc, name) -> Harpoon.MSplit (loc, name)
    in
    let invert =
      keyword "invert"
      &> cmp_exp_syn
      $> fun t -> Harpoon.Split (`invert, t)
    in
    let impossible =
      token Token.KW_IMPOSSIBLE
      &> cmp_exp_syn
      $> fun t -> Harpoon.Split (`impossible, t)
    in
    let solve =
      keyword "solve"
      &> cmp_exp_chk
      $> fun t -> Harpoon.Solve t
    in
    let auto_invert_solve =
      keyword "auto-invert-solve"
      &> maybe integer
      $> fun n -> H.AutoInvertSolve n
    in
    let inductive_auto_solve =
      keyword "inductive-auto-solve"
      &> maybe integer
      $> fun n -> H.InductiveAutoSolve n
    in
    let by =
      token Token.KW_BY &>
        seq3
          cmp_exp_syn
          (token Token.KW_AS &> name)
          (maybe_default boxity ~default:`boxed)
      $> fun (i, name, b) ->
        match b with
        | `strengthened -> Harpoon.Unbox (i, name, Option.some `strengthened)
        | `unboxed -> Harpoon.Unbox (i, name, Option.none)
        | `boxed -> Harpoon.By (i, name)
    in
    let compute_type =
      token Token.KW_TYPE
      &> cmp_exp_syn
      $> fun i -> Harpoon.Type i
    in
    let suffices =
      let tau_list_item =
        alt
          (cmp_typ $> fun tau -> `exact tau)
          (token Token.UNDERSCORE |> span $> fun (loc, ()) -> `infer loc)
      in
      seq2
        (tokens [Token.KW_SUFFICES; Token.KW_BY]
        &> cmp_exp_syn)
        (token Token.KW_TOSHOW
        &> sep_by0 tau_list_item (token Token.COMMA))
      $> fun (i, tau_list) ->
        Harpoon.Suffices (i, tau_list)
    in
    let unbox =
      keyword "unbox" &>
        seq2
          cmp_exp_syn
          (token Token.KW_AS &> name)
      $> fun (i, name) -> Harpoon.Unbox (i, name, Option.none)
    in
    let strengthen =
      keyword "strengthen" &>
        seq2
          cmp_exp_syn
          (token Token.KW_AS &> name)
      $> fun (i, name) -> Harpoon.Unbox (i, name, Option.some `strengthened)
    in
    let automation_kind =
      choice
        [ keyword "auto-intros" &> return `auto_intros
        ; keyword "auto-solve-trivial" &> return `auto_solve_trivial
        ]
    in
    let automation_change =
      choice
        [ keyword "on" &> return `on
        ; keyword "off" &> return `off
        ; keyword "toggle" &> return `toggle
        ]
    in
    let toggle_automation =
      keyword "toggle-automation"
      &> seq2 automation_kind (maybe_default automation_change ~default:`toggle)
      $> fun (t, c) -> Harpoon.ToggleAutomation (t, c)
    in
    let rename =
      let level =
        choice
          [ keyword "comp" &> return `comp
          ; keyword "meta" &> return `meta
          ]
      in
      keyword "rename"
      &> seq3 level name name
      $> fun (level, rename_from, rename_to) ->
        Harpoon.Rename { rename_from; rename_to; level }
    in
    let basic_command =
      choice
        [ keyword "list" &> return `list
        ; keyword "defer" &> return `defer
        ]
    in
    let select_theorem =
      keyword "select" &> name $> fun x -> Harpoon.SelectTheorem x
    in
    let create_command, serialize_command =
      ( keyword "create" &> return `create
      , keyword "serialize" &> return `serialize
      )
    in
    let theorem_command =
      let dump_proof =
        keyword "dump-proof"
        &> string_literal
        $> fun s -> `dump_proof s
      in
      keyword "theorem" &>
        choice
          ( basic_command
            :: dump_proof
            :: List.map (fun (k, k') -> keyword k &> return k')
                [ ("show-ihs", `show_ihs)
                ; ("show-proof", `show_proof)
                ]
          )
      $> fun cmd -> Harpoon.Theorem cmd
    in
    let session_command =
      keyword "session"
      &> choice [ basic_command; create_command; serialize_command ]
      $> fun cmd -> Harpoon.Session cmd
    in
    let subgoal_command =
      keyword "subgoal"
      &> basic_command
      $> fun cmd -> Harpoon.Subgoal cmd
    in
    let defer =
      keyword "defer" &> return (Harpoon.Subgoal `defer)
    in
    let info_kind =
      choice
        [ keyword "theorem" &> return `prog
        ]
    in
    let info =
      keyword "info"
      &> seq2 info_kind name
      $> fun (k, name) -> Harpoon.Info (k, name)
    in
    let translate =
      keyword "translate"
      &> name
      $> fun name -> Harpoon.Translate name
    in
    let undo = keyword "undo" &> return Harpoon.Undo in
    let redo = keyword "redo" &> return Harpoon.Redo in
    let history = keyword "history" &> return Harpoon.History in
    let help = keyword "help" &> return Harpoon.Help in
    let save = keyword "save" &> return (Harpoon.Session `serialize) in
    choice
      [ intros
      ; info
      ; split
      ; msplit
      ; compute_type
      ; invert
      ; impossible
      ; solve
      ; auto_invert_solve
      ; inductive_auto_solve
      ; by
      ; suffices
      ; unbox
      ; strengthen
      ; translate
      ; toggle_automation
      ; rename
      ; defer
      ; select_theorem
      ; theorem_command
      ; session_command
      ; subgoal_command
      ; undo
      ; redo
      ; history
      ; help
      ; save
      ]

  let interactive_harpoon_command_sequence =
    sep_by0 interactive_harpoon_command (token Token.SEMICOLON)

  let next_theorem =
    alt
      (token Token.COLON &> keyword "quit" &> return `quit)
      (name $> fun name -> `next name)
end

let harpoon_proof = Harpoon_parsers.harpoon_proof

let interactive_harpoon_command = Harpoon_parsers.interactive_harpoon_command

let interactive_harpoon_command_sequence =
  Harpoon_parsers.interactive_harpoon_command_sequence

let next_theorem = Harpoon_parsers.next_theorem

module rec Signature_parsers : sig
  val sgn_decl : Sgn.decl t
  val sgn : Sgn.sgn t
  val trust_order : Comp.total_dec t
  val total_order : 'a Comp.generic_order t -> 'a Comp.generic_order t
  val numeric_total_order : int Comp.generic_order t
  val optional_numeric_total_order : int Comp.generic_order option t
end = struct
  let sgn_lf_const_decl =
    seq2
      (name <& token Token.COLON)
      lf_typ
    |> span
    $> (fun (location, (identifier, typ)) ->
          Sgn.Const { location; identifier; typ })
    |> labelled "LF constant declaration"

  let sgn_lf_typ_decl : Sgn.decl parser =
    let lf_typ_decl_body =
      let typ_decl =
        seq2
          (name <& token Token.COLON)
          lf_kind
      in
      seq2
        (typ_decl <& token Token.EQUALS)
        (maybe (token Token.PIPE)
        &> sep_by0 sgn_lf_const_decl (token (Token.PIPE)))
      |> span
      $> fun (location, ((identifier, kind), const_decls)) ->
        Sgn.Typ { location; identifier; kind }, const_decls
    in
    labelled "LF type declaration block"
      (token Token.KW_LF
      &> (sep_by1 lf_typ_decl_body (token Token.KW_AND))
      <& token Token.SEMICOLON
      |> span
      $> fun (location, declarations) ->
          Sgn.MRecTyp { location; declarations })

  let call_arg =
    alt
      (name $> Option.some)
      (token Token.UNDERSCORE &> return Option.none)
    |> labelled "call argument"

  let named_total_arg : Comp.named_order t =
    name $> fun x -> Comp.Arg x

  let numeric_total_arg : Comp.numeric_order t =
    integer $> fun x -> Comp.Arg x

  let total_order (arg : 'a Comp.generic_order t) : 'a Comp.generic_order t =
    alt
      arg
      (braces (some arg) $> fun args -> Comp.Lex args)
    |> labelled "totality ordering"

  let trust_order : Comp.total_dec t =
    token Token.KW_TRUST
    |> span
    |> labelled "trust totality"
    $> fun (loc, ()) -> Comp.Trust loc

  (** Parses a totality declaration whose arguments are parsed by `arg` *)
  let total_decl : Comp.total_dec t =
    let total =
      token Token.KW_TOTAL &>
        alt
          begin
            seq2
              (trying (maybe (total_order named_total_arg)))
              (parens (seq2 name (many call_arg)))
            |> span
            $> fun (loc, (order, (r, args))) ->
               Comp.NamedTotal (loc, order, r, args)
          end
          begin
            maybe (total_order numeric_total_arg)
            |> span
            $> fun (loc, order) ->
               Comp.NumericTotal (loc, order)
          end
    in
    alt trust_order total
    |> labelled "totality declaration"

  let numeric_total_order = total_order numeric_total_arg
  let optional_numeric_total_order = maybe numeric_total_order

  (** Mutual block of computation type declarations. *)
  let sgn_cmp_typ_decl =
    labelled "Inductive or stratified computation type declaration"
      begin
        let cmp_typ_decl =
          let flavour =
            alt
              (token Token.KW_INDUCTIVE &> return Sgn.InductiveDatatype)
              (token Token.KW_STRATIFIED &> return Sgn.StratifiedDatatype)
          in
          let sgn_cmp_typ_decl_body =
            seq2
              (name <& token (Token.COLON))
              cmp_typ
            |> span
            $> fun (location, (identifier, typ)) ->
               Sgn.CompConst { location; identifier; typ }
          in
          seq5
            flavour
            (name <& token (Token.COLON))
            (cmp_kind <& token (Token.EQUALS) <& maybe (token (Token.PIPE)))
            (sep_by0 sgn_cmp_typ_decl_body (token Token.PIPE))
            get_state
          |> span
          >>= fun (location, (datatype_flavour, identifier, kind, decls, s)) ->
            check_datatype_decl location identifier decls
            $> fun () ->
               Sgn.CompTyp { location; identifier; kind; datatype_flavour }, decls
        in
        let cmp_cotyp_decl =
          let cmp_cotyp_body =
            seq2
              (* There was this unused feature in the old parser that
                 let a metacontext appear *before* the declaration of the observation.
                 Since it introduces an ambiguity in the parser, I have removed it.
                 In particular, since an optional pair of parens are
                 allowed around the declaration of the observation,
                 `( foo : ` looks like the beginning of a clf_ctyp_decl,
                 namely the beginning of an implicit context
                 abstraction. So `clf_ctyp_decl` will consume some
                 input, and then fail after the colon, thus causing a
                 fatal parse error.
                 Rather than introduce backtracking to resolve this, I
                 think it is preferable to simply remove this unused
                 feature.
                 -je
               *)
              (* (many clf_ctyp_decl $> List.fold_left (fun acc d -> LF.Dec (acc, d)) LF.Empty) *)
              (opt_parens
                 (seq2
                    (name <& token Token.COLON)
                    cmp_typ)
               <& token Token.DOUBLE_COLON)
              cmp_typ
            |> span
            $> fun (location, ((* cD, *) (identifier, tau0), tau1)) ->
               Sgn.CompDest
                { location
                ; identifier
                ; mctx = LF.Empty
                ; observation_typ = tau0
                ; return_typ = tau1
                }
          in
          seq4
            (token Token.KW_COINDUCTIVE &> name <& token Token.COLON)
            (cmp_kind <& token Token.EQUALS <& maybe (token Token.PIPE))
            (sep_by0 cmp_cotyp_body (token Token.PIPE))
            get_state
          |> span
          >>= fun (location, (identifier, kind, decls, s)) ->
            check_codatatype_decl location identifier decls
            $> fun () ->
               Sgn.CompCotyp { location; identifier; kind }, decls
        in

        sep_by1 (alt cmp_typ_decl cmp_cotyp_decl) (token Token.KW_AND)
        <& token Token.SEMICOLON
        |> span
        $> fun (location, declarations) -> Sgn.MRecTyp { location; declarations }
      end

  let sgn_query_pragma =
    let bound =
      alt
        (token Token.STAR &> return Option.none)
        (integer $> Option.some)
      |> labelled "search bound"
    in
    pragma "query" &>
      seq4
        (seq2 bound bound)
        (mctx ~sep: (return ()) (clf_ctyp_decl_bare name' (fun x -> Plicity.explicit, x) |> braces $> (fun (name, typ, plicity) -> LF.Decl (name, typ, plicity))))
        (maybe (name <& token Token.COLON))
        lf_typ
    <& token Token.DOT
    |> span
    |> labelled "logic programming engine query pragma"
    $> fun (location, ((expected_solutions, maximum_tries), cD, name, typ)) ->
       Sgn.Query { location; name; mctx = cD; typ; expected_solutions; maximum_tries }

  let sgn_oldstyle_lf_decl =
    labelled
      "old-style LF type or constant declaration"
      begin
        seq2
          (name <& token Token.COLON)
          (lf_kind_or_typ <& token Token.DOT)
        |> span
        $> fun (location, (identifier, k_or_a)) ->
           match k_or_a with
           | `Kind kind -> Sgn.Typ { location; identifier; kind }
           | `Typ typ -> Sgn.Const { location; identifier; typ }
      end

  let sgn_not_pragma : Sgn.decl parser =
    pragma "not"
    |> span
    $> fun (location, ()) -> Sgn.Pragma { location; pragma=Sgn.NotPrag }

  let left_associativity =
    labelled "associativity `left'" (keyword "left")
    $> Fun.const Associativity.left_associative

  let right_associativity =
    labelled "associativity `right'" (keyword "right")
    $> Fun.const Associativity.right_associative

  let non_associativity =
    labelled "associativity `none'" (keyword "none")
    $> Fun.const Associativity.non_associative

  let associativity =
    labelled "associativity"
    @@ choice
         [ left_associativity
         ; right_associativity
         ; non_associativity
         ]

  let sgn_fixity_pragma : Sgn.decl parser =
    let infix_pragma : Sgn.decl parser =
      pragma "infix"
      &> seq3 name integer (maybe associativity)
      <& token Token.DOT
      |> span
      $> fun (location, (constant, precedence, associativity)) ->
           let pragma =
             Sgn.FixPrag
               { constant
               ; fixity = Fixity.infix
               ; precedence
               ; associativity
               }
           in Sgn.Pragma { location; pragma }
    in
    let prefix_pragma : Sgn.decl parser =
      pragma "prefix"
      &> seq2 name integer
      <& token Token.DOT
      |> span
      $> fun (location, (constant, precedence)) ->
           let pragma =
             Sgn.FixPrag
               { constant
               ; fixity = Fixity.prefix
               ; precedence
               ; associativity = Option.some Associativity.left_associative
               } in
           Sgn.Pragma { location; pragma }
    in
    alt infix_pragma prefix_pragma

  let sgn_associativity_pragma : Sgn.decl parser =
    pragma "assoc"
    &> associativity
    <& token Token.DOT
    |> span
    $> fun (location, associativity) ->
      let pragma = Sgn.DefaultAssocPrag { associativity } in
      Sgn.Pragma { location; pragma }

  let sgn_open_pragma : Sgn.decl parser =
    pragma "open"
    &> fqidentifier
    |> span
    |> labelled "open pragma"
    <& token Token.DOT
    $> fun (location, id) ->
       Sgn.Pragma { location; pragma = Sgn.OpenPrag (List1.to_list id) }

  let sgn_abbrev_pragma : Sgn.decl parser =
    pragma "abbrev"
    &> seq2 fqidentifier identifier
    <& token Token.DOT
    |> span
    |> labelled "module abbreviation pragma"
    $> fun (location, (fq, x)) ->
       let fq = List1.to_list fq in
       Sgn.Pragma { location; pragma = Sgn.AbbrevPrag (fq, x) }

  let sgn_comment : Sgn.decl parser =
    satisfy' `html_comment
      (function
       | Token.BLOCK_COMMENT s -> Option.some s
       | _ -> Option.none)
    |> span
    |> labelled "HTML comment"
    $> fun (location, content) -> Sgn.Comment { location; content }

  let sgn_typedef_decl : Sgn.decl parser =
    seq3
      (token Token.KW_TYPEDEF &> name)
      (token Token.COLON &> cmp_kind)
      (token Token.EQUALS &> cmp_typ <& token Token.SEMICOLON)
    |> span
    |> labelled "type synonym declaration"
    $> fun (location, (identifier, kind, typ)) ->
       Sgn.CompTypAbbrev { location; identifier; kind; typ }

  let lf_schema_some : LF.typ_decl LF.ctx parser =
    alt
      (token Token.KW_SOME
       &> bracks
            (sep_by0
               lf_typ_decl
               (token Token.COMMA))
       $> fun ds -> List.fold_left (fun ctx d -> LF.Dec (ctx, d)) LF.Empty ds)
      (return LF.Empty)
    |> labelled "existential declaration"

  let lf_typ_rec_elem = seq2 (name <& token Token.COLON) lf_typ

  let lf_typ_rec_block =
    rec_block lf_typ_rec_elem
    |> labelled "LF block"

  let lf_typ_rec =
    alt lf_typ_rec_block
      (lf_typ
       |> labelled "single-entry schema body"
       $> fun a ->
          let x =
            match a with
            | LF.Atom { head; _ } -> Option.some head
            | _ -> Option.none
          in
          LF.SigmaLast (x, a))

  let lf_schema_elem =
    seq2 lf_schema_some lf_typ_rec
    |> span
    $> fun (loc, (s, a)) ->
       LF.SchElem (loc, s, a)

  let sgn_schema_decl : Sgn.decl parser =
    seq2
      (token Token.KW_SCHEMA &> name <& token Token.EQUALS)
      (sep_by1 lf_schema_elem (token Token.PLUS)
       $> List1.to_list)
    <& token Token.SEMICOLON
    |> span
    |> labelled "schema declaration"
    $> fun (location, (identifier, bs)) ->
       Sgn.Schema { location; identifier; schema = LF.Schema bs }

  let sgn_let_decl : Sgn.decl parser =
    seq2
      (token Token.KW_LET &>
         seq2
           name
           (maybe (token Token.COLON &> cmp_typ)))
      (token Token.EQUALS &> cmp_exp_syn <& token Token.SEMICOLON)
    |> span
    |> labelled "value declaration"
    $> fun (location, ((identifier, typ), expression)) ->
       Sgn.Val { location; identifier; typ; expression }

  let thm p =
    seq4
      (name <& token Token.COLON)
      (cmp_typ <& token Token.EQUALS)
      (maybe (bracketed' (token Token.SLASH) total_decl))
      p
    |> span
    $> fun (location, (name, typ, order, body)) ->
       Sgn.Theorem { location; name; typ; order; body }

  let proof_decl : Sgn.thm_decl parser =
    token Token.KW_PROOF
    &> thm (harpoon_proof $> fun p -> Comp.Proof p)

  let program_decl : Sgn.thm_decl parser =
    token Token.KW_REC
    &> thm (cmp_exp_chk $> fun e -> Comp.Program e)

  let sgn_thm_decl : Sgn.decl t =
    sep_by1
      (choice [program_decl; proof_decl])
      (token Token.KW_AND)
    <& token Token.SEMICOLON
    |> span
    |> labelled "(mutual) recursive function declaration(s)"
    $> fun (location, theorems) -> Sgn.Theorems { location; theorems }

  let sgn_module_decl : Sgn.decl t =
    seq2
      (token Token.KW_MODULE &> identifier)
      (Token.(tokens [EQUALS; KW_STRUCT]) &> some Signature_parsers.sgn_decl)
    <& Token.(tokens [KW_END; SEMICOLON])
    |> span
    |> labelled "module declaration"
    $> fun (location, (identifier, declarations)) ->
        Sgn.Module { location; identifier; declarations }

  let sgn_decl : Sgn.decl t =
    choice
      (* pragmas *)
      [ sgn_name_pragma
      ; sgn_query_pragma
      ; sgn_not_pragma
      ; sgn_fixity_pragma
      ; sgn_associativity_pragma
      ; sgn_open_pragma
      ; sgn_abbrev_pragma
      ; sgn_comment

      (* misc declarations *)
      ; sgn_module_decl
      ; sgn_typedef_decl

      (* type declarations *)
      ; sgn_lf_typ_decl
      ; sgn_cmp_typ_decl
      ; sgn_oldstyle_lf_decl
      ; sgn_schema_decl

      (* term declarations *)
      ; sgn_let_decl
      ; sgn_thm_decl
      ]
    |> labelled "top-level declaration"

  let sgn =
    seq2
      (many sgn_global_prag |> renamed "zero or more global pragmas")
      (many sgn_decl |> renamed "zero or more top-level declarations")
    $> fun (prags, decls) ->
       prags @ decls
end

let sgn = Signature_parsers.sgn
let trust_order = Signature_parsers.trust_order
let total_order = Signature_parsers.total_order
let numeric_total_order = Signature_parsers.numeric_total_order
let optional_numeric_total_order = Signature_parsers.optional_numeric_total_order
