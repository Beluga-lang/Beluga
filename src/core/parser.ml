(** Beluga syntax parser

    {1 Intro to Parser Combinators}

    This is a hand-made parser combinator system. The basic idea in parser
    combinators is to use higher-order functions to manipulate _parsing
    functions_ to build up more complex parsers.

    The most basic type we can give for a parsing function would be something
    like:

    {[
      type 'a parser = char list -> char list * 'a option
    ]}

    [char list] represents the input stream. We must return a new stream,
    perhaps with some characters removed since we parsed them. The result of
    the parse is parametric. Since parsing may fail, we use a type
    constructor to represent this, namely [option].

    However this design has many shortcomings:

    - Representing the input as a [char list] requires the entire input to be
      buffered in memory. This is wasteful. Instead, we should progressively
      read input as we need it. Therefore in our implementation we use a lazy
      list [LinkStream.t].
    - Using [option] to represent failure doesn't give us a means to specify
      what the error is. Instead we use [Either.t] in order to also return
      some information in case of failure.
    - Finally, in order to control backtracking and other parsing features,
      we will need to not only pass around and transform the {i input}, but a
      more general {i parser state}.

    So our parsing function type now looks like:

    {[
      type 'a parser = state -> state * (error, 'a) Either.t
    ]}

    where [state] contains a [(Location.t * Token.t) LinkStream.t] for the
    input as well as extra stuff for handling backtracking.

    {2 Backtracking}

    The naive implementation of the [alt] alternation combinator is to say
    that [alt p1 p2] first runs [p1], and if it fails, runs [p2]. This
    implementation has the major drawback of allowing {i unlimited}
    backtracking. This is undesirable because it results in terrible error
    messages. What we would like is a way to control the backtracking
    behaviour of parsers on a more fine-grained level.

    Instead, the library below is non-backtracking, so it introduces the
    [trying] combinator to selectively enable backtracking. [trying p] runs
    [p], and if [p] fails having even consumed input, then [trying p] can
    still be backtracked out of. The [alt] combinator is implemented like
    this:

    - Run [p1]. If it succeeds, return its result without trying [p2].
    - If [p1] failed without consuming any input, then run [p2].
    - If [p1] failed under a [trying], then run [p2].
    - Otherwise, the error generated by [p1] was fatal, so return it.

    The rationale for this is that it allows the parser writer to commit to a
    parse tree once certain conditions have been met. For example, in Beluga,
    after a [case] keyword, we know for sure that we're parsing a case
    expression. Therefore, if we fail afterwards to parse the scrutinee of
    the case, we should not backtrack out of the parser for case expressions.

    {2 Language Design Considerations}

    This parser combinator library is only suited for top-down
    data-independent parsing. That is, tokens are parsed sequentially from
    left to right, and no auxiliary data is accumulated during parsing. This
    means that left-recursive grammars and data-dependent grammars are not
    supported without either rewriting the grammar, or disambiguating and
    rewriting parsed ASTs at a later stage.

    It is best to implement a parser with a pre-defined context-free grammar
    in a language specification document. This grammar may need rewriting to
    eliminate left recursion, assign precedences and associativities using
    recursive descent parsing. *)

open Support

module LF = Syntax.Prs.LF
module CLF = Syntax.Prs.CLF
module Meta = Syntax.Prs.Meta
module Comp = Syntax.Prs.Comp
module Harpoon = Syntax.Prs.Harpoon
module Signature = Syntax.Prs.Signature

(***** Parser state definition *****)

(** Type of located values, i.e. values paired with their location. *)
type 'a locd = Location.t * 'a

(** The input to the parser is a backtrackable stream of tokens paired
    with their locations.
 *)
type input = Token.t locd LinkStream.t

(** The parser state contains the input stream as well as control
    information to handle backtracking.
 *)
type state =
  { input : input
  ; backtrack : bool
  ; last_loc : Location.t (* Location of the last token seen by the parser. *)
  }

(** Peeks at the next token in the input stream in the given state. *)
let[@warning "-32"] peek_at (s : state) : Token.t locd option =
  Option.(LinkStream.observe s.input $> Pair.fst)

(** Like {!peek_at} but forgets the location. *)
let[@warning "-32"] next_token s =
  Option.(peek_at s $> Pair.snd |> Option.value ~default:Token.EOI)

(***** ERROR HANDLING *****)

type error_entry =
  { label : string
  ; location : Location.t option
  }

type path' =
  | Entry of error_entry
  | Shift of error_entry * path
and path = path' list

let entry ?location label =
  Entry { location; label }

let rec path_head (p : path) : error_entry option =
  match p with
  | [] -> Option.none
  | x :: _ -> Option.some (path'_head x)

and path'_head (p' : path') : error_entry =
  match p' with
  | Entry e -> e
  | Shift (e, p) ->
     match path_head p with
     | Option.Some e' ->
        { e with label = e.label ^ " " ^ e'.label }
     | Option.None -> e

type content =
  [ `token of Token.t option
  | `identifier of string option
  | `qualified_identifier of (string list * string) option
  | `keyword of string option
  | `hash_identifier of string option
  | `dollar_identifier of string option
  | `hash_blank
  | `dollar_blank
  | `hole of string option
  | `integer of int option
  | `dot_integer
  | `dot_identifier
  | `string_literal
  | `html_comment
  | `eoi
  ]

let print_content ppf : content -> unit =
  let open Format in
  let format_option_with g ppf t =
    Option.print (fun ppf t -> fprintf ppf " `%a'" g t) ppf t
  in
  let string_option = format_option_with pp_print_string in
  let int_option = format_option_with pp_print_int in
  let format_with ppf s f x = fprintf ppf "%s%a" s f x in
  function
  | `token t ->
     fprintf ppf "token%a"
       (format_option_with Token.pp) t
  | `dot_integer -> fprintf ppf "dot integer"
  | `dot_identifier -> fprintf ppf "dot identifier"
  | `string_literal -> fprintf ppf "string literal"
  | `identifier i ->
     format_with ppf "identifier" string_option i
  | `qualified_identifier i ->
     fprintf ppf "qualified identifier%a"
       (format_option_with
          (fun ppf (ss, s) ->
            fprintf ppf "%a%s"
              (pp_print_list ~pp_sep: (fun ppf () -> fprintf ppf "::")
                 pp_print_string) ss
              s))
       i
  | `hash_identifier i ->
     format_with ppf "hash identifier" string_option i
  | `dollar_identifier i ->
     format_with ppf "dollar identifier" string_option i
  | `hash_blank ->
     fprintf ppf "hash blank"
  | `dollar_blank ->
     fprintf ppf "dollar blank"
  | `hole i ->
     format_with ppf "hole" string_option i
  | `keyword i ->
     format_with ppf "keyword" string_option i
  | `integer i ->
     format_with ppf "integer literal" int_option i
  | `eoi ->
     fprintf ppf "end of input"
  | `html_comment -> fprintf ppf "HTML comment"

type error =
  { error : exn
  (* ^ The actual error. *)
  ; path : path
  (* ^ Sequence of parser labels that led to the parse error.
     This is used to generate errors of the form.
     ```
     Parse error: unexpected `bar', expected `foo'.
     In a parser for `production1'
     In a parser for `production2'
     and so on
     ```
   *)
  ; loc : Location.t (* the location the error occurred at *)
  }

(* External errors: the user's fault. *)

exception Unexpected of { expected : content; actual : content }

exception NoMoreChoices of error list (* all alternatives failed *)

exception Ambiguous_backward_arrow

exception Ambiguous_forward_arrow

(* Internal errors: our fault; these should never go to the user. *)

(** Raised by {!not_followed_by} when it fails.

    This is an internal error because it is totally uninformative
    and low-level. When a high-level parser is constructed using
    {!not_followed_by}, it should check for this error and rewrite it into a
    nicer one for the user.
*)
exception NotFollowedBy

(** Pretty-print an error path. *)
let print_path ppf (path : path) : unit =
  let open Format in
  let print_entry ppf { label; location } : unit =
    fprintf ppf "in `%s'%a" label
      (Option.print
         (fun ppf x -> fprintf ppf " at %a" Location.print x))
      location
  in
  let rec go' ppf (path' : path') =
    match path' with
    | Entry e -> fprintf ppf "%a" print_entry e
    | Shift (e, p) ->
       fprintf ppf "@[%a@]@,%a" print_entry e go_box p
  and go ppf (path : path) =
    pp_print_list go' ppf path
  and go_box ppf (path : path) =
    fprintf ppf "  @[<v>%a@]" go path
  in
  fprintf ppf "%a" go_box path

let print_error ppf ({path; loc; _} as e : error) =
  let open Format in
  fprintf ppf "@[<v>Parse error.@,";
  let g ppf { error; _} =
    match error with
    | NoMoreChoices ss ->
       fprintf ppf "Expected:@,  @[<v>";
       pp_print_list ~pp_sep: (fun _ () -> ())
         (fun ppf x ->
           Option.print
             (fun ppf x -> fprintf ppf "%s@," x.label)
             ppf
             (path_head x.path))
         ppf
         ss;
       fprintf ppf "@]"
    | Unexpected { expected; actual; _ } ->
       fprintf ppf "Unexpected token in stream@,  @[<v>Expected %a@,Got %a@]@,"
         print_content expected
         print_content actual
    | Ambiguous_forward_arrow ->
       fprintf ppf "Ambiguous placement of forward arrow operator"
    | Ambiguous_backward_arrow ->
       fprintf ppf "Ambiguous placement of backward arrow operator"
  in
  fprintf ppf "%a" g e;
  if Debug.flag 11 then fprintf ppf "@,%a" print_path path;
  fprintf ppf "@]"

exception Error of { state : state; cause : error }

let () =
  Error.register_printer'
    begin
      function
      | Error { state; cause } ->
         Option.some
           (Error.print_with_location cause.loc
              (fun ppf -> print_error ppf cause))
      | _ -> Option.none
    end

(***** Parser type definition *****)

(** Gets the location of the next item in the input stream *)
let next_loc_at (s : state) : Location.t =
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed"
  (* the lexer should infinitely repeat "EOI" when it's done. *)
  | Option.Some ((loc, _), _) -> loc

let prev_loc_at (s : state) : Location.t = s.last_loc

let initial_state input =
  { input
  ; backtrack = false
  ; last_loc = Location.ghost
  }

(** A parsing result is either an error or a successfully computed value. *)
type 'a result = (error, 'a) Either .t

(** A parsing function transforms a state and produces a parsing result. *)
type 'a parser = state -> state * 'a result

(** Run a parser.
    In other words, extracts the parsing function from a parser. *)
let[@inline] run p s = p s

(** Eliminator for parse results. *)
let handle catch f = Either.eliminate catch f

(** Converts a parse result to Either. *)
let to_either (r : 'a result) : (error, 'a) Either.t = r

(** Extracts the value from a parse result.
    If the parse was unsuccessful, then this raises a parse error exception. *)
let extract =
  function
  | (state, Either.Left cause) -> raise @@ Error { state; cause }
  | (_, Either.Right result) -> result

type 'a t = 'a parser

(***** Basic parser helpers *****)

(** [catch p handler] is the parser that runs [p] and invokes [handler] to
    modify the outcome.

    Despite being called "catch", this parser is actually a kind of "map",
    and is used to implement "low-level" parser transformations.
 *)
let catch (p : 'a parser) (handler : state * 'a result -> state * 'b result) : 'b parser =
  fun s -> run p s |> handler

(** Constructs a failure result for a given state. *)
let fail_at' s loc path error =
  ( s
  , Either.left {error ; path; loc}
  )

(** Fail with no error path. *)
let fail_at s error = fail_at' s (next_loc_at s) [] error

(** A parser that fails with the given error and path. *)
let fail' path e : 'a parser =
  fun s -> fail_at' s (next_loc_at s) path e

(** A parser that fails with the given error and an empty path. *)
let fail e : 'a parser = fail' [] e

let return_at s x =
  (s, Either.right x)

(** Gets the current parser state. *)
let get_state : state parser =
  fun s -> return_at s s

(** Sets the current parser state. *)
let[@warning "-32"] put_state (s : state) : unit parser =
  fun _ -> return_at s ()

(***** Parser combinators *****)

(** [trying p] is [p] with unlimited backtracking enabled. *)
let trying p =
  fun s ->
    match run p s with
    | (s, Either.Left e) -> ({ s with backtrack = true}, Either.left e)
    | x -> x

module M = Monad.Make (struct
  type nonrec 'a t = 'a t

  let return x = fun s -> return_at s x

  let bind k p =
    fun s ->
    match run p s with
    | (s, Either.Right x) -> run (k x) s
    | (s, Either.Left e) -> (s, Either.left e)
end)

include (M : Monad.MONAD with type 'a t := 'a t)

include (Functor.Make (M) : Functor.FUNCTOR with type 'a t := 'a t)

include (Apply.Make (M) : Apply.APPLY with type 'a t := 'a t)

(***** Combinators for handling error labels. *****)

(** Gets the location of the next token in the input stream.
    If the stream is ended, gets the location of the last token.
 *)
let next_loc : Location.t parser =
  get_state
  $> fun s -> next_loc_at s

let prev_loc : Location.t parser =
  get_state
  $> fun s -> prev_loc_at s

(** Runs [p] tracking the span of source material processed by it. *)
let span p =
  seq3 next_loc p prev_loc
  $> fun (l1, x, l2) -> (Location.join l1 l2, x)

(** Runs the parser, and if it fails, runs the given function to
    transform the label stack.
    Also provides the location of the very next token `p` would see.
 *)
let relabelling (type a) (p : a parser) (f : Location.t -> path -> path) : a parser =
  next_loc
  >>= fun loc ->
    catch p
      (function
       | s, Either.Left e -> s, Either.left {e with path = f loc e.path }
       | x -> x)

let shift p s =
  relabelling p
    begin fun loc path ->
    [ Shift
        ( { location = Option.some loc
          ; label = s
          }
        , path
        )
    ]
    end

let shifted s p = shift p s

(** [label p s] is the parser that adds [s] to the stack if [p] fails. *)
let label p s =
  relabelling p (fun location path -> entry ~location s :: path)

(** Flipped version of {!label}. *)
let labelled s p = label p s

(** Replaces the _name_ of the last entry on the path. *)
let renamed label p =
  relabelling p
    begin fun loc ->
    function
    | [] -> []
    | Shift (e, p) :: xs -> Shift ({ e with label }, p) :: xs
    | Entry e :: xs -> Entry { e with label } :: xs
    end

(***** Special combinators *****)

(** [not_followed_by p] succeeds if the parser [p] fails.
    This parser does not consume any input.
 *)
let[@warning "-32"] not_followed_by (p : 'a parser) : unit parser =
  span get_state
  >>= fun (loc, s) ->
    catch p
      (function
       | s', Either.Left _ ->
          (* if [p] fails, we restore the original state *)
          run (put_state s) s'
       | _, Either.Right _ ->
          (* if [p] succeeds, then we need to fail *)
          s, Either.left { error = NotFollowedBy; path = []; loc = loc }
      )

(***** Parsing lists. *****)

(** Transforms each element of a list into a parser, and sequences the
    parsers.
*)
let[@warning "-32"] rec traverse (f : 'a -> 'b parser) (xs : 'a list) : 'b list parser =
  match xs with
  | [] -> return []
  | x :: xs ->
     seq2 (f x) (traverse f xs)
     $> fun (x, xs) -> x :: xs

(** Like {!traverse} but for parsers without interesting outputs. *)
let rec traverse_ (f : 'a -> unit parser) (xs : 'a list) : unit parser =
  match xs with
  | [] -> return ()
  | x :: xs ->
     f x &> traverse_ f xs

(** Runs a sequence of parsers in order and collects their results. *)
let[@warning "-32"] sequence (ps : 'a parser list) : 'a list parser =
  traverse Fun.id ps

(***** Prioritized choice *****)

(** [alt p1 p2] is the alternation between parsers.

    Runs [p1]. If it fails, [p2] is run if one of the following is true:
    - [p1] failed without consuming any input.
    - [p2] failed with backtracking enabled.

    Backtracking is enabled by the {!trying} combinator.
 *)
let alt (p1 : 'a parser) (p2 : 'a parser) : 'a parser =
  fun s ->
  match run p1 s with
  | (s', Either.Left e) ->
      let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
      if Bool.not consumed_input || s'.backtrack
      then run p2 s
      else (s', Either.left e)
  | x -> x

let choice (ps : 'a parser list) : 'a parser =
  fun s ->
  let rec go es =
    function
    | [] -> fail (NoMoreChoices es)
    | p :: ps' ->
        catch p
          (function
          | (s', Either.Left e) ->
              let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
              if Bool.not consumed_input || s'.backtrack
              then run (go (e :: es) ps') s
              else (s', Either.left e)
          | x -> x)
  in
  run (go [] ps) s

(** Succeeds only if the stream has reached the end of the input. *)
let eoi : unit parser =
  (fun s ->
  match LinkStream.observe s.input with
  | Option.None | Option.Some ((_, Token.EOI), _) -> return_at s ()
  | Option.Some ((_, t), _) ->
    fail_at s (Unexpected { expected = `eoi; actual = `token (Option.some t) }))
  |> labelled "end of input"

(** Constructs a parser that accepts the current token if it satisfies
    the given predicate.
    The predicate is _successful_ if it returns [Right].
    The [Left] output indicates failure and can be used to remember
    the next token in the stream to construct better errors in a
    downstream parser. If you don't care, use unit.
    The input stream advances only if the predicate succeeds.
 *)
let satisfy (f : Token.t -> ('e, 'b) Either.t) : ('e, 'b) Either.t parser =
  fun s ->
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed: end-of-input is a token"
  | Option.Some ((loc, t), xs) ->
      let r = f t in
      let s' =
        (* construct the new state with the input depending on
          whether the predicate succeeded.
        *)
        match r with
        | Either.Left _ -> s
        | Either.Right _ -> { s with input = xs; last_loc = loc }
      in
      return_at s' r

(** Tries a parser, and if it fails returns [Option.none] *)
let maybe (p : 'a parser) : 'a option parser =
  shifted "optionally"
    (alt (p $> Option.some) (return Option.none))

(** Tries a parser, and if it fails uses a default value. *)
let maybe_default p ~default =
  maybe p $> Option.value ~default

(** [void p] forgets the result of applying [p]. *)
let void (p : 'a parser) : unit parser = p $> fun _ -> ()

(** Internal implementation of {!many} that doesn't label. *)
let rec many' (p : 'a parser) : 'a list parser =
  alt (some' p $> List1.to_list) (return [])

(** Internal implementation of {!some} that doesn't label. *)
and some' (p : 'a parser) : 'a List1.t parser =
  p >>= fun x -> many' p >>= fun xs -> return (List1.from x xs)

(** [many p] repeats the parser [p] zero or more times and collects
    the results in a list.
 *)
let many (p : 'a parser) : 'a list parser =
  shifted "many" (many' p)

(** [some p] repeats the parser [p] one or more times and collects the
    results in a list.
 *)
let some (p : 'a parser) : 'a List1.t parser =
  shifted "some" (some' p)

(** [sep_by0 p sep] parses zero or more occurrences of [p] separated
    by [sep] and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use {!void}.
 *)
let sep_by0 (p : 'a parser) (sep : unit parser) : 'a list parser =
  maybe p
  >>= (function
      | Option.None -> return []
      | Option.Some x ->
        many' (sep &> p)
        >>= fun xs -> return (x :: xs))
  |> shifted "many separated"

(** [sep_by1 p sep] parses one or more occurrences of [p] separated by
    [sep] and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use {!void}.
 *)
let sep_by1 (p : 'a parser) (sep : unit parser) : 'a List1.t parser =
  seq2 p (many' (sep &> p))
  $> (fun (x, xs) -> List1.from x xs)
  |> shifted "some separated"

(****** Simple parsers *****)

let satisfy' (expected : content) (f : Token.t -> 'a option) : 'a parser =
  satisfy (fun t -> f t |> Option.eliminate (Fun.const (Either.left t)) Either.right)
  |> span
  >>= fun (location, x) ->
    match x with
    | Either.Left t ->
       fail'
         [ entry ~location (Format.stringify print_content expected) ]
         (Unexpected { expected; actual = `token (Option.some t) })
    | Either.Right x -> return x

(** Parses an exact token. *)
let token (t : Token.t) : unit parser =
  satisfy' (`token (Option.some t))
    (fun x -> Option.of_bool (Token.(x = t)))

(** Parses an exact sequence of tokens. *)
let tokens (ts : Token.t list) : unit parser =
  traverse_ token ts

(** Parses an identifier and verifies that it is exactly the given
    string. This is used for parsing "weak keywords", which we would
    still like to allow as general identifiers, but which appear in
    restricted contexts as keywords.
 *)
let keyword (kw : string) : unit parser =
  satisfy' (`keyword (Option.some kw))
    Fun.(Token.equal (Token.IDENT kw) >> Option.of_bool)

let integer : int parser =
  satisfy' (`integer Option.none)
    (function
     | Token.INTLIT k -> Option.some k
     | _ -> Option.none)

let dot_integer : int parser =
  satisfy' `dot_integer
    (function
     | Token.DOT_NUMBER k -> Option.some k
     | _ -> Option.none)

let pragma s = token (Token.PRAGMA s)

let string_literal =
  satisfy' `string_literal
    (function
     | Token.STRING s -> Option.some s
     | _ -> Option.none)

(** Runs the parser `p` between two parsers whose results are
    ignored. *)
let bracketed start stop p =
  start &> p <& stop

(** Runs the parser `p` between the two instances of the same parser
    `b` whose results are ignored. *)
let bracketed' b p = bracketed b b p

(** [parens p] parses [`(' p `)']. *)
let parens p =
  bracketed (token Token.LPAREN) (token Token.RPAREN) p

(** [braces p] parses [`{' p `}']. *)
let braces p =
  bracketed (token Token.LBRACE) (token Token.RBRACE) p

(** [bracks p] parses [`[' p `]']. *)
let[@warning "-32"] bracks p =
  bracketed (token Token.LBRACK) (token Token.RBRACK) p

(** [angles p] parses [`<' p `>']. *)
let[@warning "-32"] angles p =
  bracketed (token Token.LANGLE) (token Token.RANGLE) p

(** [opt_parens p] parses [`(' p `)' | p]. *)
let opt_parens p =
  alt (parens p) p

(** [opt_braces p] parses [`{' p `}' | p]. *)
let[@warning "-32"] opt_braces p =
  alt (braces p) p

(** [opt_bracks p] parses [`[' p `]' | p]. *)
let[@warning "-32"] opt_bracks p =
  alt (bracks p) p

(** [opt_angles p] parses [`<' p `>' | p]. *)
let[@warning "-32"] opt_angles p =
  alt (angles p) p

(** [hash_parens p] parses [`#(' p `)']. *)
let hash_parens p =
  token Token.HASH_LPAREN &> p <& token Token.RPAREN

(** [dollar_parens p] parses [`$(' p `)']. *)
let dollar_parens p =
  token Token.DOLLAR_LPAREN &> p <& token Token.RPAREN

(** [hash_bracks p] parses [`#[' p `]']. *)
let hash_bracks p =
  token Token.HASH_LBRACK &> p <& token Token.RBRACK

(** [dollar_bracks p] parses [`$[' p `]']. *)
let dollar_bracks p =
  token Token.DOLLAR_LBRACK &> p <& token Token.RBRACK

(** Parses p and requires that the input stream be finished. *)
let only p = p <& eoi

(***** Production rules *****)

let identifier =
  satisfy' (`identifier Option.none)
    (function
      | Token.IDENT s -> Option.some s
      | _ -> Option.none)
  |> span
  $> fun (location, identifier) -> Identifier.make ~location identifier

let dot_identifier =
  satisfy' `dot_identifier
    (function
     | Token.DOT_IDENT x -> Option.some x
     | _ -> Option.none)
  |> span
  $> fun (location, identifier) -> Identifier.make ~location identifier

let hash_identifier =
  satisfy' (`hash_identifier Option.none)
    (function
     | Token.HASH_IDENT s -> Option.some s
     | _ -> Option.none)
  |> span
  $> fun (location, identifier) -> Identifier.make ~location identifier

let dollar_identifier =
  satisfy' (`dollar_identifier Option.none)
    (function
     | Token.DOLLAR_IDENT s -> Option.some s
     | _ -> Option.none)
  |> span
  $> fun (location, identifier) -> Identifier.make ~location identifier

(*=
    <omittable-identifier> ::=
      | `_'
      | <identifier>
*)
let omittable_identifier =
  alt
    (token Token.UNDERSCORE $> fun () -> Option.none)
    (identifier $> Option.some)

(*=
    <omittable-hash-identifier> ::=
      | `#_'
      | <hash-identifier>
*)
let omittable_hash_identifier =
  alt
    (token Token.HASH_BLANK $> fun () -> Option.none)
    (hash_identifier $> Option.some)

(*=
    <omittable-dollar-identifier> ::=
      | `$_'
      | <dollar-identifier>
*)
let omittable_dollar_identifier =
  alt
    (token Token.DOLLAR_BLANK $> fun () -> Option.none)
    (dollar_identifier $> Option.some)

(*=
   <qualified-identifier> ::= <identifier> <dot-identifier>*
*)
let[@warning "-32"] qualified_identifier =
  seq2 identifier (many dot_identifier)
  |> span
  $> fun (location, (head, tail)) ->
       let (modules, identifier) = List1.unsnoc (List1.from head tail) in
       QualifiedIdentifier.make ~location ~modules identifier

(*=
   <dot-qualified-identifier> ::= <dot-identifier>+
*)
let dot_qualified_identifier =
  some dot_identifier
  |> span
  $> fun (location, identifiers) ->
       let (modules, identifier) = List1.unsnoc identifiers in
       QualifiedIdentifier.make ~location ~modules identifier

(*=
    <qualified-or-plain-identifier> ::=
      | <identifier>
      | <identifier> <dot-identifier>*
*)
let qualified_or_plain_identifier =
  seq2 identifier (many dot_identifier)
  |> span
  $> function
     | (_, (head, [])) -> `Plain head
     | (location, (head, tail)) ->
       let (modules, identifier) = List1.unsnoc (List1.from head tail) in
       `Qualified (QualifiedIdentifier.make ~location ~modules identifier)

let omittable_meta_object_identifier =
  let plain =
    omittable_identifier $> fun i -> i, `Plain
  and hash =
    omittable_hash_identifier $> fun i -> i, `Hash
  and dollar =
    omittable_dollar_identifier $> fun i -> i, `Dollar
  in
  choice
    [ plain
    ; hash
    ; dollar
    ]

let meta_object_identifier =
  let plain =
    identifier $> fun i -> i, `Plain
  and hash =
    hash_identifier $> fun i -> i, `Hash
  and dollar =
    dollar_identifier $> fun i -> i, `Dollar
  in
  choice
    [ plain
    ; hash
    ; dollar
    ]

let hole =
  satisfy' (`hole Option.none) (function
    | Token.HOLE "" -> Option.some `Unlabelled
    | Token.HOLE s -> Option.some (`Labelled s)
    | _ -> Option.none)
  |> span
  $> (function
     | (location, `Unlabelled) -> `Unlabelled
     | (location, `Labelled label) ->
       `Labelled (Identifier.make ~location label)
     )
  |> labelled "hole"

module rec LF_parsers : sig
  val lf_object : LF.Object.t t
end = struct
  (*=
      Original grammar:

      <lf-object> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>
        | <lf-object> <forward-arrow> <lf-object>
        | <lf-object> <backward-arrow> <lf-object>
        | <lf-object> `:' <lf-object>
        | <lf-object> <lf-object>
        | <identifier>
        | <qualified-identifier>
        | `type'
        | `_'
        | `(' <lf-object> `)'


      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (lambdas and Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <lf-weak-prefix> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>

      <lf-object> ::=
        | <lf-object1>

      <lf-object1> ::=
        | <lf-weak-prefix>
        | <lf-object2>

      <lf-object2> ::=
        | <lf-object3> (`:' (<lf-object3> | <lf-weak-prefix>))+
        | <lf-object3>

      <lf-object3> ::=
        | <lf-object4> (<forward-arrow> (<lf-object4> | <lf-weak-prefix>))+
        | <lf-object4> (<backward-arrow> (<lf-object4> | <lf-weak-prefix>))+
        | <lf-object4>

      <lf-object4> ::=
        | <lf-object5> (<lf-object5> | <lf-weak-prefix>)+
        | <lf-object5>

      <lf-object5> ::=
        | <identifier>
        | <qualified-identifier>
        | `type'
        | `_'
        | `(' <lf-object> `)'
  *)
  let lf_weak_prefix =
    let lambda =
      seq2
        (token Token.LAMBDA
          &> (seq2
              omittable_identifier
              (maybe (token Token.COLON &> LF_parsers.lf_object)))
          <& token Token.DOT)
        LF_parsers.lf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         LF.Object.RawLambda { location; parameter_identifier; parameter_sort; body })
      |> labelled "LF lambda"
    and pi =
      seq2
        (braces
          (seq2
            omittable_identifier
            (maybe (token Token.COLON &> LF_parsers.lf_object))))
        LF_parsers.lf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         LF.Object.RawPi { location; parameter_identifier; parameter_sort; body })
      |> labelled "LF Pi type or Pi kind"
    in
    choice
      [ lambda
      ; pi
      ]

  let lf_object5 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           LF.Object.RawQualifiedIdentifier { location; identifier; quoted = false }
         | (location, `Plain identifier) ->
           LF.Object.RawIdentifier { location; identifier; quoted = false })
      |> labelled "LF constant or variable"
    and type_ =
      token Token.KW_TYPE
      |> span
      $> (fun (location, ()) -> LF.Object.RawType { location })
      |> labelled "LF `type' kind"
    and hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> LF.Object.RawHole { location })
      |> labelled "LF hole object"
    and parenthesized_or_quoted_constant_or_variable =
      parens LF_parsers.lf_object
      $> (function
         | LF.Object.RawIdentifier i ->
           LF.Object.RawIdentifier { i with quoted = true }
         | LF.Object.RawQualifiedIdentifier i ->
           LF.Object.RawQualifiedIdentifier { i with quoted = true }
         | o -> o
         )
      |> labelled "LF parenthesized kind, type or term"
    in
    choice
      [ constant_or_variable
      ; type_
      ; hole
      ; parenthesized_or_quoted_constant_or_variable
      ]

  let lf_object4 =
    some (alt lf_object5 lf_weak_prefix)
    |> span
    $> (function
       | (_, List1.T (object_, [])) -> object_
       | (location, List1.T (o1, o2 :: os)) ->
         LF.Object.RawApplication { location; objects = List2.from o1 o2 os })
    |> labelled "LF atomic object or application"

  let lf_object3 =
    (* Forward arrows are right-associative, and backward arrows are
       left-associative. Forward and backward arrows have the same
       precedence. Mixing forward and backward arrows at the same precedence
       level is ambiguous. That is, [a -> b <- c] could be parsed as
       [a -> (b <- c)] when parsed from left to right, or as [(a -> b) <- c]
       when parsed from right to left. *)
    let forward_arrow = token Token.ARROW $> fun () -> `Forward_arrow
    and backward_arrow = token Token.BACKARROW $> fun () -> `Backward_arrow
    and right_operand = alt lf_object4 lf_weak_prefix in
    lf_object4 >>= fun object_ ->
    maybe (alt forward_arrow backward_arrow)
    >>= (function
          | Option.None -> return (`Singleton object_)
          | Option.Some `Forward_arrow ->
            (* A forward arrow was parsed. Subsequent backward arrows are
               ambiguous. *)
            let backward_arrow =
              token Token.BACKARROW >>= fun () ->
              fail Ambiguous_backward_arrow
            and forward_arrow = token Token.ARROW in
            let operator = alt backward_arrow forward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Forward_arrows (List1.from object_ (x :: xs))
          | Option.Some `Backward_arrow ->
            (* A backward arrow was parsed. Subsequent forward arrows are
               ambiguous. *)
            let backward_arrow = token Token.BACKARROW
            and forward_arrow =
              token Token.ARROW >>= fun () -> fail Ambiguous_forward_arrow
            in
            let operator = alt forward_arrow backward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Backward_arrows (List1.from object_ (x :: xs)))
    $> (function
         | `Singleton x -> x
         | `Forward_arrows xs ->
           List1.fold_right Fun.id
             (fun operand accumulator ->
               let location =
                 Location.join
                   (LF.location_of_object operand)
                   (LF.location_of_object accumulator)
               in
               LF.Object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Forward
                 })
             xs
         | `Backward_arrows (List1.T (x, xs)) ->
           List.fold_left
             (fun accumulator operand ->
               let location =
                 Location.join
                   (LF.location_of_object accumulator)
                   (LF.location_of_object operand)
               in
               LF.Object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Backward
                 })
             x xs)
    |> labelled
         "LF atomic object, application, annotated term, forward arrow or \
          backward arrow"

  let lf_object2 =
    (* Annotations are left-associative. *)
    let annotation =
      token Token.COLON &> (alt lf_object3 lf_weak_prefix)
    in
    let trailing_annotations =
      many (span annotation)
    in
    seq2 lf_object3 trailing_annotations
    $> (function
       | (object_, []) -> object_
       | (object_, annotations) ->
         List.fold_left
           (fun accumulator (sort_location, sort) ->
             let location =
               Location.join
                 (LF.location_of_object accumulator)
                 sort_location
             in
             LF.Object.RawAnnotated
               { location
               ; object_ = accumulator
               ; sort
               }
           )
           object_
           annotations
       )
    |> labelled
         "LF atomic object, application, annotated term, forward arrow \
          or backward arrow"

  let lf_object1 =
    choice
      [ lf_weak_prefix
      ; lf_object2
      ]

  let lf_object =
    lf_object1
    |> labelled "LF object"
end

let lf_object = LF_parsers.lf_object

module rec CLF_parsers : sig
  val clf_object : CLF.Object.t t

  val clf_context_object : CLF.Context_object.t t
end = struct
  (*=
      Original grammar:

      <clf-context-object> ::=
        | [`^']
        | `..'
        | [`..' `,'] [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)*

      <clf-object> ::=
        | `{' <omittable-identifier> `:' <clf-object> `}' <clf-object>
        | `\' <omittable-identifier> [`:' <clf-object>] `.' <clf-object>
        | <clf-object> <forward-arrow> <clf-object>
        | <clf-object> <backward-arrow> <clf-object>
        | <clf-object> `:' <clf-object>
        | `block' `(' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+ `)'
        | `block' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+
        | `block' `(' <clf-object> `)'
        | `block' <clf-object>
        | <clf-object> <clf-object>
        | <clf-object> `[' <clf-context-object> `]'
        | <clf-object>`.'<identifier>
        | <clf-object>`.'<integer>
        | `_'
        | `?'[<identifier>]
        | <identifier>
        | <qualified-identifier>
        | `<' <clf-object> (`;' <clf-object>)* `>'
        | `(' <clf-object> `)'


      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (lambdas and Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <clf-context-object> ::=
        | [`^']
        | `..'
        | [`..' `,'] [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)*

      <clf-weak-prefix> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>

      <clf-object> ::=
        | <clf-object1>

      <clf-object1> ::=
        | <clf-weak-prefix>
        | <clf-object2>

      <clf-object2> ::=
        | <clf-object3> (`:' (<clf-object3> | <clf-weak-prefix>))+
        | <clf-object3>

      <clf-object3> ::=
        | <clf-object4> (<forward-arrow> (<clf-object4> | <clf-weak-prefix>))+
        | <clf-object4> (<backward-arrow> (<clf-object4> | <clf-weak-prefix>))+
        | <clf-object4>

      <clf-object4> ::=
        | `block' `(' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+ `)'
        | `block' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+
        | `block' `(' <clf-object> `)'
        | `block' <clf-object>
        | <clf-object5>

      <clf-object5> ::=
        | <clf-object6> (<clf-object6> | <clf-weak-prefix>)+
        | <clf-object6>

      <clf-object6> ::=
        | <clf-object7> (`[' <clf-context-object> `]')+
        | <clf-object7>

      <clf-object7> ::=
        | <clf-object8>(`.'(<integer> | <identifier>))+
        | <clf-object8>

      <clf-object8> ::=
        | <identifier>
        | <qualified-identifier>
        | `_'
        | `?'[<identifier>]
        | `<' <clf-object> (`;' <clf-object>)* `>'
        | `(' <clf-object> `)'
  *)
  let clf_weak_prefix =
    let lambda =
      seq2
        (token Token.LAMBDA
          &> (seq2
              omittable_identifier
              (maybe (token Token.COLON &> CLF_parsers.clf_object)))
          <& token Token.DOT)
        CLF_parsers.clf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
        CLF.Object.RawLambda { location; parameter_identifier; parameter_sort; body })
      |> labelled "Contextual LF lambda term"
    and pi =
      seq2
        (braces
          (seq2
            omittable_identifier
            (maybe (token Token.COLON &> CLF_parsers.clf_object))))
        CLF_parsers.clf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         CLF.Object.RawPi { location; parameter_identifier; parameter_sort; body })
      |> labelled "Contextual LF Pi kind or type"
    in
    choice
      [ lambda
      ; pi
      ]

  let clf_context_object =
    let empty =
      maybe (token Token.HAT)
      |> span
      $> fun (location, _) ->
        { CLF.Context_object.location
        ; head = CLF.Context_object.Head.None { location }
        ; objects = []
        }
    and identity =
      token Token.DOTS
      |> span
      $> fun (location, ()) ->
        { CLF.Context_object.location
        ; head = CLF.Context_object.Head.Identity { location }
        ; objects = []
        }
    and non_empty =
      let bindings =
        sep_by1
          (seq2
            (maybe (identifier <& trying (token Token.COLON)))
            CLF_parsers.clf_object
          )
          (token Token.COMMA)
      in
      seq2
        (span (maybe (seq2 (span (token Token.DOTS)) (trying (token Token.COMMA)))))
        bindings
      |> span
      $> function
         | (location, ((_, Option.Some ((dots_location, ()), ())), objects)) ->
            { CLF.Context_object.location
            ; head = CLF.Context_object.Head.Identity { location = dots_location }
            ; objects = List1.to_list objects
            }
         | (location, ((empty_head_location, Option.None), objects)) ->
            { CLF.Context_object.location
            ; head = CLF.Context_object.Head.None { location = empty_head_location }
            ; objects = List1.to_list objects
            }
    in
    choice
      [ non_empty
      ; identity
      ; empty
      ]
    |> labelled "Contextual LF substitution or context object"

  let clf_object8 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           CLF.Object.RawQualifiedIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         | (location, `Plain identifier) ->
           CLF.Object.RawIdentifier
             { location
             ; identifier = identifier, `Plain
             ; quoted = false
             }
         )
      |> labelled "Contextual LF constant or variable"
    and parameter_variable =
      hash_identifier
      $> fun identifier ->
        let location = Identifier.location identifier in
        CLF.Object.RawIdentifier
          { location
          ; identifier = identifier, `Hash
          ; quoted = false
          }
    and substitution_variable =
      dollar_identifier
      $> fun identifier ->
        let location = Identifier.location identifier in
        CLF.Object.RawIdentifier
          { location
          ; identifier = identifier, `Dollar
          ; quoted = false
          }
    and underscore_hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) ->
           CLF.Object.RawHole { location; variant = `Underscore }
         )
      |> labelled "Contextual LF hole"
    and possibly_labelled_hole =
      hole
      |> span
      $> (fun (location, variant) ->
           CLF.Object.RawHole { location; variant }
         )
      |> labelled "Possibly labelled contextual LF hole"
    and tuple =
      angles (sep_by1 CLF_parsers.clf_object (token Token.SEMICOLON))
      |> span
      $> (fun (location, elements) ->
         CLF.Object.RawTuple { location; elements })
      |> labelled "Contextual LF tuple term"
    and parenthesized_or_quoted_constant_or_variable =
      parens CLF_parsers.clf_object
      $> (function
         | CLF.Object.RawIdentifier i ->
           CLF.Object.RawIdentifier { i with quoted = true }
         | CLF.Object.RawQualifiedIdentifier i ->
           CLF.Object.RawQualifiedIdentifier { i with quoted = true }
         | o -> o
         )
      |> labelled "Contextual LF parenthesized kind, type or term"
    in
    choice
      [ constant_or_variable
      ; parameter_variable
      ; substitution_variable
      ; underscore_hole
      ; possibly_labelled_hole
      ; tuple
      ; parenthesized_or_quoted_constant_or_variable
      ]

  let clf_object7 =
    (* Projections are left-associative. *)
    let integer_projection =
      dot_integer
      $> fun i ->
        `By_position i
    and identifier_projection =
      dot_identifier
      $> fun x -> `By_identifier x
    in
    let projection =
      alt integer_projection identifier_projection
    in
    let trailing_projections = many (span projection) in
    (* If a term only uses named projections, then those projections are
       actually parsed as a qualfified identifier. *)
    seq2 clf_object8 trailing_projections
    $> (function
       | (object_, []) -> object_
       | (object_, projections) ->
           List.fold_left
             (fun accumulator (projection_location, projection) ->
               let location =
                 Location.join
                   (CLF.location_of_object accumulator)
                   projection_location
               in
               CLF.Object.RawProjection
                 { location
                 ; object_ = accumulator
                 ; projection
                 }
             )
             object_
             projections
       )
    |> labelled "Contextual LF atomic object or projection term"

  let clf_object6 =
    (* Substitutions are left-associative. *)
    seq2 clf_object7 (many (bracks clf_context_object))
    $> (function
       | (object_, []) -> object_
       | (object_, substitutions) ->
           List.fold_left
             (fun accumulator substitution ->
               let location =
                  Location.join
                    (CLF.location_of_object accumulator)
                    (CLF.location_of_context_object substitution)
               in
               CLF.Object.RawSubstitution
                 { location
                 ; object_ = accumulator
                 ; substitution
                 }
             )
             object_
             substitutions
       )
    |> labelled
         "Contextual LF atomic object, projection term or\
          substitution term"

  let clf_object5 =
    some (alt clf_object6 clf_weak_prefix)
    |> span
    $> (function
       | (_, List1.T (object_, [])) -> object_
       | (location, List1.T (o1, o2 :: os)) ->
         CLF.Object.RawApplication { location; objects = List2.from o1 o2 os })
    |> labelled
         "Contextual LF atomic object, projection term, substitution term \
          or application"

  let clf_object4 =
    let block_contents =
      sep_by1
        (seq2 (maybe (identifier <& trying (token Token.COLON))) CLF_parsers.clf_object)
        (token Token.COMMA)
    in
    let block =
      token Token.KW_BLOCK &> opt_parens block_contents
      |> span
      $> (fun (location, elements) -> CLF.Object.RawBlock { location; elements })
      |> labelled "Contextual LF block type"
    in
    choice
      [ block
      ; clf_object5
      ]

  let clf_object3 =
    (* Forward arrows are right-associative, and backward arrows are
       left-associative. Forward and backward arrows have the same
       precedence. Mixing forward and backward arrows at the same precedence
       level is ambiguous. That is, [a -> b <- c] could be parsed as
       [a -> (b <- c)] when parsed from left to right, or as [(a -> b) <- c]
       when parsed from right to left. *)
    let forward_arrow = token Token.ARROW $> fun () -> `Forward_arrow
    and backward_arrow = token Token.BACKARROW $> fun () -> `Backward_arrow
    and right_operand = alt clf_object4 clf_weak_prefix in
    clf_object4 >>= fun object_ ->
    maybe (alt forward_arrow backward_arrow)
    >>= (function
          | Option.None -> return (`Singleton object_)
          | Option.Some `Forward_arrow ->
            (* A forward arrow was parsed. Subsequent backward arrows are
               ambiguous. *)
            let backward_arrow =
              token Token.BACKARROW >>= fun () ->
              fail Ambiguous_backward_arrow
            and forward_arrow = token Token.ARROW in
            let operator = alt backward_arrow forward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Forward_arrows (List1.from object_ (x :: xs))
          | Option.Some `Backward_arrow ->
            (* A backward arrow was parsed. Subsequent forward arrows are
               ambiguous. *)
            let backward_arrow = token Token.BACKARROW
            and forward_arrow =
              token Token.ARROW >>= fun () -> fail Ambiguous_forward_arrow
            in
            let operator = alt forward_arrow backward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Backward_arrows (List1.from object_ (x :: xs)))
    $> (function
         | `Singleton x -> x
         | `Forward_arrows xs ->
           List1.fold_right Fun.id
             (fun operand accumulator ->
               let location =
                 Location.join
                   (CLF.location_of_object operand)
                   (CLF.location_of_object accumulator)
               in
               CLF.Object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Forward
                 })
             xs
         | `Backward_arrows (List1.T (x, xs)) ->
           List.fold_left
             (fun accumulator operand ->
               let location =
                 Location.join
                   (CLF.location_of_object accumulator)
                   (CLF.location_of_object operand)
               in
               CLF.Object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Backward
                 })
             x xs)
    |> labelled
         "Contextual LF atomic object, application, annotated term, forward \
          arrow or backward arrow"

  let clf_object2 =
    let annotation =
      token Token.COLON &> (alt clf_object3 clf_weak_prefix)
    in
    let trailing_annotations =
      many (span annotation)
    in
    seq2 clf_object3 trailing_annotations
    $> (function
       | (object_, []) -> object_
       | (object_, annotations) ->
         List.fold_left
           (fun accumulator (sort_location, sort) ->
             let location =
               Location.join
                 (CLF.location_of_object accumulator)
                 sort_location
             in
             CLF.Object.RawAnnotated
               { location
               ; object_ = accumulator
               ; sort
               }
           )
           object_
           annotations
       )
    |> labelled
         "Contextual LF atomic object, application, annotatedterm, forward\
          arrow or backward arrow object"

  let clf_object1 =
    choice
      [ clf_weak_prefix
      ; clf_object2
      ]

  let clf_object =
    clf_object1
    |> labelled "Contextual LF object"
end

let clf_object = CLF_parsers.clf_object

let clf_context_object = CLF_parsers.clf_context_object

module rec Meta_parsers : sig
  val schema_object : Meta.Schema_object.t t

  val meta_thing : Meta.Thing.t t

  val meta_context : Meta.Context_object.t t
end = struct
  (*=
      Original grammar:

      <schema-object> ::=
        | <qualified-identifier>
        | <schema-object> `+' <schema-object>
        | [`some' `[' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>) `]']
          `block' `(' [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)* `)'
        | [`some' `[' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>) `]']
          `block' [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)*

      <meta-thing> ::=
        | <schema-object>
        | `(' <clf-context-object> `)'
        | `(' <clf-context-object> <turnstile> <clf-context-object> `)'
        | `#(' <clf-context-object> <turnstile> <clf-context-object> `)'
        | `$(' <clf-context-object> <turnstile> <clf-context-object> `)'
        | `$(' <clf-context-object> <turnstile-hash> <clf-context-object> `)'
        | `[' <clf-context-object> `]'
        | `[' <clf-context-object> <turnstile> <clf-context-object> `]'
        | `#[' <clf-context-object> <turnstile> <clf-context-object> `]'
        | `$[' <clf-context-object> <turnstile> <clf-context-object> `]'
        | `$[' <clf-context-object> <turnstile-hash> <clf-context-object> `]'

      Rewritten grammar, to eliminate left-recursions, and handle precedence
      using recursive descent.

      <schema-object> ::=
        | <schema-object1>

      <schema-object1> ::=
        | <schema-object2> (`+' <schema-object2>)+
        | <schema-object2>

      <schema-object2> ::=
        | <qualified-identifier>
        | [`some' `[' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>) `]']
          `block' `(' [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)* `)'
        | [`some' `[' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>) `]']
          `block' [<identifier> `:'] <clf-object> (`,' [<identifier> `:'] <clf-object>)*

      <meta-thing> ::=
        | <schema-object>
        | `(' <clf-context-object> [<turnstile> <clf-context-object>] `)'
        | `#(' <clf-context-object> <turnstile> <clf-context-object> `)'
        | `$(' <clf-context-object> (<turnstile> | <turnstile-hash>) <clf-context-object> `)'
        | `[' <clf-context-object> [<turnstile> <clf-context-object>] `]'
        | `#[' <clf-context-object> <turnstile> <clf-context-object> `]'
        | `$[' <clf-context-object> (<turnstile> | <turnstile-hash>) <clf-context-object> `]'
  *)
  let plus_operator = token Token.PLUS

  let schema_some_clause =
    let declaration =
      seq2 identifier (token Token.COLON &> CLF_parsers.clf_object)
    in
    token Token.KW_SOME &> bracks (sep_by1 declaration (token Token.COMMA))
    |> labelled "Context schema `some' clause"

  let schema_block_clause =
    let block_contents =
      sep_by1
        (seq2 (maybe (identifier <& trying (token Token.COLON))) CLF_parsers.clf_object)
        (token Token.COMMA)
      |> labelled "Context schema element"
    in
    token Token.KW_BLOCK &> opt_parens block_contents
    |> labelled "Context schema `block' clause"

  let schema_object2 =
    let constant =
      qualified_identifier
      $> fun identifier ->
        let location = QualifiedIdentifier.location identifier in
        Meta.Schema_object.RawConstant { location; identifier }
    and element =
      seq2 (maybe schema_some_clause) schema_block_clause
      |> span
      $> (fun (location, (some_clause, block_clause)) ->
            Meta.Schema_object.RawElement
              { location
              ; some = some_clause
              ; block = block_clause
              }
         )
      |> labelled "Context schema atom"
    in
    choice
      [ constant
      ; element
      ]

  let schema_object1 =
    sep_by1 schema_object2 plus_operator
    |> span
    $> (function
       | (_, List1.T (schema_object, [])) -> schema_object
       | (location, List1.T (c1, c2 :: cs)) ->
         let schemas = List2.from c1 c2 cs in
         Meta.Schema_object.RawAlternation { location; schemas }
       )
    |> labelled "Context schema constant, atom or alternation"

  let schema_object = schema_object1

  let meta_thing =
    let schema_type =
      schema_object
      |> span
      $> fun (location, schema) ->
        Meta.Thing.RawSchema { location; schema }
    and meta_type_or_meta_object =
      let plain_inner_thing =
        seq2
          CLF_parsers.clf_context_object
          (maybe (token Token.TURNSTILE &> CLF_parsers.clf_context_object))
      and hash_inner_thing =
        seq2
          CLF_parsers.clf_context_object
          (token Token.TURNSTILE &> CLF_parsers.clf_context_object)
      and dollar_inner_thing =
        let turnstile =
          token Token.TURNSTILE $> fun () -> `Plain
        and turnstile_hash =
          token Token.TURNSTILE_HASH $> fun () -> `Hash
        in
        seq2
          CLF_parsers.clf_context_object
          (seq2 (alt turnstile turnstile_hash) CLF_parsers.clf_context_object)
      in
      let plain_meta_type =
        choice
          [ parens plain_inner_thing
          ; bracks plain_inner_thing
          ]
        |> span
        $> (function
           | (location, (context, Option.None)) ->
             Synprs.Meta.Thing.RawContext { location; context }
           | (location, (context, Option.Some object_)) ->
             Synprs.Meta.Thing.RawTurnstile
               { location
               ; context
               ; object_
               ; variant = `Plain
               }
           )
      and hash_meta_type =
        choice
          [ hash_parens hash_inner_thing
          ; hash_bracks hash_inner_thing
          ]
        |> span
        $> fun (location, (context, object_)) ->
            Synprs.Meta.Thing.RawTurnstile
              { location
              ; context
              ; object_
              ; variant = `Hash
              }
      and dollar_meta_type =
        choice
          [ dollar_parens dollar_inner_thing
          ; dollar_bracks dollar_inner_thing
          ]
        |> span
        $> (function
           | (location, (context, (`Plain, object_))) ->
              Synprs.Meta.Thing.RawTurnstile
                { location
                ; context
                ; object_
                ; variant = `Dollar
                }
           | (location, (context, (`Hash, object_))) ->
              Synprs.Meta.Thing.RawTurnstile
                { location
                ; context
                ; object_
                ; variant = `Dollar_hash
                }
           )
      in
      choice
        [ plain_meta_type
        ; hash_meta_type
        ; dollar_meta_type
        ]
    in
    choice
      [ schema_type
      ; meta_type_or_meta_object
      ]
    |> labelled "Meta-type, meta-object, or meta-object pattern"

  (*=
      <meta-context> ::=
        | [`^']
        | <meta-object-identifier> [`:' <boxed-meta-type>] (`,' <meta-object-identifier> [`:' <boxed-meta-type>])*
  *)
  let meta_context =
    let non_empty =
      sep_by0
        (seq2 meta_object_identifier (maybe (token Token.COLON &> Meta_parsers.meta_thing)))
        (token Token.COMMA)
      |> span
      $> fun (location, bindings) ->
        { Meta.Context_object.location; bindings }
    and empty =
      maybe (token Token.HAT)
      |> span
      $> fun (location, _) -> { Meta.Context_object.location; bindings = [] }
    in
    choice
      [ non_empty
      ; empty
      ]
end

let schema_object = Meta_parsers.schema_object

let meta_thing = Meta_parsers.meta_thing

let meta_context = Meta_parsers.meta_context

module rec Comp_parsers : sig
  val comp_sort_object : Comp.Sort_object.t t

  val comp_pattern_atomic_object : Comp.Pattern_object.t t

  val comp_pattern_object : Comp.Pattern_object.t t

  val comp_expression_object : Comp.Expression_object.t t

  val comp_context : Comp.Context_object.t t
end = struct
  (*=
      Original grammar:

      <comp-sort-object> ::=
        | <identifier>
        | <qualified-identifier>
        | `ctype'
        | `{' <omittable-meta-object-identifier> [`:' <meta-thing>] `}' <comp-sort-object>
        | `(' <omittable-meta-object-identifier> [`:' <meta-thing>] `)' <comp-sort-object>
        | <comp-sort-object> <forward-arrow> <comp-sort-object>
        | <comp-sort-object> <backward-arrow> <comp-sort-object>
        | <comp-sort-object> `*' <comp-sort-object>
        | <comp-sort-object> <comp-sort-object>
        | <meta-thing>
        | `(' <comp-sort-object> `)'

      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <comp-weak-prefix> ::=
        | `{' <omittable-meta-object-identifier> [`:' <meta-thing>] `}' <comp-sort-object>
        | `(' <omittable-meta-object-identifier> [`:' <meta-thing>] `)' <comp-sort-object>

      <comp-sort-object> ::=
        | <comp-sort-object1>

      <comp-sort-object1> ::=
        | <comp-weak-prefix>
        | <comp-sort-object2>

      <comp-sort-object2> ::=
        | <comp-sort-object3> (<forward-arrow> (<comp-sort-object> | <comp-weak-prefix>))+
        | <comp-sort-object3> (<backward-arrow> (<comp-sort-object> | <comp-weak-prefix>))+
        | <comp-sort-object3>

      <comp-sort-object3> ::=
        | <comp-sort-object4> (`*' <comp-sort-object>)+
        | <comp-sort-object4>

      <comp-sort-object4> ::=
        | <comp-sort-object5> (<comp-sort-object5> | <comp-weak-prefix>)+
        | <comp-sort-object5>

      <comp-sort-object5> ::=
        | <identifier>
        | <qualified-identifier>
        | `ctype'
        | <meta-thing>
        | `(' <comp-sort-object> `)'
  *)
  let comp_weak_prefix =
    let declaration =
      seq2
        omittable_meta_object_identifier
        (maybe (token Token.COLON &> Meta_parsers.meta_thing))
    in
    let explicit_pi =
      seq2 (braces declaration) Comp_parsers.comp_sort_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         Comp.Sort_object.RawPi
           { location
           ; parameter_identifier
           ; parameter_sort
           ; plicity = Plicity.explicit
           ; body
           })
      |> labelled "Explicit computational Pi kind or type"
    and implicit_pi =
      seq2 (parens declaration) Comp_parsers.comp_sort_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         Comp.Sort_object.RawPi
           { location
           ; parameter_identifier
           ; parameter_sort
           ; plicity = Plicity.implicit
           ; body
           })
      |> labelled "Implicit computational Pi kind or type"
    in
    choice
      [ explicit_pi
      ; implicit_pi
      ]

  let comp_sort_object5 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           Comp.Sort_object.RawQualifiedIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         | (location, `Plain identifier) ->
           Comp.Sort_object.RawIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         )
      |> labelled "Computational type constant or term variable"
    and ctype =
      token Token.KW_CTYPE
      |> span
      $> (fun (location, ()) -> Comp.Sort_object.RawCtype { location })
      |> labelled "Computational `ctype' kind"
    and meta_object_of_meta_type =
      (* Needs [trying] because meta-types can be parenthesized, and the
         leading `(' is ambiguous with [parenthesized]. *)
      trying Meta_parsers.meta_thing
      |> span
      $> (fun (location, boxed) -> Comp.Sort_object.RawBox { location; boxed })
      |> labelled "Computational boxed meta-object or meta-type"
    and parenthesized =
      parens Comp_parsers.comp_sort_object
      $> (function
         | Comp.Sort_object.RawIdentifier i ->
           Comp.Sort_object.RawIdentifier { i with quoted = true}
         | Comp.Sort_object.RawQualifiedIdentifier i ->
           Comp.Sort_object.RawQualifiedIdentifier { i with quoted = true}
         | sort -> sort
         )
      |> labelled "Parenthesized computational kind or type"
    in
    choice
      [ constant_or_variable
      ; ctype
      ; meta_object_of_meta_type
      ; parenthesized
      ]

  let comp_sort_object4 =
    some (alt comp_sort_object5 comp_weak_prefix)
    |> span
    $> (function
       | (_, List1.T (object_, [])) -> object_
       | (location, List1.T (o1, o2 :: os)) ->
         let objects = List2.from o1 o2 os in
         Comp.Sort_object.RawApplication { location; objects }
       )
    |> labelled "Atomic computational kind or type, or type application"

  let comp_sort_object3 =
    seq2 comp_sort_object4 (many (token Token.STAR &> comp_sort_object4))
    |> span
    $> (function
       | (_, (object_, [])) -> object_
       | (location, (o1, o2 :: os)) ->
         let operands = List2.from o1 o2 os in
         Comp.Sort_object.RawCross { location; operands })
    |> labelled
         "Atomic computational kind or type, type application or cross type"

  let comp_sort_object2 =
    (* Forward arrows are right-associative, and backward arrows are
       left-associative. Forward and backward arrows have the same
       precedence. Mixing forward and backward arrows at the same precedence
       level is ambiguous. That is, [a -> b <- c] could be parsed as
       [a -> (b <- c)] when parsed from left to right, or as [(a -> b) <- c]
       when parsed from right to left. *)
    let forward_arrow = token Token.ARROW $> fun () -> `Forward_arrow
    and backward_arrow = token Token.BACKARROW $> fun () -> `Backward_arrow
    and right_operand = alt comp_sort_object3 comp_weak_prefix in
    comp_sort_object3 >>= fun object_ ->
    maybe (alt forward_arrow backward_arrow)
    >>= (function
          | Option.None -> return (`Singleton object_)
          | Option.Some `Forward_arrow ->
            (* A forward arrow was parsed. Subsequent backward arrows are
               ambiguous. *)
            let backward_arrow =
              token Token.BACKARROW >>= fun () ->
              fail Ambiguous_backward_arrow
            and forward_arrow = token Token.ARROW in
            let operator = alt backward_arrow forward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Forward_arrows (List1.from object_ (x :: xs))
          | Option.Some `Backward_arrow ->
            (* A backward arrow was parsed. Subsequent forward arrows are
               ambiguous. *)
            let backward_arrow = token Token.BACKARROW
            and forward_arrow =
              token Token.ARROW >>= fun () -> fail Ambiguous_forward_arrow
            in
            let operator = alt forward_arrow backward_arrow in
            seq2 right_operand (many (operator &> right_operand))
            $> fun (x, xs) -> `Backward_arrows (List1.from object_ (x :: xs)))
    $> (function
         | `Singleton x -> x
         | `Forward_arrows xs ->
           List1.fold_right Fun.id
             (fun operand accumulator ->
               let location =
                 Location.join
                   (Comp.location_of_sort_object operand)
                   (Comp.location_of_sort_object accumulator)
               in
               Comp.Sort_object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Forward
                 })
             xs
         | `Backward_arrows (List1.T (x, xs)) ->
           List.fold_left
             (fun accumulator operand ->
               let location =
                 Location.join
                   (Comp.location_of_sort_object accumulator)
                   (Comp.location_of_sort_object operand)
               in
               Comp.Sort_object.RawArrow
                 { location
                 ; domain = operand
                 ; range = accumulator
                 ; orientation = `Backward
                 })
             x xs)
    |> labelled
         "Atomic computational kind or type, type application, cross type, \
          forward or backward arrow"

  let comp_sort_object1 =
    choice
      [ comp_weak_prefix
      ; comp_sort_object2
      ]

  let comp_sort_object = comp_sort_object1

  (*=
      Original grammar:

      <comp-pattern-atomic-object> ::=
        | <identifier>
        | <qualified-identifier>
        | <boxed-meta-object-thing>
        | `(' <comp-pattern-object> (`,' <comp-pattern-object>)+ `)'
        | <dot-qualified-identifier> <comp-pattern-atomic-object>*
        | `_'
        | `(' <comp-pattern-object> `)'

      <comp-pattern-object> ::=
        | <identifier>
        | <qualified-identifier>
        | <boxed-meta-object-thing>
        | `(' <comp-pattern-object> (`,' <comp-pattern-object>)+ `)'
        | <comp-pattern-object> <comp-pattern-object>
        | <dot-qualified-identifier> <comp-pattern-object>*
        | <comp-pattern-object> `:' <comp-type>
        | `{' <omittable-meta-object-identifier> `:' <meta-thing> `}' <comp-pattern-object>
        | `_'
        | `(' <comp-pattern-object> `)'

      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <comp-weak-prefix-pattern> ::=
        | `{' <omittable-meta-object-identifier> `:' <meta-thing> `}' <comp-pattern-object>

      <comp-pattern-object> ::=
        | <comp-pattern-object1>

      <comp-pattern-object1> ::=
        | <comp-weak-prefix-pattern>
        | <comp-pattern-object2>

      <comp-pattern-object2> ::=
        | <comp-pattern-object3> (`:' <comp-type>)+
        | <comp-pattern-object3>

      <comp-pattern-object3> ::=
        | <comp-pattern-object4> (<comp-pattern-object4> | <comp-weak-prefix-pattern>)+
        | <comp-pattern-object4>

      <comp-pattern-object4> ::=
        | <identifier>
        | <qualified-identifier>
        | <boxed-meta-object-thing>
        | <dot-qualified-identifier> <comp-pattern-atomic-object>*
        | `_'
        | `(' <comp-pattern-object> (`,' <comp-pattern-object>)+ `)'
        | `(' <comp-pattern-object> `)'
  *)
  let comp_pattern_atomic_object =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           Comp.Pattern_object.RawQualifiedIdentifier
             { location
             ; identifier
             ; observation = false
             ; quoted = false
             }
         | (location, `Plain identifier) ->
           Comp.Pattern_object.RawIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         )
      |> labelled "Computational type constant or term variable"
    and box =
      Meta_parsers.meta_thing
      |> span
      $> (fun (location, pattern) ->
            Comp.Pattern_object.RawBox { location; pattern }
         )
      |> labelled "Meta-object pattern"
    and observation =
      seq2 dot_qualified_identifier (many Comp_parsers.comp_pattern_atomic_object)
      |> span
      $> (fun (location, (constant, arguments)) ->
            Comp.Pattern_object.RawObservation { location; constant; arguments }
         )
    and wildcard =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> Comp.Pattern_object.RawWildcard { location })
      |> labelled "Computational wildcard pattern"
    and parenthesized_or_tuple =
      parens (sep_by1 Comp_parsers.comp_pattern_object (token Token.COMMA))
      |> span
      $> (function
         | (_, List1.T (Comp.Pattern_object.RawIdentifier i, [])) ->
          Comp.Pattern_object.RawIdentifier { i with quoted = true }
         | (_, List1.T (Comp.Pattern_object.RawQualifiedIdentifier i, [])) ->
          Comp.Pattern_object.RawQualifiedIdentifier { i with quoted = true }
         | (_, List1.T (pattern, [])) -> pattern
         | (location, List1.T (p1, p2 :: ps)) ->
           let elements = List2.from p1 p2 ps in
           Comp.Pattern_object.RawTuple { location; elements }
         )
      |> labelled "Computational tuple pattern or parenthesized pattern"
    in
    choice
      [ constant_or_variable
      ; box
      ; observation
      ; wildcard
      ; parenthesized_or_tuple
      ]

  let comp_weak_prefix_pattern =
    let pi =
      seq2
        (braces
          (seq2
            omittable_meta_object_identifier
            (maybe (token Token.COLON &> Meta_parsers.meta_thing))))
        Comp_parsers.comp_pattern_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_typ), pattern)) ->
         Comp.Pattern_object.RawMetaAnnotated
           { location
           ; parameter_identifier
           ; parameter_typ
           ; pattern
           })
      |> labelled "Explicit computational Pi kind or type"
    in
    pi

  let comp_pattern_object4 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           Comp.Pattern_object.RawQualifiedIdentifier
             { location
             ; identifier
             ; observation = false
             ; quoted = false
             }
         | (location, `Plain identifier) ->
           Comp.Pattern_object.RawIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         )
      |> labelled "Computational type constant or term variable"
    and box =
      Meta_parsers.meta_thing
      |> span
      $> (fun (location, pattern) ->
            Comp.Pattern_object.RawBox { location; pattern }
         )
      |> labelled "Meta-object pattern"
    and observation =
      seq2 dot_qualified_identifier (many Comp_parsers.comp_pattern_atomic_object)
      |> span
      $> (fun (location, (constant, arguments)) ->
            Comp.Pattern_object.RawObservation { location; constant; arguments }
         )
    and wildcard =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> Comp.Pattern_object.RawWildcard { location })
      |> labelled "Computational wildcard pattern"
    and parenthesized_or_tuple =
      parens (sep_by1 Comp_parsers.comp_pattern_object (token Token.COMMA))
      |> span
      $> (function
         | (_, List1.T (Comp.Pattern_object.RawIdentifier i, [])) ->
          Comp.Pattern_object.RawIdentifier { i with quoted = true }
         | (_, List1.T (Comp.Pattern_object.RawQualifiedIdentifier i, [])) ->
          Comp.Pattern_object.RawQualifiedIdentifier { i with quoted = true }
         | (_, List1.T (pattern, [])) -> pattern
         | (location, List1.T (p1, p2 :: ps)) ->
           let elements = List2.from p1 p2 ps in
           Comp.Pattern_object.RawTuple { location; elements }
         )
      |> labelled "Computational tuple pattern or parenthesized pattern"
    in
    choice
      [ constant_or_variable
      ; box
      ; observation
      ; wildcard
      ; parenthesized_or_tuple
      ]

  let comp_pattern_object3 =
    some (alt comp_pattern_object4 comp_weak_prefix_pattern)
    |> span
    $> (function
       | (_, List1.T (pattern, [])) -> pattern
       | (location, List1.T (p1, p2 :: ps)) ->
         let patterns = List2.from p1 p2 ps in
         Comp.Pattern_object.RawApplication { location; patterns })
    |> labelled "Computational atomic or application pattern"

  let comp_pattern_object2 =
    let annotation =
      token Token.COLON &> comp_sort_object
    in
    let trailing_annotations =
      many (span annotation)
    in
    seq2 comp_pattern_object3 trailing_annotations
    $> (function
       | (pattern, []) -> pattern
       | (pattern, annotations) ->
         List.fold_left
           (fun accumulator (sort_location, typ) ->
             let location =
               Location.join
                 (Comp.location_of_pattern_object accumulator)
                 sort_location
             in
             Comp.Pattern_object.RawAnnotated
               { location
               ; pattern = accumulator
               ; typ
               }
           )
           pattern
           annotations
       )
    |> labelled "Computational annotated, atomic, application or pattern"

  let comp_pattern_object1 =
    choice
      [ comp_weak_prefix_pattern
      ; comp_pattern_object2
      ]

  let comp_pattern_object = comp_pattern_object1

  (*=
      Original grammar:

      <comp-expression-object> ::=
        | <identifier>
        | <qualified-identifier>
        | `fn' <omittable-identifier>+ <thick-forward-arrow> <comp-expression>
        | `fun' [`|'] <comp-pattern-atomic-object>+ <thick-forward-arrow> <comp-expression-object>
          (`|' <comp-pattern-atomic-object>+ <thick-forward-arrow> <comp-expression-object>)*
        | `mlam' <omittable-meta-object-identifier>+ <thick-forward-arrow> <comp-expression-object>
        | `let' <comp-pattern-object> `=' <comp-expression-object> `in' <comp-expression-object>
        | <boxed-meta-object-thing>
        | `impossible' <comp-expression-object>
        | `case' <comp-expression-object> [`--not'] `of'
          [`|'] <comp-pattern-object> <thick-forward-arrow> <comp-expression-object>
          (`|' <comp-pattern-object> <thick-forward-arrow> <comp-expression-object>)*
        | `(' <comp-expression-object> (`,' <comp-expression-object>)+ `)'
        | `?' [<identifier>]
        | `_'
        | <comp-expression-object> <comp-expression-object>
        | <qualified-identifier> <comp-expression-object>*
        | <comp-expression-object> `:' <comp-type>
        | `(' <comp-expression-object> `)'

      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.

      <comp-expression-object> ::=
        | <comp-expression-object1>

      <comp-expression-object1> ::=
        | <comp-expression-object2> (`:' <comp-sort-object>)+
        | <comp-expression-object2>

      <comp-expression-object2> ::=
        | <comp-expression-object3> <comp-expression-object3>+
        | <comp-expression-object3>

      <comp-expression-object3> ::=
        | <identifier>
        | <qualified-identifier>
        | `fn' <omittable-identifier>+ <thick-forward-arrow> <comp-expression>
        | `fun' [`|'] <comp-pattern-atomic-object>+ <thick-forward-arrow> <comp-expression-object>
          (`|' <comp-pattern-atomic-object>+ <thick-forward-arrow> <comp-expression-object>)*
        | `mlam' <omittable-meta-object-identifier>+ <thick-forward-arrow> <comp-expression-object>
        | `let' <comp-pattern-object> `=' <comp-expression-object> `in' <comp-expression-object>
        | <boxed-meta-object-thing>
        | `impossible' <comp-expression-object>
        | `case' <comp-expression-object> [`--not'] `of'
          [`|'] <comp-pattern-object> <thick-forward-arrow> <comp-expression-object>
          (`|' <comp-pattern-object> <thick-forward-arrow> <comp-expression-object>)*
        | `?' [<identifier>]
        | `_'
        | `(' <comp-expression-object> (`,' <comp-expression-object>)+ `)'
        | `(' <comp-expression-object> `)'
  *)
  let comp_expression_object3 =
    let comma_opt =
      (* Optionally parse a comma, for backwards compatibility with
         `fn x1, x2, ..., xn => e' and `mlam X1, X2, ..., Xn => e'. *)
      void (maybe (token Token.COMMA))
    in
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           Comp.Expression_object.RawQualifiedIdentifier
             { location
             ; identifier
             ; observation = false
             ; quoted = false
             }
         | (location, `Plain identifier) ->
           Comp.Expression_object.RawIdentifier
             { location
             ; identifier
             ; quoted = false
             }
         )
      |> labelled "Computational type constant or term variable"
    and fn =
      seq2
        (token Token.KW_FN &> sep_by1 omittable_identifier comma_opt)
        (token Token.THICK_ARROW &> Comp_parsers.comp_expression_object)
      |> span
      $> (fun (location, (parameters, body)) ->
           Comp.Expression_object.RawFn { location; parameters; body }
         )
      |> labelled "Ordinary function abstraction"
    and matching_fun =
      token Token.KW_FUN
      &> maybe (token Token.PIPE)
      &> sep_by1
        (seq2
          (sep_by1 Comp_parsers.comp_pattern_atomic_object comma_opt)
          (token Token.THICK_ARROW &> Comp_parsers.comp_expression_object))
        (token Token.PIPE)
      |> span
      $> (fun (location, branches) ->
           Comp.Expression_object.RawFun { location; branches }
         )
      |> labelled "Pattern-matching function abstraction"
    and mlam =
      seq2
        (token Token.KW_FN &> some omittable_meta_object_identifier)
        (token Token.THICK_ARROW &> Comp_parsers.comp_expression_object)
      |> span
      $> (fun (location, (parameters, body)) ->
           Comp.Expression_object.RawMlam { location; parameters; body }
         )
      |> labelled "Meta-level function abstraction"
    and let_ =
      seq3
        (token Token.KW_LET &> Comp_parsers.comp_pattern_object)
        (token Token.EQUALS &> Comp_parsers.comp_expression_object)
        (token Token.KW_IN &> Comp_parsers.comp_expression_object)
      |> span
      $> (fun (location, (pattern, scrutinee, body)) ->
           Comp.Expression_object.RawLet { location; pattern; scrutinee; body }
         )
      |> labelled "`let'-expressions"
    and impossible =
      token Token.KW_IMPOSSIBLE &> Comp_parsers.comp_expression_object
      |> span
      $> (fun (location, scrutinee) ->
           Comp.Expression_object.RawImpossible { location; scrutinee }
         )
      |> labelled "Empty `impossible' case analysis"
    and box =
      Meta_parsers.meta_thing
      |> span
      $> (fun (location, meta_object) ->
           Comp.Expression_object.RawBox { location; meta_object }
         )
      |> labelled "Boxed meta-object"
    and case =
      seq3
        (token Token.KW_CASE &> Comp_parsers.comp_expression_object)
        (token Token.KW_OF &> maybe (pragma "not"))
        (maybe (token Token.PIPE)
        &> sep_by1
          (seq2
            Comp_parsers.comp_pattern_object
            (token Token.THICK_ARROW &> Comp_parsers.comp_expression_object))
          (token Token.PIPE))
      |> span
      $> (fun (location, (scrutinee, check_coverage, branches)) ->
           let check_coverage = Option.is_some check_coverage in
           Comp.Expression_object.RawCase
             { location
             ; scrutinee
             ; check_coverage
             ; branches
             }
         )
      |> labelled "Pattern-matching expression"
    and hole =
      hole
      |> span
      $> (function
         | (location, `Unlabelled) ->
           let label = Option.none in
           Comp.Expression_object.RawHole { location; label }
         | (location, `Labelled label) ->
           let label = Option.some label in
           Comp.Expression_object.RawHole { location; label }
         )
      |> labelled "Computational hole"
    and box_hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> Comp.Expression_object.RawBoxHole { location })
      |> labelled "Box hole"
    and parenthesized_or_tuple =
      parens (sep_by1 Comp_parsers.comp_expression_object (token Token.COMMA))
      |> span
      $> (function
         | (_, List1.T (Comp.Expression_object.RawIdentifier i, [])) ->
          Comp.Expression_object.RawIdentifier { i with quoted = true }
         | (_, List1.T (Comp.Expression_object.RawQualifiedIdentifier i, [])) ->
          Comp.Expression_object.RawQualifiedIdentifier { i with quoted = true }
         | (_, List1.T (pattern, [])) -> pattern
         | (location, List1.T (p1, p2 :: ps)) ->
           let elements = List2.from p1 p2 ps in
           Comp.Expression_object.RawTuple { location; elements }
         )
      |> labelled "Computational tuple or parenthesized expression"
    in
    choice
      [ constant_or_variable
      ; fn
      ; matching_fun
      ; mlam
      ; let_
      ; impossible
      ; box
      ; case
      ; hole
      ; box_hole
      ; parenthesized_or_tuple
      ]

  let comp_expression_object2 =
    some comp_expression_object3
    |> span
    $> (function
       | (_, List1.T (expression, [])) -> expression
       | (location, List1.T (x1, x2 :: xs)) ->
         let expressions = List2.from x1 x2 xs in
         Comp.Expression_object.RawApplication { location; expressions }
       )
    |> labelled "Atomic computational expression or application"

  let comp_expression_object1 =
    let annotation =
      token Token.COLON &> comp_sort_object
    in
    let trailing_annotations =
      many (span annotation)
    in
    seq2 comp_expression_object2 trailing_annotations
    $> (function
       | (expression, []) -> expression
       | (expression, annotations) ->
         List.fold_left
           (fun accumulator (sort_location, typ) ->
             let location =
               Location.join
                 (Comp.location_of_expression_object accumulator)
                 sort_location
             in
             Comp.Expression_object.RawAnnotated
               { location
               ; expression = accumulator
               ; typ
               }
           )
           expression
           annotations
       )
    |> labelled "Possibly annotated computational expression"

  let comp_expression_object = comp_expression_object1

  (*=
      <comp-context> ::=
        | [`^']
        | <identifier> [`:' <comp-type>] (`,' <identifier> [`:' <comp-type>])*
  *)
  let comp_context =
    let non_empty =
      sep_by0
        (seq2 identifier (maybe (token Token.COLON &> Comp_parsers.comp_sort_object)))
        (token Token.COMMA)
      |> span
      $> fun (location, bindings) ->
        { Comp.Context_object.location; bindings }
    and empty =
      maybe (token Token.HAT)
      |> span
      $> fun (location, _) ->
        { Comp.Context_object.location; bindings = [] }
    in
    choice
      [ non_empty
      ; empty
      ]
end

let comp_sort_object = Comp_parsers.comp_sort_object

let comp_pattern_object = Comp_parsers.comp_pattern_object

let comp_expression_object = Comp_parsers.comp_expression_object

let comp_context = Comp_parsers.comp_context

module rec Harpoon_parsers : sig
  val harpoon_proof : Harpoon.Proof.t t
  val interactive_harpoon_command : Harpoon.Repl.Command.t t
  val interactive_harpoon_command_sequence : Harpoon.Repl.Command.t List.t t
  val next_theorem : [> `next of Identifier.t | `quit ] t
end = struct
  let boxity =
    let boxed =
      keyword "boxed"
      $> fun () -> `Boxed
    and unboxed =
      keyword "unboxed"
      $> fun () -> `Unboxed
    and strengthened =
      keyword "strengthened"
      $> fun () -> `Strengthened
    in
    choice
      [ boxed
      ; unboxed
      ; strengthened
      ]

  let harpoon_command =
    let by =
      token Token.KW_BY &>
        seq3
          (Comp_parsers.comp_expression_object <& token Token.KW_AS)
          identifier
          (maybe_default boxity ~default:`Boxed)
      |> span
      |> labelled "Harpoon command"
      $> function
         | (location, (expression, assignee, `Boxed)) ->
           Harpoon.Command.By { location; assignee; expression }
         | (location, (expression, assignee, `Unboxed)) ->
           Harpoon.Command.Unbox
             { location
             ; assignee
             ; expression
             ; modifier = Option.none
             }
         | (location, (expression, assignee, `Strengthened)) ->
           Harpoon.Command.Unbox
             { location
             ; assignee
             ; expression
             ; modifier = Option.some `Strengthened
             }
    and unbox =
      keyword "unbox" &>
        seq2
          ((span Comp_parsers.comp_expression_object) <& token Token.KW_AS)
          identifier
      $> fun ((location, expression), assignee) ->
           Harpoon.Command.Unbox
             { location
             ; assignee
             ; expression
             ; modifier = Option.none
             }
    and strengthen =
      keyword "strengthen" &>
        seq2
          (span Comp_parsers.comp_expression_object <& token Token.KW_AS)
          identifier
      $> fun ((location, expression), assignee) ->
           Harpoon.Command.Unbox
             { location
             ; assignee
             ; expression
             ; modifier = Option.some `Strengthened
             }
    in
    choice
      [ by
      ; unbox
      ; strengthen
      ]

  let split_branch_label =
    let extension_case_label =
      trying (keyword "extended" &> token Token.KW_BY) &> integer
      |> span
      |> labelled "context extension case label"
      $> fun (location, schema_element) ->
          Harpoon.Split_branch.Label.Extended_context
            { location
            ; schema_element
            }
    and empty_case_label =
      trying (keyword "empty" &> keyword "context")
      |> span
      |> labelled "empty context case label"
      $> fun (location, ()) ->
          Harpoon.Split_branch.Label.Empty_context { location }
    and constant_case_label =
      qualified_identifier
      |> span
      |> labelled "constructor case label"
      $> fun (location, identifier) ->
           Harpoon.Split_branch.Label.Constant { location; identifier }
    and pvar_case_label =
      token Token.HASH &>
        seq2
          (maybe_default integer ~default:1)
          (maybe dot_integer)
      |> span
      |> labelled "parameter variable case label"
      $> fun (location, (n, k)) ->
          Harpoon.Split_branch.Label.Parameter_variable
            { location
            ; schema_element = n
            ; projection = k
            }
    and bvar_case_label =
      trying (keyword "head" &> keyword "variable")
      |> span
      $> fun (location, ()) ->
          Harpoon.Split_branch.Label.Bound_variable { location }
    in
    choice
      [ bvar_case_label
      ; extension_case_label
      ; empty_case_label
      ; constant_case_label
      ; pvar_case_label
      ]

  let harpoon_hypothetical =
    let hypotheses =
      seq3 Meta_parsers.meta_context (token Token.PIPE) Comp_parsers.comp_context
    in
    seq2
      (hypotheses <& token Token.SEMICOLON)
      Harpoon_parsers.harpoon_proof
    |> braces
    |> span
    |> labelled "Harpoon hypothetical"
    $> fun (location, ((meta_context, (), comp_context), proof)) ->
        { Harpoon.Hypothetical.location; meta_context; comp_context; proof }

  let harpoon_split_branch =
    token Token.KW_CASE &>
      seq2
        (split_branch_label <& token Token.COLON)
        harpoon_hypothetical
    |> span
    |> labelled "Harpoon split branch"
    $> fun (location, (label, body)) ->
        { Harpoon.Split_branch.location; label; body }

  let harpoon_directive =
    let intros =
      keyword "intros" &> harpoon_hypothetical
      |> span
      $> fun (location, hypothetical) ->
           Harpoon.Directive.Intros { location; hypothetical }
    and solve =
      keyword "solve" &> Comp_parsers.comp_expression_object
      |> span
      $> fun (location, solution) ->
           Harpoon.Directive.Solve { location; solution }
    and split =
      keyword "split"
      &> seq2
        Comp_parsers.comp_expression_object
        (token Token.KW_AS &> some harpoon_split_branch)
      |> span
      $> fun (location, (scrutinee, branches)) ->
           Harpoon.Directive.Split { location; scrutinee; branches }
    and impossible =
      token Token.KW_IMPOSSIBLE &> Comp_parsers.comp_expression_object
      |> span
      $> fun (location, scrutinee) ->
           Harpoon.Directive.Impossible { location; scrutinee }
    and suffices =
      let suffices_branch =
        seq2 Comp_parsers.comp_sort_object (braces Harpoon_parsers.harpoon_proof)
        |> span
        $> fun (location, (goal, proof)) ->
          { Harpoon.Suffices_branch.location; goal; proof }
      in
      tokens [ Token.KW_SUFFICES; Token.KW_BY ] &>
        seq2
          (Comp_parsers.comp_expression_object <& token Token.KW_TOSHOW)
          (many suffices_branch)
      |> span
      $> fun (location, (scrutinee, branches)) ->
           Harpoon.Directive.Suffices { location; scrutinee; branches }
    in
    choice
      [ intros
      ; solve
      ; split
      ; impossible
      ; suffices
      ]
    |> shifted "Harpoon directive"

  let harpoon_proof =
    let incomplete_proof =
      hole
      |> span
      |> labelled "Harpoon incomplete proof `?'"
      $> function
         | (location, `Unlabelled) ->
           Harpoon.Proof.Incomplete { location; label = Option.none }
         | (location, `Labelled label) ->
           Harpoon.Proof.Incomplete { location; label = Option.some label }
    and command_proof =
      seq2
        (harpoon_command <& token Token.SEMICOLON)
        Harpoon_parsers.harpoon_proof
      |> span
      $> fun (location, (command, body)) ->
           Harpoon.Proof.Command { location; command; body }
    and directive_proof =
      harpoon_directive
      |> span
      $> fun (location, directive) ->
           Harpoon.Proof.Directive { location; directive }
    in
    choice
      [ incomplete_proof
      ; command_proof
      ; directive_proof
      ]
    |> labelled "Harpoon proof"

  let interactive_harpoon_command =
    let intros =
      keyword "intros"
      &> maybe (some identifier')
      $> fun xs -> Harpoon.Intros (Option.map List1.to_list xs)
    in
    let split =
      keyword "split"
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Split { scrutinee }
    in
    let msplit =
      keyword "msplit"
      &> span (choice [ dollar_name; hash_name; name ])
      $> fun (loc, name) -> Harpoon.MSplit (loc, name)
    in
    let invert =
      keyword "invert"
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Invert { scrutinee }
    in
    let impossible =
      token Token.KW_IMPOSSIBLE
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Impossible { scrutinee }
    in
    let solve =
      keyword "solve"
      &> cmp_exp_chk
      $> fun t -> Harpoon.Solve t
    in
    let by =
      token Token.KW_BY &>
        seq3
          Comp_parsers.comp_expression_object
          (token Token.KW_AS &> identifier)
          (maybe_default boxity ~default:`Boxed)
      |> span
      $> function
          | (location, (expression, assignee, `Boxed)) ->
            Harpoon.Repl.Command.By { location; assignee; expression }
          | (location, (expression, assignee, `Unboxed)) ->
            Harpoon.Repl.Command.Unbox
              { location
              ; assignee
              ; expression
              ; modifier = Option.none
              }
          | (location, (expression, assignee, `Strengthened)) ->
            Harpoon.Repl.Command.Unbox
              { location
              ; assignee
              ; expression
              ; modifier = Option.some `Strengthened
              }
    and compute_type =
      token Token.KW_TYPE
      &> Comp_parsers.comp_expression_object
      |> span
      $> fun (location, scrutinee) ->
        Harpoon.Repl.Command.Type { location; scrutinee }
    and suffices =
      let tau_list_item =
        alt
          (Comp_parsers.comp_sort_object $> fun tau -> `exact tau)
          (token Token.UNDERSCORE |> span $> fun (loc, ()) -> `infer loc)
      in
      seq2
        (tokens [ Token.KW_SUFFICES; Token.KW_BY ]
        &> Comp_parsers.comp_expression_object)
        (token Token.KW_TOSHOW
        &> sep_by0 tau_list_item (token Token.COMMA))
      |> span
      $> fun (location, (implication, goal_premises)) ->
        Harpoon.Repl.Command.Suffices { location; implication; goal_premises }
    and unbox =
      keyword "unbox" &>
        seq2
          Comp_parsers.comp_expression_object
          (token Token.KW_AS &> identifier)
      |> span
      $> fun (location, (expression, assignee)) ->
          Harpoon.Repl.Command.Unbox
            { location
            ; expression
            ; assignee
            ; modifier = Option.none
            }
    and strengthen =
      keyword "strengthen" &>
        seq2
          Comp_parsers.comp_expression_object
          (token Token.KW_AS &> identifier)
      |> span
      $> fun (location, (expression, assignee)) ->
          Harpoon.Repl.Command.Unbox
            { location
            ; expression
            ; assignee
            ; modifier = Option.some `Strengthened
            }
    and toggle_automation =
      let automation_kind =
        let auto_intros =
          keyword "auto-intros"
          $> fun () -> `auto_intros
        and auto_solve_trivial =
          keyword "auto-solve-trivial"
          $> fun () -> `auto_solve_trivial
        in
        choice
          [ auto_intros
          ; auto_solve_trivial
          ]
      and automation_change =
        let on =
          keyword "on"
          $> fun () -> `on
        and off =
          keyword "off"
          $> fun () -> `off
        and toggle =
          keyword "toggle"
          $> fun () -> `toggle
        in
        choice
          [ on
          ; off
          ; toggle
          ]
      in
      keyword "toggle-automation"
      &> seq2 automation_kind (maybe_default automation_change ~default:`toggle)
      |> span
      $> fun (location, (kind, change)) ->
        Harpoon.Repl.Command.ToggleAutomation { location; kind; change }
    and rename =
      let level =
        let comp_level =
          keyword "comp"
          $> fun () -> `comp
        and meta_level =
          keyword "meta"
          $> fun () -> `meta
        in
        choice
          [ comp_level
          ; meta_level
          ]
      in
      keyword "rename" &> seq3 level identifier identifier
      |> span
      $> fun (location, (level, rename_from, rename_to)) ->
           Harpoon.Repl.Command.Rename
             { location
             ; rename_from
             ; rename_to
             ; level
             }
    and select_theorem =
      keyword "select" &> qualified_identifier
      |> span
      $> fun (location, theorem) ->
          Harpoon.Repl.Command.SelectTheorem { location; theorem }
    and theorem_command =
      let list_theorems =
        keyword "list"
        $> fun () -> `list
      and defer_theorem =
        keyword "defer"
        $> fun () -> `defer
      and dump_proof =
        keyword "dump-proof"
        &> string_literal
        $> fun s -> `dump_proof s
      and show_ihs =
        keyword "show-ihs"
        $> fun () -> `show_ihs
      and show_proof =
        keyword "show-proof"
        $> fun () -> `show_proof
      in
      keyword "theorem"
      &> choice
          [ list_theorems
          ; defer_theorem
          ; dump_proof
          ; show_ihs
          ; show_proof
          ]
      |> span
      $> fun (location, subcommand) ->
        Harpoon.Repl.Command.Theorem { location; subcommand }
    and session_command =
      let list_sessions =
        keyword "list"
        $> fun () -> `list
      and defer_session =
        keyword "defer"
        $> fun () -> `defer
      and create_command =
        keyword "create"
        $> fun () -> `create
      and serialize_command =
        keyword "serialize"
        $> fun () -> `serialize
      in
      keyword "session"
      &> choice
          [ list_sessions
          ; defer_session
          ; create_command
          ; serialize_command
          ]
      |> span
      $> fun (location, subcommand) ->
        Harpoon.Repl.Command.Session { location; subcommand }
    and subgoal_command =
      let list_subgoals =
        keyword "list"
        $> fun () -> `list
      and defer_subgoal =
        keyword "defer"
        $> fun () -> `defer
      in
      keyword "subgoal"
      &> choice
          [ list_subgoals
          ; defer_subgoal
          ]
      |> span
      $> fun (location, subcommand) ->
        Harpoon.Repl.Command.Subgoal { location; subcommand }
    and defer =
      keyword "defer"
      |> span
      $> fun (location, ()) ->
        Harpoon.Repl.Command.Subgoal { location; subcommand = `defer }
    and info =
      let theorem =
        keyword "theorem"
        $> fun () -> `prog
      in
      let info_kind =
        choice [ theorem ]
      in
      keyword "info" &> seq2 info_kind qualified_identifier
      |> span
      $> fun (location, (kind, object_identifier)) ->
          Harpoon.Repl.Command.Info { location; kind; object_identifier }
    and translate =
      keyword "translate" &> qualified_identifier
      |> span
      $> fun (location, theorem) ->
        Harpoon.Repl.Command.Translate { location; theorem }
    and undo =
      keyword "undo"
      |> span
      $> fun (location, ()) -> Harpoon.Repl.Command.Undo { location }
    and redo =
      keyword "redo"
      |> span
      $> fun (location, ()) -> Harpoon.Repl.Command.Redo { location }
    and history =
      keyword "history"
      |> span
      $> fun (location, ()) -> Harpoon.Repl.Command.History { location }
    and help =
      keyword "help"
      |> span
      $> fun (location, ()) -> Harpoon.Repl.Command.Help { location }
    and save =
      keyword "save"
      |> span
      $> fun (location, ()) ->
        Harpoon.Repl.Command.Session { location; subcommand = `serialize}
    in
    choice
      [ intros
      ; info
      ; split
      ; msplit
      ; compute_type
      ; invert
      ; impossible
      ; solve
      ; auto_invert_solve
      ; inductive_auto_solve
      ; by
      ; suffices
      ; unbox
      ; strengthen
      ; translate
      ; toggle_automation
      ; rename
      ; defer
      ; select_theorem
      ; theorem_command
      ; session_command
      ; subgoal_command
      ; undo
      ; redo
      ; history
      ; help
      ; save
      ]

  let interactive_harpoon_command_sequence =
    sep_by0 interactive_harpoon_command (token Token.SEMICOLON)

  let next_theorem =
    let quit =
      token Token.COLON &> keyword "quit"
      $> fun () -> `quit
    and next =
      identifier
      $> fun name -> `next name
    in
    choice
      [ quit
      ; next
      ]
end

let interactive_harpoon_command = Harpoon_parsers.interactive_harpoon_command

let interactive_harpoon_command_sequence =
  Harpoon_parsers.interactive_harpoon_command_sequence

let next_theorem = Harpoon_parsers.next_theorem

module rec Signature_parsers : sig
  val sgn : Signature.t t

  val sgn_decl : Signature.Declaration.t t

  val trust_totality_declaration : Signature.Totality.Declaration.t t

  val named_totality_declaration : Signature.Totality.Declaration.t t

  val numeric_totality_declaration : Signature.Totality.Declaration.t t

  val totality_declaration : Signature.Totality.Declaration.t t
end = struct
  let nostrenghten_pragma =
    pragma "nostrengthen"
    |> span
    $> fun (location, ()) ->
      Signature.Pragma.Global.No_strengthening { location }

  let coverage_pragma =
    pragma "coverage"
    |> span
    $> fun (location, ()) ->
      Signature.Pragma.Global.Coverage { location; variant = `Error }

  let warncoverage_pragma =
    pragma "warncoverage"
    |> span
    $> fun (location, ()) ->
      Signature.Pragma.Global.Coverage { location; variant = `Warn }

  let sgn_global_prag =
    let global_pragma_to_global_pragma_declaration pragma =
      pragma
      |> span
      $> fun (location, pragma) ->
        Signature.Declaration.GlobalPragma { location; pragma }
    in
    let global_pragmas =
      [ nostrenghten_pragma
      ; coverage_pragma
      ; warncoverage_pragma
      ]
    in
    let global_pragma_declarations =
      global_pragmas
      |> List.map global_pragma_to_global_pragma_declaration
    in
    choice global_pragma_declarations
    |> labelled "global pragma"

  let name_pragma =
    seq3
      (pragma "name" &> qualified_identifier)
      identifier
      (maybe identifier <& token Token.DOT)
    |> labelled "name pragma"
    |> span
    $> fun (location, (constant, meta_variable_base, computation_variable_base)) ->
          Signature.Pragma.Name
            { location
            ; constant
            ; meta_variable_base
            ; computation_variable_base
            }

  let sgn_lf_const_decl =
    seq2
      (identifier <& token Token.COLON)
      LF_parsers.lf_object
    |> span
    $> (fun (location, (identifier, typ)) ->
          Signature.Declaration.Const { location; identifier; typ })
    |> labelled "LF term-level constant declaration"

  let sgn_lf_typ_decl =
    let lf_typ_decl_body =
      let typ_decl =
        seq2
          (identifier <& token Token.COLON)
          LF_parsers.lf_object
      in
      seq2
        (typ_decl <& token Token.EQUALS)
        (maybe (token Token.PIPE)
        &> sep_by0 sgn_lf_const_decl (token Token.PIPE))
      |> span
      $> fun (location, ((identifier, kind), constructor_declarations)) ->
        let typ_declaration =
          Signature.Declaration.Typ { location; identifier; kind }
        in
        List1.from typ_declaration constructor_declarations
    in
    token Token.KW_LF
      &> (sep_by1 lf_typ_decl_body (token Token.KW_AND &> maybe (token Token.KW_LF) |> void))
      <& token Token.SEMICOLON
    |> span
    $> (fun (location, declarations) ->
        let declarations' = List1.flatten declarations in
        Signature.Declaration.Recursive_declarations
          { location
          ; declarations = declarations'
          })
    |> labelled "LF type declaration block"

  let named_totality_argument =
    identifier
    |> span
    $> fun (location, argument) ->
        Signature.Totality.Order.Argument { location; argument }

  let numeric_totality_argument =
    integer
    |> span
    $> fun (location, argument) ->
        Signature.Totality.Order.Argument { location; argument }

  let total_order totality_argument =
    let argument =
      totality_argument
    and lexical_ordering =
      braces (some totality_argument)
      |> span
      $> fun (location, arguments) ->
        Signature.Totality.Order.Lexical_ordering { location; arguments }
    and simultaneous_ordering =
      bracks (some totality_argument)
      |> span
      $> fun (location, arguments) ->
        Signature.Totality.Order.Simultaneous_ordering { location; arguments }
    in
    choice
      [ argument
      ; lexical_ordering
      ; simultaneous_ordering
      ]
    |> labelled "totality ordering"

  let trust_totality_declaration =
    token Token.KW_TRUST
    |> span
    $> (fun (location, ()) -> Signature.Totality.Declaration.Trust { location })
    |> labelled "trust totality"

  let named_totality_declaration =
    seq2
      (trying (maybe (total_order named_totality_argument)))
      (parens (seq2 identifier (many omittable_identifier)))
    |> span
    $> fun (location, (order, (program, argument_labels))) ->
        Signature.Totality.Declaration.Named { location; order; program; argument_labels }

  let numeric_totality_declaration =
    maybe (total_order numeric_totality_argument)
    |> span
    $> fun (location, order) ->
      Signature.Totality.Declaration.Numeric { location; order }

  let totality_declaration =
    let total =
      token Token.KW_TOTAL
      &> alt named_totality_declaration numeric_totality_declaration
    in
    alt trust_totality_declaration total
    |> labelled "totality declaration"

  (** Mutual block of computation type declarations. *)
  let sgn_cmp_typ_decl =
    let cmp_typ_decl =
      let inductive =
        token Token.KW_INDUCTIVE
        $> fun () -> `Inductive
      and stratified =
        token Token.KW_STRATIFIED
        $> fun () -> `Stratified
      in
      let flavour =
        choice
          [ inductive
          ; stratified
          ]
      in
      let sgn_cmp_typ_decl_body =
        seq2
          (identifier <& token (Token.COLON))
          Comp_parsers.comp_sort_object
        |> span
        $> fun (location, (identifier, typ)) ->
            Signature.Declaration.CompConst { location; identifier; typ }
      in
      seq4
        flavour
        (identifier <& token (Token.COLON))
        (Comp_parsers.comp_sort_object <& token (Token.EQUALS) <& maybe (token (Token.PIPE)))
        (sep_by0 sgn_cmp_typ_decl_body (token Token.PIPE))
      |> span
      $> fun (location, (datatype_flavour, identifier, kind, constructor_declarations)) ->
            let typ_declaration =
              Signature.Declaration.CompTyp { location; identifier; kind; datatype_flavour }
            in
            List1.from typ_declaration constructor_declarations
    in
    let cmp_cotyp_decl =
      let cmp_cotyp_body =
        seq2
          (opt_parens
              (seq2
                (identifier <& token Token.COLON)
                Comp_parsers.comp_sort_object)
            <& token Token.DOUBLE_COLON)
          Comp_parsers.comp_sort_object
        |> span
        $> fun (location, ((identifier, observation_type), return_type)) ->
            Signature.Declaration.CompDest
            { location
            ; identifier
            ; observation_type
            ; return_type
            }
      in
      seq3
        (token Token.KW_COINDUCTIVE &> identifier <& token Token.COLON)
        (Comp_parsers.comp_sort_object <& token Token.EQUALS <& maybe (token Token.PIPE))
        (sep_by0 cmp_cotyp_body (token Token.PIPE))
      |> span
      $> fun (location, (identifier, kind, destructor_declarations)) ->
            let cotyp_declaration =
              Signature.Declaration.CompCotyp { location; identifier; kind }
            in List1.from cotyp_declaration destructor_declarations
    in
    sep_by1 (alt cmp_typ_decl cmp_cotyp_decl) (token Token.KW_AND)
    <& token Token.SEMICOLON
    |> span
    $> (fun (location, declarations) ->
      let declarations' = List1.flatten declarations in
      Signature.Declaration.Recursive_declarations
        { location
        ; declarations = declarations'
        })
    |> labelled "Inductive or stratified computation type declaration"

  let query_declaration =
    let bound =
      alt
        (token Token.STAR $> fun () -> Option.none)
        (integer $> Option.some)
      |> labelled "search bound"
    and meta_context =
      many
        (braces
          (seq2
            meta_object_identifier
            (maybe (token Token.COLON &> Meta_parsers.meta_thing))))
      |> span
      $> fun (location, bindings) ->
        { Meta.Context_object.location; bindings }
    in
    pragma "query"
    &> seq4
        (seq2 bound bound)
        meta_context
        (maybe (identifier <& token Token.COLON))
        LF_parsers.lf_object
    <& token Token.DOT
    |> span
    |> labelled "logic programming engine query pragma"
    $> fun (location, ((expected_solutions, maximum_tries), meta_context, identifier, typ)) ->
       Signature.Declaration.Query
         { location
         ; identifier
         ; meta_context
         ; typ
         ; expected_solutions
         ; maximum_tries
         }

  let sgn_mquery_pragma =
    let bound =
      alt
        (token Token.STAR &> return Option.none)
        (integer $> Option.some)
      |> labelled "search bound"
    in
    pragma "mquery"
    &> seq3
        (seq3 bound bound bound)
        (maybe (identifier <& token Token.COLON))
        Comp_parsers.comp_sort_object
    <& token Token.DOT
    |> span
    |> labelled "meta-logic search engine mquery pragma"
    $> fun (location, ((expected_solutions, search_tries, search_depth), identifier, typ)) ->
       Signature.Declaration.MQuery
         { location
         ; identifier
         ; typ
         ; expected_solutions
         ; search_tries
         ; search_depth
         }

  let sgn_oldstyle_lf_decl =
    seq2 (identifier <& token Token.COLON) LF_parsers.lf_object <& token Token.DOT
    |> span
    $> (fun (location, (identifier, typ_or_const)) ->
          Signature.Declaration.Typ_or_const { location; identifier; typ_or_const })
    |> labelled "old-style LF type or constant declaration"

  let not_pragma =
    pragma "not"
    |> span
    $> fun (location, ()) -> Signature.Pragma.Not { location }

  let left_associativity =
    keyword "left"
    $> Fun.const Associativity.left_associative
    |> labelled "associativity `left'"

  let right_associativity =
    keyword "right"
    $> Fun.const Associativity.right_associative
    |> labelled "associativity `right'"

  let non_associativity =
    keyword "none"
    $> Fun.const Associativity.non_associative
    |> labelled "associativity `none'"

  let associativity =
    choice
      [ left_associativity
      ; right_associativity
      ; non_associativity
      ]
    |> labelled "associativity"

  let prefix_pragma =
    (pragma "prefix" &> seq2 qualified_identifier (maybe integer)) <& token Token.DOT
    |> span
    $> fun (location, (constant, precedence)) ->
        Signature.Pragma.Prefix_fixity
          { location
          ; constant
          ; precedence
          }

  let infix_pragma =
    (pragma "infix" &> seq3 qualified_identifier (maybe integer) (maybe associativity)) <& token Token.DOT
    |> span
    $> fun (location, (constant, precedence, associativity)) ->
          Signature.Pragma.Infix_fixity
            { location
            ; constant
            ; precedence
            ; associativity
            }

  let postfix_pragma =
    (pragma "postfix" &> seq2 qualified_identifier (maybe integer)) <& token Token.DOT
    |> span
    $> fun (location, (constant, precedence)) ->
          Signature.Pragma.Postfix_fixity
            { location
            ; constant
            ; precedence
            }

  let fixity_pragma =
    choice
      [ prefix_pragma
      ; infix_pragma
      ; postfix_pragma
      ]

  let default_associativity_pragma =
    pragma "assoc" &> associativity <& token Token.DOT
    |> span
    $> fun (location, associativity) ->
      Signature.Pragma.Default_associativity { location; associativity }

  let open_pragma =
    pragma "open" &> qualified_identifier <& token Token.DOT
    |> span
    $> (fun (location, module_identifier) ->
         Signature.Pragma.Open_module { location; module_identifier })
    |> labelled "open module pragma"

  let abbrev_pragma =
    pragma "abbrev" &> seq2 qualified_identifier identifier <& token Token.DOT
    |> span
    $> (fun (location, (module_identifier, abbreviation)) ->
          Signature.Pragma.Abbreviation { location; module_identifier; abbreviation }
       )
    |> labelled "module abbreviation pragma"

  let sgn_comment =
    satisfy' `html_comment
      (function
       | Token.BLOCK_COMMENT s -> Option.some s
       | _ -> Option.none)
    |> span
    |> labelled "HTML comment"
    $> fun (location, content) -> Signature.Declaration.Comment { location; content }

  let sgn_typedef_decl =
    seq3
      (token Token.KW_TYPEDEF &> identifier)
      (token Token.COLON &> Comp_parsers.comp_sort_object)
      (token Token.EQUALS &> Comp_parsers.comp_sort_object <& token Token.SEMICOLON)
    |> span
    |> labelled "type synonym declaration"
    $> fun (location, (identifier, kind, typ)) ->
       Signature.Declaration.CompTypAbbrev { location; identifier; kind; typ }

  let sgn_schema_decl =
    seq2
      (token Token.KW_SCHEMA &> identifier <& token Token.EQUALS)
      Meta_parsers.schema_object
    <& token Token.SEMICOLON
    |> span
    $> (fun (location, (identifier, schema)) ->
          Signature.Declaration.Schema { location; identifier; schema }
       )
    |> labelled "Context schema declaration"

  let sgn_let_decl =
    seq2
      (token Token.KW_LET &>
         seq2
           identifier
           (maybe (token Token.COLON &> Comp_parsers.comp_sort_object)))
      (token Token.EQUALS &> Comp_parsers.comp_expression_object <& token Token.SEMICOLON)
    |> span
    |> labelled "value declaration"
    $> fun (location, ((identifier, typ), expression)) ->
       Signature.Declaration.Val { location; identifier; typ; expression }

  let program_decl =
    seq4
      (identifier <& token Token.COLON)
      (Comp_parsers.comp_sort_object <& token Token.EQUALS)
      (maybe (bracketed' (token Token.SLASH) totality_declaration))
      Comp_parsers.comp_expression_object
    |> span
    $> fun (location, (identifier, typ, order, body)) ->
      Signature.Declaration.Theorem { location; identifier; typ; order; body }

  let proof_decl =
    token Token.KW_PROOF
    &> seq4
      (identifier <& token Token.COLON)
      (Comp_parsers.comp_sort_object <& token Token.EQUALS)
      (maybe (bracketed' (token Token.SLASH) totality_declaration))
      Harpoon_parsers.harpoon_proof
  |> span
  $> fun (location, (identifier, typ, order, body)) ->
    Signature.Declaration.Proof { location; identifier; typ; order; body }

  let sgn_thm_decl =
    token Token.KW_REC
      &> sep_by1
          (choice [ program_decl; proof_decl ])
          (token Token.KW_AND)
      <& token Token.SEMICOLON
    |> span
    |> labelled "(mutual) recursive function declaration(s)"
    $> fun (location, declarations) ->
      Signature.Declaration.Recursive_declarations { location; declarations }

  let sgn_module_decl =
    seq2
      (token Token.KW_MODULE &> identifier)
      (tokens [ Token.EQUALS; Token.KW_STRUCT ] &> many Signature_parsers.sgn_decl)
    <& token Token.KW_END
    <& maybe (token Token.SEMICOLON)
    |> span
    |> labelled "module declaration"
    $> fun (location, (identifier, declarations)) ->
        Signature.Declaration.Module { location; identifier; declarations }

  let sgn_decl =
    let pragma =
      choice
        [ name_pragma
        ; not_pragma
        ; fixity_pragma
        ; default_associativity_pragma
        ; open_pragma
        ; abbrev_pragma
        ]
      |> span
      $> fun (location, pragma) -> Signature.Declaration.Pragma { location; pragma }
    in
    choice
      [ pragma

      ; query_declaration
      ; mquery_declaration
      ; sgn_comment

      (* misc declarations *)
      ; sgn_module_decl
      ; sgn_typedef_decl

      (* type declarations *)
      ; sgn_lf_typ_decl
      ; sgn_cmp_typ_decl
      ; sgn_oldstyle_lf_decl
      ; sgn_schema_decl

      (* term declarations *)
      ; sgn_let_decl
      ; sgn_thm_decl
      ]
    |> labelled "top-level declaration"

  let sgn =
    seq2
      (many sgn_global_prag |> renamed "zero or more global pragmas")
      (many sgn_decl |> renamed "zero or more top-level declarations")
    $> fun (prags, decls) ->
       prags @ decls
end

let sgn = Signature_parsers.sgn

let sgn_decl = Signature_parsers.sgn_decl

let trust_totality_declaration = Signature_parsers.trust_totality_declaration

let named_totality_declaration = Signature_parsers.named_totality_declaration

let numeric_totality_declaration = Signature_parsers.numeric_totality_declaration

let totality_declaration = Signature_parsers.totality_declaration
