(** Beluga syntax parser

    {1 Intro to Parser Combinators}

    This is a hand-made parser combinator system. The basic idea in parser
    combinators is to use higher-order functions to manipulate _parsing
    functions_ to build up more complex parsers.

    The most basic type we can give for a parsing function would be something
    like:

    {[
      type 'a parser = char list -> char list * 'a option
    ]}

    [char list] represents the input stream. We must return a new stream,
    perhaps with some characters removed since we parsed them. The result of
    the parse is parametric. Since parsing may fail, we use a type
    constructor to represent this, namely [option].

    However this design has many shortcomings:

    - Representing the input as a [char list] requires the entire input to be
      buffered in memory. This is wasteful. Instead, we should progressively
      read input as we need it. Therefore in our implementation we use a lazy
      list [LinkStream.t].
    - Using [option] to represent failure doesn't give us a means to specify
      what the error is. Instead we use [Either.t] in order to also return
      some information in case of failure.
    - Finally, in order to control backtracking and other parsing features,
      we will need to not only pass around and transform the {i input}, but a
      more general {i parser state}.

    So our parsing function type now looks like:

    {[
      type 'a parser = state -> state * (error, 'a) Either.t
    ]}

    where [state] contains a [(Location.t * Token.t) LinkStream.t] for the
    input as well as extra stuff for handling backtracking.

    {2 Backtracking}

    The naive implementation of the [alt] alternation combinator is to say
    that [alt p1 p2] first runs [p1], and if it fails, runs [p2]. This
    implementation has the major drawback of allowing {i unlimited}
    backtracking. This is undesirable because it results in terrible error
    messages. What we would like is a way to control the backtracking
    behaviour of parsers on a more fine-grained level.

    Instead, the library below is non-backtracking, so it introduces the
    [trying] combinator to selectively enable backtracking. [trying p] runs
    [p], and if [p] fails having even consumed input, then [trying p] can
    still be backtracked out of. The [alt] combinator is implemented like
    this:

    - Run [p1]. If it succeeds, return its result without trying [p2].
    - If [p1] failed without consuming any input, then run [p2].
    - If [p1] failed under a [trying], then run [p2].
    - Otherwise, the error generated by [p1] was fatal, so return it.

    The rationale for this is that it allows the parser writer to commit to a
    parse tree once certain conditions have been met. For example, in Beluga,
    after a `case' keyword, we know for sure that we're parsing a case
    expression. Therefore, if we fail afterwards to parse the scrutinee of
    the case, we should not backtrack out of the parser for case expressions.

    {2 Language Design Considerations}

    This parser combinator library is only suited for top-down
    data-independent parsing. That is, tokens are parsed sequentially from
    left to right, and no auxiliary data is accumulated during parsing. This
    means that left-recursive grammars and data-dependent grammars are not
    supported without either rewriting the grammar, or disambiguating and
    rewriting parsed ASTs at a later stage.

    It is best to implement a parser with a pre-defined context-free grammar
    in a language specification document. This grammar may need rewriting to
    eliminate left recursion, assign precedences and associativities using
    recursive descent parsing. *)

open Support

module LF = Syntax.Prs.LF
module CLF = Syntax.Prs.CLF
module Comp = Syntax.Prs.Comp
module Harpoon = Syntax.Prs.Harpoon
module Sgn = Syntax.Prs.Sgn

(***** Parser state definition *****)

(** Type of located values, i.e. values paired with their location. *)
type 'a locd = Location.t * 'a

(** The input to the parser is a backtrackable stream of tokens paired
    with their locations.
 *)
type input = Token.t locd LinkStream.t

(** The parser state contains the input stream as well as control
    information to handle backtracking.
 *)
type state =
  { input : input
  ; backtrack : bool
  ; last_loc : Location.t (* Location of the last token seen by the parser. *)
  }

  (*
(** Peeks at the next token in the input stream in the given state. *)
let peek_at (s : state) : Token.t locd option =
  Option.(LinkStream.observe s.input $> Pair.fst)
   *)

  (*
(** Like `peek_at` but forgets the location. *)
let next_token s =
  Option.(peek_at s $> Pair.snd |> get_default Token.EOI)
   *)

(***** ERROR HANDLING *****)

type error_entry =
  { label : string
  ; location : Location.t option
  }

type path' =
  | Entry of error_entry
  | Shift of error_entry * path
and path = path' list

let entry ?location label =
  Entry { location; label }

let rec path_head (p : path) : error_entry option =
  match p with
  | [] -> Option.none
  | x :: _ -> Option.some (path'_head x)

and path'_head (p' : path') : error_entry =
  match p' with
  | Entry e -> e
  | Shift (e, p) ->
     match path_head p with
     | Option.Some e' ->
        { e with label = e.label ^ " " ^ e'.label }
     | Option.None -> e

type content =
  [ `token of Token.t option
  | `identifier of string option
  | `qualified_identifier of (string list * string) option
  | `keyword of string option
  | `hash_identifier of string option
  | `dollar_identifier of string option
  | `hash_blank
  | `dollar_blank
  | `hole of string option
  | `integer of int option
  | `dot_integer
  | `string_literal
  | `html_comment
  | `eoi
  ]

let print_content ppf : content -> unit =
  let open Format in
  let format_option_with g ppf t =
    Option.print (fun ppf t -> fprintf ppf " `%a'" g t) ppf t
  in
  let string_option = format_option_with pp_print_string in
  let int_option = format_option_with pp_print_int in
  let format_with ppf s f x = fprintf ppf "%s%a" s f x in
  function
  | `token t ->
     fprintf ppf "token%a"
       (format_option_with Token.pp) t
  | `dot_integer -> fprintf ppf "dot integer"
  | `string_literal -> fprintf ppf "string literal"
  | `identifier i ->
     format_with ppf "identifier" string_option i
  | `qualified_identifier i ->
     fprintf ppf "qualified identifier%a"
       (format_option_with
          (fun ppf (ss, s) ->
            fprintf ppf "%a%s"
              (pp_print_list ~pp_sep: (fun ppf () -> fprintf ppf ".")
                 pp_print_string) ss
              s))
       i
  | `hash_identifier i ->
     format_with ppf "hash identifier" string_option i
  | `dollar_identifier i ->
     format_with ppf "dollar identifier" string_option i
  | `hash_blank ->
     fprintf ppf "hash blank"
  | `dollar_blank ->
     fprintf ppf "dollar blank"
  | `hole i ->
     format_with ppf "hole" string_option i
  | `keyword i ->
     format_with ppf "keyword" string_option i
  | `integer i ->
     format_with ppf "integer literal" int_option i
  | `eoi ->
     fprintf ppf "end of input"
  | `html_comment -> fprintf ppf "HTML comment"

type error' =
  (* External errors: the user's fault. *)
  | Unexpected of { expected : content; actual : content }
  | IllFormedDataDecl
  (* ^ incorrect constructor type: the type of a constructor must be a
     base type or a function type.
   *)
  (* | Custom of string (* Generic external error. *) *)
  | WrongConstructorType of
    { constructor_name : Name.t
    ; expected_type_name : Name.t
    ; actual_type_name : Name.t
    }

  | NoMoreChoices of error list (* all alternatives failed *)

  | AmbiguousUseOfOperator of
      { associativity : Associativity.t
      }

  (* Internal errors: our fault; these should never go to the user. *)
  (* Raised by `satisfy` when it fails.
      This is an internal error because it is totally uninformative
      and low-level. When a high-level parser is constructed using
      `satisfy`, it should check for this error and rewrite it into a
      nicer one for the user.
   *)
  | NotFollowedBy

  (* Generic internal error. *)
  | Violation of string

and error =
  { error : error'
  (* ^ The actual error. *)
  ; path : path
  (* ^ Sequence of parser labels that led to the parse error.
     This is used to generate errors of the form.
     ```
     Parse error: unexpected `bar', expected `foo'.
     In a parser for `production1'
     In a parser for `production2'
     and so on
     ```
   *)
  ; loc : Location.t (* the location the error occurred at *)
  }

exception Error of state * error

(** Pretty-print an error path. *)
let print_path ppf (path : path) : unit =
  let open Format in
  let print_entry ppf { label; location } : unit =
    fprintf ppf "in `%s'%a" label
      (Option.print
         (fun ppf x -> fprintf ppf " at %a" Location.print x))
      location
  in
  let rec go' ppf (path' : path') =
    match path' with
    | Entry e -> fprintf ppf "%a" print_entry e
    | Shift (e, p) ->
       fprintf ppf "@[%a@]@,%a" print_entry e go_box p
  and go ppf (path : path) =
    pp_print_list go' ppf path
  and go_box ppf (path : path) =
    fprintf ppf "  @[<v>%a@]" go path
  in
  fprintf ppf "%a" go_box path

let print_error ppf ({path; loc; _} as e : error) =
  let open Format in
  fprintf ppf "@[<v>Parse error.@,";
  let (* rec *) g ppf {error = e; _} =
    match e with
    | NoMoreChoices ss ->
       fprintf ppf "Expected:@,  @[<v>";
       pp_print_list ~pp_sep: (fun _ () -> ())
         (fun ppf x ->
           Option.print
             (fun ppf x -> fprintf ppf "%s@," x.label)
             ppf
             (path_head x.path))
         ppf
         ss;
       fprintf ppf "@]"
    (* fprintf ppf "Next token: %a@." Token.(print `TOKEN) (next_token s) *)
    | Unexpected { expected = t_exp; actual = t_act; _ } ->
       fprintf ppf "Unexpected token in stream@,  @[<v>Expected %a@,Got %a@]@,"
         print_content t_exp
         print_content t_act
    | IllFormedDataDecl ->
       fprintf ppf
         ( "Ill-formed constructor declaration.@," ^^
             "The type of a constructor must be a base type or function type."
         )
    | WrongConstructorType
      { constructor_name = c
      ; expected_type_name = exp
      ; actual_type_name = act
      } ->
       fprintf ppf
         ( "Wrong datatype for constructor %s.@,  @[<v>"
           ^^ "Expected type %s@,"
           ^^ "Actual type %s"
           ^^ "@]"
         )
         (Name.string_of_name c)
         (Name.string_of_name exp)
         (Name.string_of_name act)
    | AmbiguousUseOfOperator
        { associativity = Associativity.Left_associative
        } ->
       fprintf ppf "Ambiguous use of a left-associative operator"
    | AmbiguousUseOfOperator
        { associativity = Associativity.Right_associative
        } ->
       fprintf ppf "Ambiguous use of a right-associative operator"
    | AmbiguousUseOfOperator
        { associativity = Associativity.Non_associative
        } ->
       fprintf ppf "Ambiguous use of a non-associative operator"
    (* | Custom s -> fprintf ppf "%s" s *)
    | Violation s -> fprintf ppf "%s" s
  in
  fprintf ppf "%a" g e;
  if Debug.flag 11 then fprintf ppf "@,%a" print_path path;
  fprintf ppf "@]"

let () =
  Error.register_printer'
    begin
      function
      | Error (s, e) ->
         Option.some
           (Error.print_with_location e.loc
              (fun ppf -> print_error ppf e))
      | _ -> Option.none
    end

(***** Parser type definition *****)

(** Gets the location of the next item in the input stream *)
let next_loc_at (s : state) : Location.t =
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed"
  (* the lexer should infinitely repeat "EOI" when it's done. *)
  | Option.Some ((loc, _), _) -> loc

let prev_loc_at (s : state) : Location.t = s.last_loc

let initial_state input =
  { input
  ; backtrack = false
  ; last_loc = Location.ghost
  }

(** A parsing result is either an error or a successfully computed value. *)
type 'a result = (error, 'a) Either .t

(** A parsing function transforms a state and produces a parsing result. *)
type 'a parser = state -> state * 'a result

(** Run a parser.
    In other words, extracts the parsing function from a parser. *)
let[@inline] run p s = p s

(** Eliminator for parse results. *)
let handle catch f = Either.eliminate catch f

(** Converts a parse result to Either. *)
let to_either (r : 'a result) : (error, 'a) Either.t = r

(** Extracts the value from a parse result.
    If the parse was unsuccessful, then this raises a parse error exception. *)
let extract =
  function
  | (s, Either.Left e) -> raise @@ Error (s, e)
  | (_, Either.Right x) -> x

type 'a t = 'a parser

(***** Basic parser helpers *****)

(** Runs `p' and invokes the given handler to modify the outcome.
    Despite being called "catch", this parser is actually a kind of `map',
    and is used to implement "low-level" parser transformations.
 *)
let catch (p : 'a parser) (handler : state * 'a result -> state * 'b result) : 'b parser =
  fun s -> run p s |> handler

(** Constructs a failure result for a given state. *)
let fail_at' s loc path error =
  ( s
  , Either.left {error ; path; loc}
  )

(** Fail with no error path. *)
let fail_at s error = fail_at' s (next_loc_at s) [] error

(** A parser that fails with the given error and path. *)
let fail' path e : 'a parser =
  fun s -> fail_at' s (next_loc_at s) path e

(** A parser that fails with the given error and an empty path. *)
let fail e : 'a parser = fail' [] e

let return_at s x =
  (s, Either.right x)

(** Gets the current parser state. *)
let get_state : state parser =
  fun s -> return_at s s

(** Sets the current parser state. *)
let[@warning "-32"] put_state (s : state) : unit parser =
  fun _ -> return_at s ()

(***** Parser combinators *****)

(** Runs the parser `p` with unlimited backtracking enabled. *)
let trying p =
  fun s ->
    match run p s with
    | (s, Either.Left e) -> ({ s with backtrack = true}, Either.left e)
    | x -> x

module M = Monad.Make (struct
  type nonrec 'a t = 'a t

  let return x = fun s -> return_at s x

  let bind k p =
    fun s ->
    match run p s with
    | (s, Either.Right x) -> run (k x) s
    | (s, Either.Left e) -> (s, Either.left e)
end)

include (M : Monad.MONAD with type 'a t := 'a t)

include (Functor.Make (M) : Functor.FUNCTOR with type 'a t := 'a t)

include (Apply.Make (M) : Apply.APPLY with type 'a t := 'a t)

(***** Combinators for handling error labels. *****)

(** Gets the location of the next token in the input stream.
    If the stream is ended, gets the location of the last token.
 *)
let next_loc : Location.t parser =
  get_state
  $> fun s -> next_loc_at s

let prev_loc : Location.t parser =
  get_state
  $> fun s -> prev_loc_at s

(** Runs `p` tracking the span of source material processed by it. *)
let span p =
  seq3 next_loc p prev_loc $> fun (l1, x, l2) -> (Location.join l1 l2, x)

(** Runs the parser, and if it fails, runs the given function to
    transform the label stack.
    Also provides the location of the very next token `p` would see.
 *)
let relabelling (type a) (p : a parser) (f : Location.t -> path -> path) : a parser =
  next_loc
  >>= fun loc ->
    catch p
      (function
       | s, Either.Left e -> s, Either.left {e with path = f loc e.path }
       | x -> x)

let shift p s =
  relabelling p
    begin fun loc path ->
    [ Shift
        ( { location = Option.some loc
          ; label = s
          }
        , path
        )
    ]
    end

let shifted s p = shift p s

(** Adds the given label to the stack if `p` fails. *)
let label p s =
  relabelling p (fun location path -> entry ~location s :: path)

(** Flipped version of `label'. *)
let labelled s p = label p s

(** Replaces the _name_ of the last entry on the path. *)
let renamed label p =
  relabelling p
    begin fun loc ->
    function
    | [] -> []
    | Shift (e, p) :: xs -> Shift ({ e with label }, p) :: xs
    | Entry e :: xs -> Entry { e with label } :: xs
    end

(***** Special combinators *****)

(** [not_followed_by p] succeeds if the parser [p] fails.
    This parser does not consume any input.
 *)
let[@warning "-32"] not_followed_by (p : 'a parser) : unit parser =
  span get_state
  >>= fun (loc, s) ->
    catch p
      (function
       | s', Either.Left _ ->
          (* if [p] fails, we restore the original state *)
          run (put_state s) s'
       | _, Either.Right _ ->
          (* if [p] succeeds, then we need to fail *)
          s, Either.left { error = NotFollowedBy; path = []; loc = loc }
      )

(***** Parsing lists. *****)

(** Like {!traverse} but for parsers without interesting outputs. *)
let rec traverse_ (f : 'a -> unit parser) (xs : 'a list) : unit parser =
  match xs with
  | [] -> return ()
  | x :: xs ->
     f x &> traverse_ f xs

(***** Prioritized choice *****)

(** Alternation between parsers.

    Runs `p1`. If it fails, p2 is run if one of the following is true.
    - p1 failed without consuming any input.
    - p2 failed with backtracking enabled.

    Backtracking is enabled by the `trying` combinator.
 *)
let alt (p1 : 'a parser) (p2 : 'a parser) : 'a parser =
  fun s ->
  match run p1 s with
  | (s', Either.Left e) ->
      let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
      if Bool.not consumed_input || s'.backtrack
      then run p2 s
      else (s', Either.left e)
  | x -> x

let choice (ps : 'a parser list) : 'a parser =
  fun s ->
  let rec go es =
    function
    | [] -> fail (NoMoreChoices es)
    | p :: ps' ->
        catch p
          (function
          | (s', Either.Left e) ->
              let consumed_input = LinkStream.position s.input < LinkStream.position s'.input in
              if Bool.not consumed_input || s'.backtrack
              then run (go (e :: es) ps') s
              else (s', Either.left e)
          | x -> x)
  in
  run (go [] ps) s

(** Succeeds only if the stream has reached the end of the input. *)
let eoi : unit parser =
  (fun s ->
  match LinkStream.observe s.input with
  | Option.None | Option.Some ((_, Token.EOI), _) -> return_at s ()
  | Option.Some ((_, t), _) ->
    fail_at s (Unexpected { expected = `eoi; actual = `token (Option.some t) }))
  |> labelled "end of input"

(** Constructs a parser that accepts the current token if it satisfies
    the given predicate.
    The predicate is _successful_ if it returns `Right`.
    The `Left` output indicates failure and can be used to remember
    the next token in the stream to construct better eroros in a
    downstream parser. If you don't care, use unit.
    The input stream advances only if the predicate succeeds.
 *)
let satisfy (f : Token.t -> ('e, 'b) Either.t) : ('e, 'b) Either.t parser =
  fun s ->
  match LinkStream.observe s.input with
  | Option.None -> failwith "lexer invariant failed: end-of-input is a token"
  | Option.Some ((loc, t), xs) ->
      let r = f t in
      let s' =
        (* construct the new state with the input depending on
          whether the predicate succeeded.
        *)
        match r with
        | Either.Left _ -> s
        | Either.Right _ -> { s with input = xs; last_loc = loc }
      in
      return_at s' r

(** Tries a parser, and if it fails returns [Option.none] *)
let maybe (p : 'a parser) : 'a option parser =
  shifted "optionally"
    (alt (p $> Option.some) (return Option.none))

(** Tries a parser, and if it fails uses a default value. *)
let maybe_default p ~default =
  maybe p $> Option.value ~default

(** Internal implementation of `many` that doesn't label. *)
let rec many' (p : 'a parser) : 'a list parser =
  alt (some' p $> List1.to_list) (return [])

(** Internal implementation of `some` that doesn't label. *)
and some' (p : 'a parser) : 'a List1.t parser =
  p >>= fun x -> many' p >>= fun xs -> return (List1.from x xs)

(** `many p` repeats the parser `p` zero or more times and collects
    the results in a list.
 *)
let many (p : 'a parser) : 'a list parser =
  shifted "many" (many' p)

(** `some p` repeats the parser `p` one or more times and collects the
    results in a list.
 *)
let some (p : 'a parser) : 'a List1.t parser =
  shifted "some" (some' p)

(** `sep_by0 p sep` parses zero or more occurrences of `p` separated
    by `sep` and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use `void`.
 *)
let sep_by0 (p : 'a parser) (sep : unit parser) : 'a list parser =
  maybe p
  >>= (function
      | Option.None -> return []
      | Option.Some x ->
        many' (sep &> p)
        >>= fun xs -> return (x :: xs))
  |> shifted "many separated"

(** `sep_by1 p sep` parses one or more occurrences of `p` separated by
    `sep` and collects the results in a list.
    Remark: the separator parser must not produce a result; to forget
    the result of a parser, use `void`.
 *)
let sep_by1 (p : 'a parser) (sep : unit parser) : 'a List1.t parser =
  seq2 p (many' (sep &> p))
  $> (fun (x, xs) -> List1.from x xs)
  |> shifted "some separated"

(** {1 Expressions Parsing}

    Helpers for parsing expression lists containing pre-defined operators.
    These pre-defined operators may be prefix, postifx or infix,
    left-associative, right-associative or non-associative, and with
    differing predecences.

    This implementation is adapted from the [parsec] library on Hackage:

    @see <https://github.com/haskell/parsec/blob/master/src/Text/Parsec/Expr.hs> *)

(** This data type specifies operators that work on values of type ['operand].
    An operator is either binary infix or unary prefix or postfix. A binary
    operator has also an associativity.

    An operator's parser parses the token or identifier corresponding to the
    operator, and returns the function to construct the operand corresponding
    to the application of the operator. *)
type[@warning "-37"] 'operand operator =
  | Infix of
      { parser :
          (left_operand:'operand -> right_operand:'operand -> 'operand) t
      ; associativity : Associativity.t
      }
  | Prefix of { parser : ('operand -> 'operand) t }
  | Postfix of { parser : ('operand -> 'operand) t }

(** An operator table is a list of operator lists. The list is ordered in
    descending precedence. All operators in one list have the same precedence
    (but may have a different associativity). *)
type 'a operator_table = 'a operator List.t List.t

(** [expression operators operand] is an expression parser with operators in
    [operators] and operands parsed as [operand]. Operator precedence, fixity
    and precedence as specified in [operators] are taken into account. *)
let expression : 'a operator_table -> 'a t -> 'a t =
  let splitOp operator (rassoc, lassoc, nassoc, prefix, postfix) =
    match operator with
    | Infix { parser = op; associativity } -> (
      match associativity with
      | Associativity.Non_associative ->
        (rassoc, lassoc, op :: nassoc, prefix, postfix)
      | Associativity.Left_associative ->
        (rassoc, op :: lassoc, nassoc, prefix, postfix)
      | Associativity.Right_associative ->
        (op :: rassoc, lassoc, nassoc, prefix, postfix))
    | Prefix { parser = op } ->
      (rassoc, lassoc, nassoc, op :: prefix, postfix)
    | Postfix { parser = op } ->
      (rassoc, lassoc, nassoc, prefix, op :: postfix)
  in
  let makeParser term ops =
    let rassoc, lassoc, nassoc, prefix, postifx =
      List.fold_right splitOp ops ([], [], [], [], [])
    in
    let rassocOp = choice rassoc
    and lassocOp = choice lassoc
    and nassocOp = choice nassoc
    and prefixOp = choice prefix
    and postfixOp = choice postifx in
    let ambiguous associativity op =
      op >>= fun _ -> fail @@ AmbiguousUseOfOperator { associativity }
    in
    let ambiguousRight = ambiguous Associativity.right_associative rassocOp
    and ambiguousLeft = ambiguous Associativity.left_associative lassocOp
    and ambiguousNon = ambiguous Associativity.non_associative nassocOp in
    let postfixP = alt postfixOp (return Fun.id)
    and prefixP = alt prefixOp (return Fun.id) in
    let termP =
      seq3 prefixP term postfixP
      $> fun (pre, x, post) -> post (pre x)
    in
    let rec rassocP left_operand =
      seq2 rassocOp (termP >>= rassocP1)
      $> fun (f, right_operand) -> f ~left_operand ~right_operand
    and rassocP1 left_operand =
      alt (rassocP left_operand) (return left_operand)
    in
    let rec lassocP left_operand =
      seq2 lassocOp termP
      >>= fun (f, right_operand) -> lassocP1 (f ~left_operand ~right_operand)
    and lassocP1 left_operand =
      alt (lassocP left_operand) (return left_operand)
    in
    let nassocP left_operand =
      seq2 nassocOp termP
      >>= fun (f, right_operand) ->
        choice
          [ ambiguousRight
          ; ambiguousLeft
          ; ambiguousNon
          ; return (f ~left_operand ~right_operand)
          ]
    in
    termP >>= fun x -> choice [ rassocP x; lassocP x; nassocP x; return x ]
  in
  fun operators operand -> List.fold_left makeParser operand operators

(***** Unmixing & other checks *****)

(** Checks that datatype declarations are well formed.
    We can't do this later because after parsing there is no
    structural grouping between constructors of a same datatype.
 *)
let check_datatype_decl loc a cs : unit parser =
  let rec retname =
    function
    | Comp.TypBase { head; _ } -> return head
    | Comp.TypArr { range; _ } -> retname range
    | Comp.TypPiBox { range; _ } -> retname range
    | _ -> fail IllFormedDataDecl
  in
  traverse_
    (function
     | Sgn.CompConst { identifier; typ; _ } ->
        retname typ
        >>= fun a' ->
          if Name.(a <> a')
          then fail
            (WrongConstructorType
              { constructor_name = identifier
              ; expected_type_name = a
              ; actual_type_name = a'
              })
          else return ()
     | _ -> fail (Violation "check_datatype_decl invalid input"))
    cs

let check_codatatype_decl loc a cs : unit parser =
  let retname =
    function
    | Comp.TypBase { head; _ } -> return head
    | _ -> fail IllFormedDataDecl
  in
  traverse_
    (function
     | Sgn.CompDest { identifier; observation_typ = tau0; _} ->
        retname tau0
        >>= fun a' ->
          if Name.(a <> a')
          then fail
            (WrongConstructorType
              { constructor_name = identifier
              ; expected_type_name = a
              ; actual_type_name = a'
              })
          else return ()
     | _ -> fail (Violation "check_codatatype_decl invalid input"))
    cs

(****** Simple parsers *****)

let satisfy' (expected : content) (f : Token.t -> 'a option) : 'a parser =
  satisfy (fun t -> f t |> Option.eliminate (Fun.const (Either.left t)) Either.right)
  |> span
  >>= fun (location, x) ->
    match x with
    | Either.Left t ->
       fail'
         [ entry ~location (Format.stringify print_content expected) ]
         (Unexpected { expected; actual = `token (Option.some t) })
    | Either.Right x -> return x

(** Parses an exact token. *)
let token (t : Token.t) : unit parser =
  satisfy' (`token (Option.some t))
    (fun x -> Option.of_bool (Token.(x = t)))

(** Parses an exact sequence of tokens. *)
let tokens (ts : Token.t list) : unit parser =
  traverse_ token ts

(** Parses an identifier and verifies that it is exactly the given
    string. This is used for parsing "weak keywords", which we would
    still like to allow as general identifiers, but which appear in
    restricted contexts as keywords.
 *)
let keyword (kw : string) : unit parser =
  satisfy' (`keyword (Option.some kw))
    Fun.(Token.equal (Token.IDENT kw) >> Option.of_bool)

let identifier' : string parser =
  satisfy' (`identifier Option.none)
    (function
     | Token.IDENT s -> Option.some s
     | _ -> Option.none)

let hash_identifier : string parser =
  satisfy' (`hash_identifier Option.none)
    (function
     | Token.HASH_IDENT s -> Option.some s
     | _ -> Option.none)

let dollar_identifier : string parser =
  satisfy' (`dollar_identifier Option.none)
    (function
     | Token.DOLLAR_IDENT s -> Option.some s
     | _ -> Option.none)

let namify (p : string t) : Name.t t =
  p |> span
  $> fun (location, x) -> Name.mk_name ~location (Name.SomeString x)

let name : Name.t parser =
  namify identifier'

let hash_name : Name.t t =
  namify hash_identifier

let dollar_name : Name.t t =
  namify dollar_identifier

let integer : int parser =
  satisfy' (`integer Option.none)
    (function
     | Token.INTLIT k -> Option.some k
     | _ -> Option.none)

let dot_integer : int parser =
  satisfy' `dot_integer
    (function
     | Token.DOT_NUMBER k -> Option.some k
     | _ -> Option.none)

let fqidentifier = sep_by1 (trying identifier') (token Token.DOUBLE_COLON)

let pragma s = token (Token.PRAGMA s)

let string_literal =
  satisfy' `string_literal
    (function
     | Token.STRING s -> Option.some s
     | _ -> Option.none)

(** Runs the parser `p` between two parsers whose results are
    ignored. *)
let bracketed start stop p =
  start &> p <& stop

(** Runs the parser `p` between the two instances of the same parser
    `b` whose results are ignored. *)
let bracketed' b p = bracketed b b p

(** [parens p] parses [`(` p `)`]. *)
let parens p = bracketed (token Token.LPAREN) (token Token.RPAREN) p

(** [braces p] parses [`{` p `}`]. *)
let braces p = bracketed (token Token.LBRACE) (token Token.RBRACE) p

(** [bracks p] parses [`[` p `]`]. *)
let[@warning "-32"] bracks p = bracketed (token Token.LBRACK) (token Token.RBRACK) p

(** [angles p] parses [`<` p `>`]. *)
let[@warning "-32"] angles p = bracketed (token Token.LANGLE) (token Token.RANGLE) p

(** Helper for parsing something *optionally* between parens. *)
let opt_parens p = alt (parens p) p

(** Parses p and requires that the input stream be finished. *)
let only p = p <& eoi

(***** Production rules *****)

let nostrenghten_pragma =
  span (pragma "nostrengthen")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.NoStrengthen }

let coverage_pragma =
  span (pragma "coverage")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.Coverage `Error }

let warncoverage_pragma =
  span (pragma "warncoverage")
  $> fun (location, ()) ->
    Sgn.GlobalPragma { location; pragma = Sgn.Coverage `Warn }

let sgn_global_prag : Sgn.decl parser =
  labelled "global pragma"
  @@ choice
       [ nostrenghten_pragma
       ; coverage_pragma
       ; warncoverage_pragma
       ]

let sgn_name_pragma : Sgn.decl parser =
  seq3
    (pragma "name" &> name)
    identifier'
    (maybe identifier' <& token Token.DOT)
  |> labelled "name pragma"
  |> span
  $> fun (location, (constant, meta_name, comp_name)) ->
       let pragma = Sgn.NamePrag { constant; meta_name; comp_name } in
       Sgn.Pragma { location; pragma }

let identifier =
  satisfy' (`identifier Option.none)
    (function
      | Token.IDENT s -> Option.some s
      | _ -> Option.none)
  |> span
  $> fun (location, identifier) -> Identifier.make ~location identifier

let dot_identifier =
  token Token.DOT &> identifier

(*=
    <omittable-identifier> ::=
      | `_'
      | <identifier>
*)
let omittable_identifier =
  alt
    (token Token.UNDERSCORE $> fun () -> Option.none)
    (identifier $> Option.some)

(*=
   <qualified-identifier> ::= (<identifier> `::')* <identifier>
*)
let[@warning "-32"] qualified_identifier =
  sep_by1 identifier (token Token.DOUBLE_COLON)
  |> span
  $> fun (location, identifiers) ->
       let (modules, identifier) = List1.unsnoc identifiers in
       QualifiedIdentifier.make ~location ~modules identifier

(*=
    <qualified-or-plain-identifier> ::=
      | <identifier>
      | (<identifier> `::')+ <identifier>
*)
let qualified_or_plain_identifier =
  sep_by1 identifier (token Token.DOUBLE_COLON)
  |> span
  $> function
     | (_, List1.T (head, [])) -> `Plain head
     | (location, identifiers) ->
       let (modules, identifier) = List1.unsnoc identifiers in
       `Qualified (QualifiedIdentifier.make ~location ~modules identifier)

module rec LF_parsers : sig
  val lf_object : LF.Object.t t
end = struct
  (*=
      Original grammar:

      <lf-object> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>
        | <lf-object> <forward-arrow> <lf-object>
        | <lf-object> <backward-arrow> <lf-object>
        | <lf-object> `:' <lf-object>
        | <lf-object> <lf-object>
        | <identifier>
        | <qualified-identifier>
        | `type'
        | `_'
        | `(' <lf-object> `)'


      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (lambdas and Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <weak-prefix> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>

      <lf-object> ::=
        | <lf-object1>

      <lf-object1> ::=
        | <weak-prefix>
        | <lf-object2>

      <lf-object2> ::=
        | <lf-object3> (`:' (<lf-object3> | <weak-prefix>))+
        | <lf-object3>

      <lf-object3> ::=
        | <lf-object4> ((<forward-arrow> | <backward-arrow>) (<lf-object4> | <weak-prefix>))+
        | <lf-object4>

      <lf-object4> ::=
        | <lf-object5> (<lf-object5> | <weak-prefix>)+
        | <lf-object5>

      <lf-object5> ::=
        | <identifier>
        | <qualified-identifier>
        | `type'
        | `_'
        | `(' <lf-object> `)'
  *)
  let weak_prefix =
    let lambda =
      seq2
        (token Token.LAMBDA
          &> (seq2
              omittable_identifier
              (maybe (token Token.COLON &> LF_parsers.lf_object)))
          <& token Token.DOT)
        LF_parsers.lf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         LF.Object.RawLambda { location; parameter_identifier; parameter_sort; body })
      |> labelled "LF lambda object"
    and pi =
      seq2
        (braces
          (seq2
            omittable_identifier
            (maybe (token Token.COLON &> LF_parsers.lf_object))))
        LF_parsers.lf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         LF.Object.RawPi { location; parameter_identifier; parameter_sort; body })
      |> labelled "LF Pi object"
    in
    choice
      [ lambda
      ; pi
      ]

  let lf_object5 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           LF.Object.RawQualifiedIdentifier { location; identifier; quoted = false }
         | (location, `Plain identifier) ->
           LF.Object.RawIdentifier { location; identifier; quoted = false })
      |> labelled "LF constant or variable object"
    and type_ =
      token Token.KW_TYPE
      |> span
      $> (fun (location, ()) -> LF.Object.RawType { location })
      |> labelled "LF `type' kind object"
    and hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) -> LF.Object.RawHole { location })
      |> labelled "LF hole object"
    and parenthesized_or_quoted_constant_or_variable =
      parens LF_parsers.lf_object
      $> (function
         | LF.Object.RawIdentifier i ->
           LF.Object.RawIdentifier { i with quoted = true }
         | LF.Object.RawQualifiedIdentifier i ->
           LF.Object.RawQualifiedIdentifier { i with quoted = true }
         | o -> o
         )
      |> labelled "LF parenthesized object"
    in
    choice
      [ constant_or_variable
      ; type_
      ; hole
      ; parenthesized_or_quoted_constant_or_variable
      ]

  let lf_object4 =
    some (alt lf_object5 weak_prefix)
    |> span
    $> (function
       | (_, List1.T (object_, [])) -> object_
       | (location, List1.T (o1, o2 :: os)) ->
         LF.Object.RawApplication { location; objects = List2.from o1 o2 os })
    |> labelled "LF atomic or application object"

  let lf_object3 =
    let forward_arrow =
      let parser =
        token Token.ARROW
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (LF.location_of_object left_operand)
              (LF.location_of_object right_operand)
          in
          LF.Object.RawArrow
            { location
            ; domain = left_operand
            ; range = right_operand
            ; orientation = `Forward
            }
      in
      Infix { parser; associativity = Associativity.right_associative }
    and backward_arrow =
      let parser =
        token Token.BACKARROW
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (LF.location_of_object left_operand)
              (LF.location_of_object right_operand)
          in
          LF.Object.RawArrow
            { location
            ; range = left_operand
            ; domain = right_operand
            ; orientation = `Backward
            }
      in
      Infix { parser; associativity = Associativity.left_associative }
    in
    expression
      [ [forward_arrow; backward_arrow] ]
      (alt lf_object4 weak_prefix)
    |> labelled "LF atomic, application, annotated, forward arrow or backward arrow object"

  let lf_object2 =
    let annotation_operator =
      let parser =
        token Token.COLON
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (LF.location_of_object left_operand)
              (LF.location_of_object right_operand)
          in
          LF.Object.RawAnnotated
            { location
            ; object_ = left_operand
            ; sort = right_operand
            }
      in
      Infix { parser; associativity = Associativity.left_associative }
    in
    expression
      [ [annotation_operator] ]
      (alt lf_object3 weak_prefix)
    |> labelled "LF atomic, application, annotated, forward arrow or backward arrow object"

  let lf_object1 =
    choice
      [ weak_prefix
      ; lf_object2
      ]

  let lf_object =
    lf_object1
    |> labelled "LF object"
end

module rec CLF_parsers : sig
  val clf_object : CLF.Object.t t
end = struct
  (*=
      Original grammar:

      <substitution> ::=
        | [`^']
        | `..'
        | `[`..' `,'] <clf-object> (`,' <clf-object>)*

      <clf-object> ::=
        | `{' <omittable-identifier> `:' <clf-object> `}' <clf-object>
        | `\' <omittable-identifier> [`:' <clf-object>] `.' <clf-object>
        | <clf-object> <forward-arrow> <clf-object>
        | <clf-object> <backward-arrow> <clf-object>
        | <clf-object> `:' <clf-object>
        | `block' `(' <identifier> `:' <clf-type> (`,' <identifier> `:' <clf-type>)+ `)'
        | `block' <identifier> `:' <clf-type> (`,' <identifier> `:' <clf-type>)+
        | `block' `(' <clf-type> `)'
        | `block' <clf-type>
        | <clf-object> <clf-object>
        | <clf-object> `[' <substitution> `]'
        | <clf-object>`.'<identifier>
        | <clf-object>`.'<integer>
        | `_'
        | `?'[<identifier>]
        | <identifier>
        | <qualified-identifier>
        | `<' <clf-object> (`;' <clf-object>)* `>'
        | `(' <clf-object> `)'


      Rewritten grammar, to eliminate left-recursions, handle precedence
      using recursive descent, and handle left-associative operators.
      Weak prefix operators (lambdas and Pis) may appear without parentheses
      as the rightmost operand of an operator.

      <substitution> ::=
        | [`^']
        | `..'
        | [`..' `,'] <clf-object> (`,' <clf-object>)*

      <weak-prefix> ::=
        | `{' <omittable-identifier> [`:' <lf-object>] `}' <lf-object>
        | `\' <omittable-identifier> [`:' <lf-object>] `.' <lf-object>

      <clf-object> ::=
        | <clf-object1>

      <clf-object1> ::=
        | <weak-prefix>
        | <clf-object2>

      <clf-object2> ::=
        | <clf-object3> (`:' (<clf-object3> | <weak-prefix>))+
        | <clf-object3>

      <clf-object3> ::=
        | <clf-object4> ((<forward-arrow> | <backward-arrow>) (<clf-object4> | <weak-prefix>))+
        | <clf-object4>

      <clf-object4> ::=
        | `block' `(' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+ `)'
        | `block' <identifier> `:' <clf-object> (`,' <identifier> `:' <clf-object>)+
        | `block' `(' <clf-object> `)'
        | `block' <clf-object>
        | <clf-object5>

      <clf-object5> ::=
        | <clf-object6> (<clf-object6> | <weak-prefix>)+
        | <clf-object6>

      <clf-object6> ::=
        | <clf-object7> (`[' <substitution> `]')+
        | <clf-object7>

      <clf-object7> ::=
        | <clf-object8>(`.'(<integer> | <identifier>))+
        | <clf-object8>

      <clf-object8> ::=
        | <identifier>
        | <qualified-identifier>
        | `_'
        | `?'[<identifier>]
        | `<' <clf-object> (`;' <clf-object>)* `>'
        | `(' <clf-object> `)'
  *)
  let weak_prefix =
    let lambda =
      seq2
        (token Token.LAMBDA
          &> (seq2
              omittable_identifier
              (maybe (token Token.COLON &> CLF_parsers.clf_object)))
          <& token Token.DOT)
        CLF_parsers.clf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
        CLF.Object.RawLambda { location; parameter_identifier; parameter_sort; body })
      |> labelled "Contextual LF lambda object"
    and pi =
      seq2
        (braces
          (seq2
            omittable_identifier
            (maybe (token Token.COLON &> CLF_parsers.clf_object))))
        CLF_parsers.clf_object
      |> span
      $> (fun (location, ((parameter_identifier, parameter_sort), body)) ->
         CLF.Object.RawPi { location; parameter_identifier; parameter_sort; body })
      |> labelled "Contextual LF Pi object"
    in
    choice
      [ lambda
      ; pi
      ]

  let substitution =
    let empty =
      token Token.HAT
    and identity_extension =
      token Token.DOTS
      &> (many (token Token.COMMA &> CLF_parsers.clf_object))
    and plain =
      sep_by1 CLF_parsers.clf_object (token Token.COMMA)
    in
    maybe
      (choice
        [ empty $> (fun () -> `Empty)
        ; identity_extension $> (fun s -> `Identity_extension s)
        ; plain $> (fun s -> `Plain s)
        ]
      )
    |> span
    $> (function
       | (location, Option.None) ->
         { CLF.Substitution.location
         ; head = CLF.Substitution.Head.None
         ; objects = []
         }
       | (location, Option.Some `Empty) ->
         { CLF.Substitution.location
         ; head = CLF.Substitution.Head.None
         ; objects = []
         }
       | (location, Option.Some (`Identity_extension [])) ->
         { CLF.Substitution.location
         ; head = CLF.Substitution.Head.Identity { location }
         ; objects = []
         }
       | (location, Option.Some (`Identity_extension objects)) ->
         { CLF.Substitution.location
         ; head = CLF.Substitution.Head.Identity { location }
         ; objects
         }
       | (location, Option.Some (`Plain objects)) ->
         { CLF.Substitution.location
         ; head = CLF.Substitution.Head.None
         ; objects = List1.to_list objects
         }
       )
    |> labelled "Contextual LF substitution"

  let clf_object8 =
    let constant_or_variable =
      qualified_or_plain_identifier
      |> span
      $> (function
         | (location, `Qualified identifier) ->
           CLF.Object.RawQualifiedIdentifier { location; identifier; quoted = false }
         | (location, `Plain identifier) ->
           CLF.Object.RawIdentifier { location; identifier; quoted = false })
      |> labelled "Contextual LF constant or variable object"
    and underscore_hole =
      token Token.UNDERSCORE
      |> span
      $> (fun (location, ()) ->
           CLF.Object.RawHole { location; variant = `Underscore }
         )
      |> labelled "Contextual LF hole object"
    and possibly_labelled_hole =
      satisfy' (`hole Option.none)
        (function
         | Token.HOLE "" -> Option.some Option.none
         | Token.HOLE s -> Option.some (Option.some s)
         | _ -> Option.none)
      |> span
      $> (function
         | (location, Option.None) ->
           CLF.Object.RawHole { location; variant = `Unlabelled }
         | (location, Option.Some label) ->
           CLF.Object.RawHole
             { location
             ; variant = `Labelled (Identifier.make ~location label)
             }
         )
      |> labelled "Contextual LF possibly labelled hole"
    and tuple =
      angles (sep_by1 CLF_parsers.clf_object (token Token.SEMICOLON))
      |> span
      $> (fun (location, elements) ->
         CLF.Object.RawTuple { location; elements })
      |> labelled "Contextual LF tuple object"
    and parenthesized_or_quoted_constant_or_variable =
      parens CLF_parsers.clf_object
      $> (function
         | CLF.Object.RawIdentifier i ->
           CLF.Object.RawIdentifier { i with quoted = true }
         | CLF.Object.RawQualifiedIdentifier i ->
           CLF.Object.RawQualifiedIdentifier { i with quoted = true }
         | o -> o
         )
      |> labelled "Contextual LF parenthesized object"
    in
    choice
      [ constant_or_variable
      ; underscore_hole
      ; possibly_labelled_hole
      ; tuple
      ; parenthesized_or_quoted_constant_or_variable
      ]

  let clf_object7 =
    let integer_projection =
      dot_integer
      $> fun i ->
        `By_position i
    and identifier_projection =
      dot_identifier
      |> span
      $> fun (location, x) ->
        `By_identifier (Identifier.make ~location x)
    in
    let projection =
      alt integer_projection identifier_projection
    in
    let trailing_projections = many (span projection) in
    seq2 clf_object8 trailing_projections
    $> (function
       | (object_, []) -> object_
       | (object_, projections) ->
           List.fold_left
             (fun accumulator (projection_location, projection) ->
               let location =
                 Location.join
                   (CLF.location_of_object accumulator)
                   projection_location
               in
               CLF.Object.RawProjection
                 { location
                 ; object_ = accumulator
                 ; projection
                 }
             )
             object_
             projections
       )
    |> labelled "Contextual LF atomic or projection object"

  let clf_object6 =
    seq2 clf_object7 (many (bracks substitution))
    $> (function
       | (object_, []) -> object_
       | (object_, substitutions) ->
           List.fold_right
             (fun substitution accumulator ->
               let location =
                  Location.join
                    (CLF.location_of_object accumulator)
                    (CLF.location_of_substitution substitution)
               in
               CLF.Object.RawSubstitution
                 { location
                 ; object_ = accumulator
                 ; substitution
                 }
             )
             substitutions
             object_
       )
    |> labelled "Contextual LF atomic, projection or substitution object"

  let clf_object5 =
    some (alt clf_object6 weak_prefix)
    |> span
    $> (function
       | (_, List1.T (object_, [])) -> object_
       | (location, List1.T (o1, o2 :: os)) ->
         CLF.Object.RawApplication { location; objects = List2.from o1 o2 os })
    |> labelled "Contextual LF atomic, projection, substitution or application object"

  let clf_object4 =
    let block_contents =
      sep_by1
        (seq2 (maybe (identifier <& token Token.COLON)) CLF_parsers.clf_object)
        (token Token.COMMA)
    in
    let block =
      token Token.KW_BLOCK &> alt (parens block_contents) block_contents
      |> span
      $> (fun (location, elements) -> CLF.Object.RawBlock { location; elements })
      |> labelled "Contextual LF block object"
    in
    choice
      [ block
      ; clf_object5
      ]

  let clf_object3 =
    let forward_arrow =
      let parser =
        token Token.ARROW
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (CLF.location_of_object left_operand)
              (CLF.location_of_object right_operand)
          in
          CLF.Object.RawArrow
            { location
            ; domain = left_operand
            ; range = right_operand
            ; orientation = `Forward
            }
      in
      Infix { parser; associativity = Associativity.right_associative }
    and backward_arrow =
      let parser =
        token Token.BACKARROW
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (CLF.location_of_object left_operand)
              (CLF.location_of_object right_operand)
          in
          CLF.Object.RawArrow
            { location
            ; range = left_operand
            ; domain = right_operand
            ; orientation = `Backward
            }
      in
      Infix { parser; associativity = Associativity.left_associative }
    in
    expression
      [ [forward_arrow; backward_arrow] ]
      (alt clf_object4 weak_prefix)
    |> labelled "Contextual LF atomic, application, annotated, forward arrow or backward arrow object"


  let clf_object2 =
    let annotation_operator =
      let parser =
        token Token.COLON
        $> fun () ~left_operand ~right_operand ->
          let location =
            Location.join
              (CLF.location_of_object left_operand)
              (CLF.location_of_object right_operand)
          in
          CLF.Object.RawAnnotated
            { location
            ; object_ = left_operand
            ; sort = right_operand
            }
      in
      Infix { parser; associativity = Associativity.left_associative }
    in
    expression
      [ [annotation_operator] ]
      (alt clf_object3 weak_prefix)
    |> labelled "Contextual LF atomic, application, annotated, forward arrow or backward arrow object"

  let clf_object1 =
    choice
      [ weak_prefix
      ; clf_object2
      ]

  let clf_object =
    clf_object1
    |> labelled "Contextual LF object"
end

let hole : string option parser =
  satisfy' (`hole Option.none)
    (function
     | Token.HOLE "" -> Option.some Option.none
     | Token.HOLE s -> Option.some (Option.some s)
     | _ -> Option.none)
  |> labelled "hole"

let clf_ctyp_decl_bare = Obj.magic ()

let mctx ?(sep = token Token.COMMA) p =
  sep_by0 p sep
  $> Context.of_list_rev

let cmp_kind = Obj.magic ()
let cmp_typ = Obj.magic ()
let cmp_exp_chk = Obj.magic ()
let cmp_exp_syn = Obj.magic ()
let gctx = Obj.magic ()

module rec Harpoon_parsers : sig
  val harpoon_proof : Comp.proof t
  val interactive_harpoon_command : Harpoon.command t
  val interactive_harpoon_command_sequence : Harpoon.command list t
  val next_theorem : [> `next of Name.t | `quit ] t
end = struct
  let boxity =
    choice
      [ keyword "boxed" &> return `boxed
      ; keyword "unboxed" &> return `unboxed
      ; keyword "strengthened" &> return `strengthened
      ]

  let harpoon_command : Comp.command t =
    let by =
      token Token.KW_BY &>
        seq3
          (cmp_exp_syn <& token Token.KW_AS)
          name
          (maybe_default boxity ~default:`boxed)
      |> span
      |> labelled "Harpoon command"
      $> fun (loc, (i, x, b)) ->
         match b with
         | `boxed -> Comp.By (loc, i, x)
         | `unboxed -> Comp.Unbox (loc, i, x, Option.none)
         | `strengthened -> Comp.Unbox (loc, i, x, Option.some `strengthened)
    in
    let unbox =
      keyword "unbox" &>
        seq2
          ((span cmp_exp_syn) <& token Token.KW_AS)
          name
      $> fun ((loc, i), x) -> Comp.Unbox (loc, i, x, Option.none)
    in
    let strengthen =
      keyword "strengthend" &>
        seq2
          (span cmp_exp_syn <& token Token.KW_AS)
          name
      $> fun ((loc, i), x) -> Comp.Unbox (loc, i, x, Option.some `strengthened)
    in
    choice [ by; unbox; strengthen ]

  let case_label : Comp.case_label parser =
    let extension_case_label =
      trying (keyword "extended" &> token Token.KW_BY) &> integer
      |> span
      |> labelled "context extension case label"
      $> fun (loc, n) -> Comp.(ContextCase (ExtendedBy (loc, n)))
    in
    let empty_case_label =
      trying (keyword "empty" &> keyword "context")
      |> span
      |> labelled "empty context case label"
      $> fun (loc, ()) -> Comp.(ContextCase (EmptyContext loc))
    in
    let named_case_label =
      name
      |> span
      |> labelled "constructor case label"
      $> fun (loc, name) -> Comp.NamedCase (loc, name)
    in
    let pvar_case_label =
      token Token.HASH &>
        seq2
          (maybe_default integer ~default:1)
          (maybe dot_integer)
      |> span
      |> labelled "parameter variable case label"
      $> fun (loc, (n, k)) -> Comp.PVarCase (loc, n, k)
    in
    let bvar_case_label =
      trying (keyword "head" &> keyword "variable")
      |> span
      $> fun (loc, ()) -> Comp.BVarCase loc
    in
    choice
      [ bvar_case_label
      ; extension_case_label
      ; empty_case_label
      ; named_case_label
      ; pvar_case_label
      ]

  let harpoon_hypothetical : Comp.hypothetical parser =
    let open Comp in
    let hypotheses =
      seq2
        (mctx (clf_ctyp_decl_bare <& token Token.PIPE))
        gctx
      $> fun (cD, cG) -> { cD = (Obj.magic ()); cG }
    in
    seq2
      (hypotheses <& token Token.SEMICOLON)
      Harpoon_parsers.harpoon_proof
    |> braces
    |> span
    |> labelled "Harpoon hypothetical"
    $> fun (hypothetical_loc, (hypotheses, proof)) ->
        { hypotheses; proof; hypothetical_loc }

  let harpoon_split_branch : Comp.split_branch parser =
    token Token.KW_CASE &>
      seq2
        (case_label <& token Token.COLON)
        harpoon_hypothetical
    |> span
    |> labelled "Harpoon split branch"
    $> fun (split_branch_loc, (case_label, branch_body)) ->
        let open Comp in
        { case_label; branch_body; split_branch_loc }

  let harpoon_directive : Comp.directive parser =
    choice
      [ keyword "intros"
        &> harpoon_hypothetical
        |> span
        $> (fun (loc, h) -> Comp.Intros (loc, h))
      ; keyword "solve"
        &> cmp_exp_chk
        |> span
        $> (fun (loc, e) -> Comp.Solve (loc, e))
      ; keyword "split"
        &> seq2
              (cmp_exp_syn <& token Token.KW_AS)
              (many harpoon_split_branch)
        |> span
        $> (fun (loc, (i, bs)) -> Comp.Split (loc, i, bs))
      ; token Token.KW_IMPOSSIBLE
        &> cmp_exp_syn
        |> span
        $> (fun (loc, i) -> Comp.Split (loc, i, []))
      ; let suffices_arg =
          seq2 cmp_typ (Harpoon_parsers.harpoon_proof |> braces)
          |> span
          $> fun (loc, (tau, p)) -> (loc, tau, p)
        in
        tokens Token.[KW_SUFFICES; KW_BY] &>
          seq2
            (cmp_exp_syn <& token Token.KW_TOSHOW)
            (many suffices_arg)
        |> span
        $> (fun (loc, (i, args)) -> Comp.Suffices (loc, i, args))
      ]
    |> shifted "Harpoon directive"

  let harpoon_proof : Comp.proof parser =
    let incomplete_proof =
      hole
      |> span
      |> labelled "Harpoon incomplete proof `?'"
      $> fun (loc, h) -> Comp.Incomplete (loc, h)
    in
    let command_proof =
      seq2
        (harpoon_command <& token Token.SEMICOLON)
        Harpoon_parsers.harpoon_proof
      |> span
      $> fun (loc, (cmd, prf)) -> Comp.Command (loc, cmd, prf)
    in
    let directive_proof =
      harpoon_directive
      |> span
      $> fun (loc, d) -> Comp.Directive (loc, d)
    in
    choice
      [ incomplete_proof
      ; command_proof
      ; directive_proof
      ]
    |> labelled "Harpoon proof"

  let interactive_harpoon_command : Harpoon.command t =
    let intros =
      keyword "intros"
      &> maybe (some identifier')
      $> fun xs -> Harpoon.Intros (Option.map List1.to_list xs)
    in
    let split =
      keyword "split"
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Split { scrutinee }
    in
    let msplit =
      keyword "msplit"
      &> span (choice [ dollar_name; hash_name; name ])
      $> fun (loc, name) -> Harpoon.MSplit (loc, name)
    in
    let invert =
      keyword "invert"
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Invert { scrutinee }
    in
    let impossible =
      token Token.KW_IMPOSSIBLE
      &> cmp_exp_syn
      $> fun scrutinee -> Harpoon.Impossible { scrutinee }
    in
    let solve =
      keyword "solve"
      &> cmp_exp_chk
      $> fun t -> Harpoon.Solve t
    in
    let auto_invert_solve =
      keyword "auto-invert-solve"
      &> maybe integer
      $> fun n -> H.AutoInvertSolve n
    in
    let inductive_auto_solve =
      keyword "inductive-auto-solve"
      &> maybe integer
      $> fun n -> H.InductiveAutoSolve n
    in
    let by =
      token Token.KW_BY &>
        seq3
          cmp_exp_syn
          (token Token.KW_AS &> name)
          (maybe_default boxity ~default:`boxed)
      $> fun (i, name, b) ->
        match b with
        | `strengthened -> Harpoon.Unbox (i, name, Option.some `strengthened)
        | `unboxed -> Harpoon.Unbox (i, name, Option.none)
        | `boxed -> Harpoon.By (i, name)
    in
    let compute_type =
      token Token.KW_TYPE
      &> cmp_exp_syn
      $> fun i -> Harpoon.Type i
    in
    let suffices =
      let tau_list_item =
        alt
          (cmp_typ $> fun tau -> `exact tau)
          (token Token.UNDERSCORE |> span $> fun (loc, ()) -> `infer loc)
      in
      seq2
        (tokens [Token.KW_SUFFICES; Token.KW_BY]
        &> cmp_exp_syn)
        (token Token.KW_TOSHOW
        &> sep_by0 tau_list_item (token Token.COMMA))
      $> fun (i, tau_list) ->
        Harpoon.Suffices (i, tau_list)
    in
    let unbox =
      keyword "unbox" &>
        seq2
          cmp_exp_syn
          (token Token.KW_AS &> name)
      $> fun (i, name) -> Harpoon.Unbox (i, name, Option.none)
    in
    let strengthen =
      keyword "strengthen" &>
        seq2
          cmp_exp_syn
          (token Token.KW_AS &> name)
      $> fun (i, name) -> Harpoon.Unbox (i, name, Option.some `strengthened)
    in
    let automation_kind =
      choice
        [ keyword "auto-intros" &> return `auto_intros
        ; keyword "auto-solve-trivial" &> return `auto_solve_trivial
        ]
    in
    let automation_change =
      choice
        [ keyword "on" &> return `on
        ; keyword "off" &> return `off
        ; keyword "toggle" &> return `toggle
        ]
    in
    let toggle_automation =
      keyword "toggle-automation"
      &> seq2 automation_kind (maybe_default automation_change ~default:`toggle)
      $> fun (t, c) -> Harpoon.ToggleAutomation (t, c)
    in
    let rename =
      let level =
        choice
          [ keyword "comp" &> return `comp
          ; keyword "meta" &> return `meta
          ]
      in
      keyword "rename"
      &> seq3 level name name
      $> fun (level, rename_from, rename_to) ->
        Harpoon.Rename { rename_from; rename_to; level }
    in
    let basic_command =
      choice
        [ keyword "list" &> return `list
        ; keyword "defer" &> return `defer
        ]
    in
    let select_theorem =
      keyword "select" &> name $> fun x -> Harpoon.SelectTheorem x
    in
    let create_command, serialize_command =
      ( keyword "create" &> return `create
      , keyword "serialize" &> return `serialize
      )
    in
    let theorem_command =
      let dump_proof =
        keyword "dump-proof"
        &> string_literal
        $> fun s -> `dump_proof s
      in
      keyword "theorem" &>
        choice
          ( basic_command
            :: dump_proof
            :: List.map (fun (k, k') -> keyword k &> return k')
                [ ("show-ihs", `show_ihs)
                ; ("show-proof", `show_proof)
                ]
          )
      $> fun cmd -> Harpoon.Theorem cmd
    in
    let session_command =
      keyword "session"
      &> choice [ basic_command; create_command; serialize_command ]
      $> fun cmd -> Harpoon.Session cmd
    in
    let subgoal_command =
      keyword "subgoal"
      &> basic_command
      $> fun cmd -> Harpoon.Subgoal cmd
    in
    let defer =
      keyword "defer" &> return (Harpoon.Subgoal `defer)
    in
    let info_kind =
      choice
        [ keyword "theorem" &> return `prog
        ]
    in
    let info =
      keyword "info"
      &> seq2 info_kind name
      $> fun (k, name) -> Harpoon.Info (k, name)
    in
    let translate =
      keyword "translate"
      &> name
      $> fun name -> Harpoon.Translate name
    in
    let undo = keyword "undo" &> return Harpoon.Undo in
    let redo = keyword "redo" &> return Harpoon.Redo in
    let history = keyword "history" &> return Harpoon.History in
    let help = keyword "help" &> return Harpoon.Help in
    let save = keyword "save" &> return (Harpoon.Session `serialize) in
    choice
      [ intros
      ; info
      ; split
      ; msplit
      ; compute_type
      ; invert
      ; impossible
      ; solve
      ; auto_invert_solve
      ; inductive_auto_solve
      ; by
      ; suffices
      ; unbox
      ; strengthen
      ; translate
      ; toggle_automation
      ; rename
      ; defer
      ; select_theorem
      ; theorem_command
      ; session_command
      ; subgoal_command
      ; undo
      ; redo
      ; history
      ; help
      ; save
      ]

  let interactive_harpoon_command_sequence =
    sep_by0 interactive_harpoon_command (token Token.SEMICOLON)

  let next_theorem =
    alt
      (token Token.COLON &> keyword "quit" &> return `quit)
      (name $> fun name -> `next name)
end

let harpoon_proof = Harpoon_parsers.harpoon_proof

let interactive_harpoon_command = Harpoon_parsers.interactive_harpoon_command

let interactive_harpoon_command_sequence =
  Harpoon_parsers.interactive_harpoon_command_sequence

let next_theorem = Harpoon_parsers.next_theorem

module rec Signature_parsers : sig
  val sgn_decl : Sgn.decl t
  val sgn : Sgn.sgn t
  val trust_order : Comp.total_dec t
  val total_order : 'a Comp.generic_order t -> 'a Comp.generic_order t
  val numeric_total_order : int Comp.generic_order t
  val optional_numeric_total_order : int Comp.generic_order option t
end = struct
  let sgn_lf_const_decl =
    seq2
      (name <& token Token.COLON)
      LF_parsers.lf_object
    |> span
    $> (fun (location, (identifier, typ)) ->
          Sgn.Const { location; identifier; typ })
    |> labelled "LF constant declaration"

  let sgn_lf_typ_decl : Sgn.decl parser =
    let lf_typ_decl_body =
      let typ_decl =
        seq2
          (name <& token Token.COLON)
          LF_parsers.lf_object
      in
      seq2
        (typ_decl <& token Token.EQUALS)
        (maybe (token Token.PIPE)
        &> sep_by0 sgn_lf_const_decl (token (Token.PIPE)))
      |> span
      $> fun (location, ((identifier, kind), const_decls)) ->
        Sgn.Typ { location; identifier; kind }, const_decls
    in
    labelled "LF type declaration block"
      (token Token.KW_LF
      &> (sep_by1 lf_typ_decl_body (token Token.KW_AND))
      <& token Token.SEMICOLON
      |> span
      $> fun (location, declarations) ->
          Sgn.MRecTyp { location; declarations })

  let call_arg =
    alt
      (name $> Option.some)
      (token Token.UNDERSCORE &> return Option.none)
    |> labelled "call argument"

  let named_total_arg : Comp.named_order t =
    name $> fun x -> Comp.Arg x

  let numeric_total_arg : Comp.numeric_order t =
    integer $> fun x -> Comp.Arg x

  let total_order (arg : 'a Comp.generic_order t) : 'a Comp.generic_order t =
    alt
      arg
      (braces (some arg) $> fun args -> Comp.Lex (List1.to_list args))
    |> labelled "totality ordering"

  let trust_order : Comp.total_dec t =
    token Token.KW_TRUST
    |> span
    |> labelled "trust totality"
    $> fun (loc, ()) -> Comp.Trust loc

  (** Parses a totality declaration whose arguments are parsed by `arg` *)
  let total_decl : Comp.total_dec t =
    let total =
      token Token.KW_TOTAL &>
        alt
          begin
            seq2
              (trying (maybe (total_order named_total_arg)))
              (parens (seq2 name (many call_arg)))
            |> span
            $> fun (loc, (order, (r, args))) ->
               Comp.NamedTotal (loc, order, r, args)
          end
          begin
            maybe (total_order numeric_total_arg)
            |> span
            $> fun (loc, order) ->
               Comp.NumericTotal (loc, order)
          end
    in
    alt trust_order total
    |> labelled "totality declaration"

  let numeric_total_order = total_order numeric_total_arg
  let optional_numeric_total_order = maybe numeric_total_order

  (** Mutual block of computation type declarations. *)
  let sgn_cmp_typ_decl =
    labelled "Inductive or stratified computation type declaration"
      begin
        let cmp_typ_decl =
          let flavour =
            alt
              (token Token.KW_INDUCTIVE &> return Sgn.InductiveDatatype)
              (token Token.KW_STRATIFIED &> return Sgn.StratifiedDatatype)
          in
          let sgn_cmp_typ_decl_body =
            seq2
              (name <& token (Token.COLON))
              cmp_typ
            |> span
            $> fun (location, (identifier, typ)) ->
               Sgn.CompConst { location; identifier; typ }
          in
          seq5
            flavour
            (name <& token (Token.COLON))
            (cmp_kind <& token (Token.EQUALS) <& maybe (token (Token.PIPE)))
            (sep_by0 sgn_cmp_typ_decl_body (token Token.PIPE))
            get_state
          |> span
          >>= fun (location, (datatype_flavour, identifier, kind, decls, s)) ->
            check_datatype_decl location identifier decls
            $> fun () ->
               Sgn.CompTyp { location; identifier; kind; datatype_flavour }, decls
        in
        let cmp_cotyp_decl =
          let cmp_cotyp_body =
            seq2
              (* There was this unused feature in the old parser that
                 let a metacontext appear *before* the declaration of the observation.
                 Since it introduces an ambiguity in the parser, I have removed it.
                 In particular, since an optional pair of parens are
                 allowed around the declaration of the observation,
                 `( foo : ` looks like the beginning of a clf_ctyp_decl,
                 namely the beginning of an implicit context
                 abstraction. So `clf_ctyp_decl` will consume some
                 input, and then fail after the colon, thus causing a
                 fatal parse error.
                 Rather than introduce backtracking to resolve this, I
                 think it is preferable to simply remove this unused
                 feature.
                 -je
               *)
              (* (many clf_ctyp_decl $> List.fold_left (fun acc d -> LF.Dec (acc, d)) LF.Empty) *)
              (opt_parens
                 (seq2
                    (name <& token Token.COLON)
                    cmp_typ)
               <& token Token.DOUBLE_COLON)
              cmp_typ
            |> span
            $> fun (location, ((* cD, *) (identifier, tau0), tau1)) ->
               Sgn.CompDest
                { location
                ; identifier
                ; mctx = (Obj.magic ())(* CLF.Empty *)
                ; observation_typ = tau0
                ; return_typ = tau1
                }
          in
          seq4
            (token Token.KW_COINDUCTIVE &> name <& token Token.COLON)
            (cmp_kind <& token Token.EQUALS <& maybe (token Token.PIPE))
            (sep_by0 cmp_cotyp_body (token Token.PIPE))
            get_state
          |> span
          >>= fun (location, (identifier, kind, decls, s)) ->
            check_codatatype_decl location identifier decls
            $> fun () ->
               Sgn.CompCotyp { location; identifier; kind }, decls
        in

        sep_by1 (alt cmp_typ_decl cmp_cotyp_decl) (token Token.KW_AND)
        <& token Token.SEMICOLON
        |> span
        $> fun (location, declarations) -> Sgn.MRecTyp { location; declarations }
      end

  let sgn_query_pragma =
    let bound =
      alt
        (token Token.STAR &> return Option.none)
        (integer $> Option.some)
      |> labelled "search bound"
    in
    pragma "query" &>
      seq4
        (seq2 bound bound)
        (mctx ~sep: (return ()) (clf_ctyp_decl_bare |> braces))
        (maybe (name <& token Token.COLON))
        (Obj.magic ())(* CLF_parsers.clf_typ *)
    <& token Token.DOT
    |> span
    |> labelled "logic programming engine query pragma"
    $> fun (location, ((expected_solutions, maximum_tries), cD, name, typ)) ->
       Sgn.Query { location; name; mctx = (Obj.magic ())(* cD *); typ; expected_solutions; maximum_tries }

  let sgn_oldstyle_lf_decl =
    labelled
      "old-style LF type or constant declaration"
      begin
        seq2
          (name <& token Token.COLON)
          (alt (LF_parsers.lf_object $> fun kind -> `Kind kind) (LF_parsers.lf_object $> fun typ -> `Typ typ) <& token Token.DOT) (* FIXME: Disambiguation is impossible at this point *)
        |> span
        $> fun (location, (identifier, k_or_a)) ->
           match k_or_a with
           | `Kind kind -> Sgn.Typ { location; identifier; kind }
           | `Typ typ -> Sgn.Const { location; identifier; typ }
      end

  let sgn_not_pragma : Sgn.decl parser =
    pragma "not"
    |> span
    $> fun (location, ()) -> Sgn.Pragma { location; pragma=Sgn.NotPrag }

  let left_associativity =
    labelled "associativity `left'" (keyword "left")
    $> Fun.const Associativity.left_associative

  let right_associativity =
    labelled "associativity `right'" (keyword "right")
    $> Fun.const Associativity.right_associative

  let non_associativity =
    labelled "associativity `none'" (keyword "none")
    $> Fun.const Associativity.non_associative

  let associativity =
    labelled "associativity"
    @@ choice
         [ left_associativity
         ; right_associativity
         ; non_associativity
         ]

  let sgn_fixity_pragma =
    let prefix_pragma =
      pragma "prefix"
      &> seq2 name integer
      <& token Token.DOT
      |> span
      $> fun (location, (constant, precedence)) ->
           let pragma =
             Sgn.FixPrag
               { constant
               ; fixity = Fixity.prefix
               ; precedence
               ; associativity = Option.some Associativity.left_associative
               }
           in
           Sgn.Pragma { location; pragma }
    in
    let infix_pragma =
      pragma "infix"
      &> seq3 name integer (maybe associativity)
      <& token Token.DOT
      |> span
      $> fun (location, (constant, precedence, associativity)) ->
           let pragma =
             Sgn.FixPrag
               { constant
               ; fixity = Fixity.infix
               ; precedence
               ; associativity
               }
           in
           Sgn.Pragma { location; pragma }
    in
    let postfix_pragma =
      pragma "postfix"
      &> seq2 name integer
      <& token Token.DOT
      |> span
      $> fun (location, (constant, precedence)) ->
           let pragma =
             Sgn.FixPrag
               { constant
               ; fixity = Fixity.postfix
               ; precedence
               ; associativity = Option.some Associativity.right_associative
               }
           in
           Sgn.Pragma { location; pragma }
    in
    choice
      [ prefix_pragma
      ; infix_pragma
      ; postfix_pragma
      ]

  let sgn_associativity_pragma : Sgn.decl parser =
    pragma "assoc"
    &> associativity
    <& token Token.DOT
    |> span
    $> fun (location, associativity) ->
      let pragma = Sgn.DefaultAssocPrag { associativity } in
      Sgn.Pragma { location; pragma }

  let sgn_open_pragma : Sgn.decl parser =
    pragma "open"
    &> fqidentifier
    |> span
    |> labelled "open pragma"
    <& token Token.DOT
    $> fun (location, id) ->
       Sgn.Pragma { location; pragma = Sgn.OpenPrag (List1.to_list id) }

  let sgn_abbrev_pragma : Sgn.decl parser =
    pragma "abbrev"
    &> seq2 fqidentifier identifier'
    <& token Token.DOT
    |> span
    |> labelled "module abbreviation pragma"
    $> fun (location, (fq, x)) ->
       let fq = List1.to_list fq in
       Sgn.Pragma { location; pragma = Sgn.AbbrevPrag (fq, x) }

  let sgn_comment : Sgn.decl parser =
    satisfy' `html_comment
      (function
       | Token.BLOCK_COMMENT s -> Option.some s
       | _ -> Option.none)
    |> span
    |> labelled "HTML comment"
    $> fun (location, content) -> Sgn.Comment { location; content }

  let sgn_typedef_decl : Sgn.decl parser =
    seq3
      (token Token.KW_TYPEDEF &> name)
      (token Token.COLON &> cmp_kind)
      (token Token.EQUALS &> cmp_typ <& token Token.SEMICOLON)
    |> span
    |> labelled "type synonym declaration"
    $> fun (location, (identifier, kind, typ)) ->
       Sgn.CompTypAbbrev { location; identifier; kind; typ }

  let sgn_schema_decl : Sgn.decl parser = Obj.magic ()

  let sgn_let_decl : Sgn.decl parser =
    seq2
      (token Token.KW_LET &>
         seq2
           name
           (maybe (token Token.COLON &> cmp_typ)))
      (token Token.EQUALS &> cmp_exp_syn <& token Token.SEMICOLON)
    |> span
    |> labelled "value declaration"
    $> fun (location, ((identifier, typ), expression)) ->
       Sgn.Val { location; identifier; typ; expression }

  let thm p =
    seq4
      (name <& token Token.COLON)
      (cmp_typ <& token Token.EQUALS)
      (maybe (bracketed' (token Token.SLASH) total_decl))
      p
    |> span
    $> fun (location, (name, typ, order, body)) ->
       Sgn.Theorem { location; name; typ; order; body }

  let proof_decl : Sgn.thm_decl parser =
    token Token.KW_PROOF
    &> thm (harpoon_proof $> fun p -> Comp.Proof p)

  let program_decl : Sgn.thm_decl parser =
    token Token.KW_REC
    &> thm (cmp_exp_chk $> fun e -> Comp.Program e)

  let sgn_thm_decl : Sgn.decl t =
    sep_by1
      (choice [program_decl; proof_decl])
      (token Token.KW_AND)
    <& token Token.SEMICOLON
    |> span
    |> labelled "(mutual) recursive function declaration(s)"
    $> fun (location, theorems) -> Sgn.Theorems { location; theorems }

  let sgn_module_decl : Sgn.decl t =
    seq2
      (token Token.KW_MODULE &> identifier')
      (Token.(tokens [EQUALS; KW_STRUCT]) &> some Signature_parsers.sgn_decl)
    <& Token.(tokens [KW_END; SEMICOLON])
    |> span
    |> labelled "module declaration"
    $> fun (location, (identifier, declarations)) ->
        Sgn.Module { location; identifier; declarations = List1.to_list declarations }

  let sgn_decl : Sgn.decl t =
    choice
      (* pragmas *)
      [ sgn_name_pragma
      ; sgn_query_pragma
      ; sgn_not_pragma
      ; sgn_fixity_pragma
      ; sgn_associativity_pragma
      ; sgn_open_pragma
      ; sgn_abbrev_pragma
      ; sgn_comment

      (* misc declarations *)
      ; sgn_module_decl
      ; sgn_typedef_decl

      (* type declarations *)
      ; sgn_lf_typ_decl
      ; sgn_cmp_typ_decl
      ; sgn_oldstyle_lf_decl
      ; sgn_schema_decl

      (* term declarations *)
      ; sgn_let_decl
      ; sgn_thm_decl
      ]
    |> labelled "top-level declaration"

  let sgn =
    seq2
      (many sgn_global_prag |> renamed "zero or more global pragmas")
      (many sgn_decl |> renamed "zero or more top-level declarations")
    $> fun (prags, decls) ->
       prags @ decls
end

let sgn = Signature_parsers.sgn
let trust_order = Signature_parsers.trust_order
let total_order = Signature_parsers.total_order
let numeric_total_order = Signature_parsers.numeric_total_order
let optional_numeric_total_order = Signature_parsers.optional_numeric_total_order
